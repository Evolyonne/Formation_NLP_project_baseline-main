# Rapport â€“ Projet Veille NLP

## 1. Objectif du projet
Mettre en place une **pipeline de veille automatique en NLP** permettant de :
- Collecter des articles (HackerNews, RSS)
- PrÃ©traiter les textes
- Classifier les articles (niveau / sentiment)
- GÃ©nÃ©rer automatiquement un **rapport de veille**

Le projet est implÃ©mentÃ© en **Python**, structurÃ© de faÃ§on modulaire et versionnÃ© avec **Git**.

---

## 2. Structure finale du projet

```
baseline_project/
â”‚
â”œâ”€â”€ data/                   # DonnÃ©es gÃ©nÃ©rÃ©es (ignorÃ©es par Git)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ output/                 # Rapports gÃ©nÃ©rÃ©s (ignorÃ©s par Git)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ src/                    # Code source
â”‚   â”œâ”€â”€ news_collector.py
â”‚   â”œâ”€â”€ text_preprocessor.py
â”‚   â”œâ”€â”€ news_classifier.py
â”‚   â””â”€â”€ report_generator.py
â”‚
â”œâ”€â”€ config.json             # Configuration du pipeline
â”œâ”€â”€ main.py                 # Orchestrateur du pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

ğŸ‘‰ **Principe clÃ©** : seuls le code et la configuration sont versionnÃ©s. Les fichiers gÃ©nÃ©rÃ©s (`data/`, `output/`, `__pycache__`) sont exclus de Git.

---

## 3. Pipeline NLP implÃ©mentÃ©e

### Ã‰tape 1 â€“ Collecte des articles
- Sources : HackerNews + flux RSS
- Module : `news_collector.py`
- RÃ©sultat : liste dâ€™articles structurÃ©s (titre, contenu, source, URL)

### Ã‰tape 2 â€“ PrÃ©traitement NLP
- Module : `text_preprocessor.py`
- Nettoyage du texte
- Tokenisation avec **spaCy**
- Rapport de qualitÃ© (perte de tokens, statistiques)

### Ã‰tape 3 â€“ Classification
- Module : `news_classifier.py`
- Classification du **niveau** (Intermediate / Advanced)
- Analyse de **sentiment** (Positif / Neutre / Critique)
- DÃ©tection de doublons

### Ã‰tape 4 â€“ GÃ©nÃ©ration du rapport
- Module : `report_generator.py`
- AgrÃ©gation des rÃ©sultats
- Trending topics
- Articles â€œmustâ€‘readâ€
- Sortie : `output/veille_report.txt`

---

## 4. ProblÃ¨mes rencontrÃ©s et solutions

### 4.1 Dossiers `data/` et `output/` dupliquÃ©s
**ProblÃ¨me** : chemins absolus et incohÃ©rents â†’ gÃ©nÃ©ration de plusieurs dossiers.

**Solution** :
- Centralisation des chemins avec `Path(__file__).parent`
- Utilisation systÃ©matique de chemins relatifs
- Un seul `data/` et un seul `output/`

---

### 4.2 Conflits Git lors des merges
**ProblÃ¨me** : fichiers gÃ©nÃ©rÃ©s suivis par Git (`.jsonl`, `.txt`, `__pycache__`, `.pyc`).

**Solution dÃ©finitive** :
- Nettoyage de lâ€™index Git
- Mise Ã  jour du `.gitignore`

```gitignore
# Python cache
__pycache__/
*.pyc

# Generated data
data/*.jsonl
data/*.json
output/*.txt
*.log
```

RÃ©sultat : merges propres et reproductibles.

---

### 4.3 ProblÃ¨mes dâ€™environnement Python
- Conflits spaCy / Typer / Click
- ModÃ¨les spaCy manquants

DÃ©cision : **stabilisation du pipeline existant**, sans ajout dâ€™amÃ©liorations expÃ©rimentales.

---

## 5. Tentative dâ€™amÃ©lioration : Custom NER (abandonnÃ©e)

Objectif initial :
- Annotation manuelle avec **Doccano**
- CrÃ©ation dâ€™un modÃ¨le NER personnalisÃ© (technologies : PyTorch, TensorFlow, FastAPIâ€¦)

Ce qui a Ã©tÃ© fait :
- DÃ©ploiement de Doccano via Docker
- CrÃ©ation dâ€™un projet dâ€™annotation (sequence labeling)

Raison de lâ€™abandon :
- Conflits dâ€™environnement
- Temps limitÃ©
- PrioritÃ© donnÃ©e Ã  la stabilitÃ© du pipeline principal

---

## 6. Ã‰tat final du projet

âœ… Pipeline fonctionnelle
âœ… Architecture propre et modulaire
âœ… Git propre (aucun fichier gÃ©nÃ©rÃ© versionnÃ©)
âœ… Rapport automatique reproductible

âŒ AmÃ©liorations avancÃ©es (Custom NER) reportÃ©es

---

## 7. Commande principale

Pour exÃ©cuter la veille :

```bash
python main.py
```

---

## 8. Conclusion

Le projet atteint son objectif principal : **une veille NLP automatisÃ©e, stable et maintenable**.

Les bases sont solides pour de futures extensions (NER custom, dashboards, orchestration), mais le socle actuel est fonctionnel et propre.

---

ğŸ“Œ *Rapport gÃ©nÃ©rÃ© Ã  des fins acadÃ©miques â€“ Projet NLP*

