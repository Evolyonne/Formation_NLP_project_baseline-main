{"title": "Linux kernel framework for PCIe device emulation, in userspace", "url": "https://github.com/cakehonolulu/pciem", "content": "Linux kernel framework for PCIe device emulation, in userspace", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["linux", "kernel", "framework", "for", "pcie", "devic", "emulation", "in", "userspace"], "num_tokens": 9, "token_loss_pct": 0.0, "normalized_content": "linux kernel framework for pcie device emulation in userspace"}
{"title": "UK consulting on bringing in social media ban for under 16s", "url": "https://www.bbc.com/news/articles/cgm4xpyxp7lo", "content": "UK consulting on bringing in social media ban for under 16s", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["uk", "consulting", "bringing", "in", "social", "media", "ban", "for", "under", "16"], "num_tokens": 10, "token_loss_pct": 9.09, "normalized_content": "uk consulting on bringing in social media ban for under 16s"}
{"title": "The Overcomplexity of the Shadcn Radio Button", "url": "https://paulmakeswebsites.com/writing/shadcn-radio-button/", "content": "The Overcomplexity of the Shadcn Radio Button", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["the", "overcomplexity", "of", "the", "shadcn", "radio", "button"], "num_tokens": 7, "token_loss_pct": 0.0, "normalized_content": "the overcomplexity of the shadcn radio button"}
{"title": "Level S4 solar radiation event", "url": "https://www.swpc.noaa.gov/news/g4-severe-geomagnetic-storm-levels-reached-19-jan-2026", "content": "Level S4 solar radiation event", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["level", "s4", "solar", "radiation", "event"], "num_tokens": 5, "token_loss_pct": 0.0, "normalized_content": "level s4 solar radiation event"}
{"title": "Increasing the performance of WebAssembly Text Format parser by 350%", "url": "https://blog.gplane.win/posts/improve-wat-parser-perf.html", "content": "Increasing the performance of WebAssembly Text Format parser by 350%", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["increasing", "the", "performance", "of", "webassembly", "text", "format", "parser", "by", "350"], "num_tokens": 10, "token_loss_pct": 0.0, "normalized_content": "increasing the performance of webassembly text format parser by 350"}
{"title": "Reticulum, a secure and anonymous mesh networking stack", "url": "https://github.com/markqvist/Reticulum", "content": "Reticulum, a secure and anonymous mesh networking stack", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["reticulum", "secure", "and", "anonymou", "mesh", "networking", "stack"], "num_tokens": 7, "token_loss_pct": 12.5, "normalized_content": "reticulum a secure and anonymous mesh networking stack"}
{"title": "King – man + woman is queen; but why? (2017)", "url": "https://p.migdal.pl/blog/2017/01/king-man-woman-queen-why/", "content": "King – man + woman is queen; but why? (2017)", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["king", "man", "woman", "i", "queen", "but", "why", "2017"], "num_tokens": 8, "token_loss_pct": 20.0, "normalized_content": "king  man  woman is queen but why 2017"}
{"title": "x86 prefixes and escape opcodes flowchart", "url": "https://soc.me/interfaces/x86-prefixes-and-escape-opcodes-flowchart.html", "content": "x86 prefixes and escape opcodes flowchart", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["x86", "prefixe", "and", "escape", "opcoder", "flowchart"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "x86 prefixes and escape opcodes flowchart"}
{"title": "Apple testing new App Store design that blurs the line between ads and results", "url": "https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/", "content": "Apple testing new App Store design that blurs the line between ads and results", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["apple", "testing", "new", "app", "store", "design", "that", "blur", "the", "line", "between", "ads", "and", "results"], "num_tokens": 14, "token_loss_pct": 0.0, "normalized_content": "apple testing new app store design that blurs the line between ads and results"}
{"title": "What came first: the CNAME or the A record?", "url": "https://blog.cloudflare.com/cname-a-record-order-dns-standards/", "content": "What came first: the CNAME or the A record?", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["what", "came", "first", "the", "cname", "the", "record"], "num_tokens": 7, "token_loss_pct": 22.22, "normalized_content": "what came first the cname or the a record"}
{"title": "Nanolang: A tiny experimental language designed to be targeted by coding LLMs", "url": "https://github.com/jordanhubbard/nanolang", "content": "Nanolang: A tiny experimental language designed to be targeted by coding LLMs", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["nanolang", "tiny", "experimental", "languag", "designed", "to", "b", "targeted", "by", "coding", "llm"], "num_tokens": 11, "token_loss_pct": 8.33, "normalized_content": "nanolang a tiny experimental language designed to be targeted by coding llms"}
{"title": "Scaling long-running autonomous coding", "url": "https://simonwillison.net/2026/Jan/19/scaling-long-running-autonomous-coding/", "content": "Scaling long-running autonomous coding", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["scaling", "long", "running", "autonomou", "coding"], "num_tokens": 5, "token_loss_pct": 16.67, "normalized_content": "scaling long-running autonomous coding"}
{"title": "Giving university exams in the age of chatbots", "url": "https://ploum.net/2026-01-19-exam-with-chatbots.html", "content": "Giving university exams in the age of chatbots", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["giving", "university", "examen", "in", "the", "age", "of", "chatbot"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "giving university exams in the age of chatbots"}
{"title": "The coming industrialisation of exploit generation with LLMs", "url": "https://sean.heelan.io/2026/01/18/on-the-coming-industrialisation-of-exploit-generation-with-llms/", "content": "The coming industrialisation of exploit generation with LLMs", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["the", "coming", "industrialisation", "of", "exploit", "generation", "with", "llms"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "the coming industrialisation of exploit generation with llms"}
{"title": "Notes on Apple's Nano Texture (2025)", "url": "https://jon.bo/posts/nano-texture/", "content": "Notes on Apple's Nano Texture (2025)", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["note", "apple'", "nano", "texture", "2025"], "num_tokens": 5, "token_loss_pct": 28.57, "normalized_content": "notes on apple's nano texture 2025"}
{"title": "3D printing my laptop ergonomic setup", "url": "https://www.ntietz.com/blog/3d-printing-my-laptop-ergonomic-setup/", "content": "3D printing my laptop ergonomic setup", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["3d", "printing", "my", "laptop", "ergonomic", "setup"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "3d printing my laptop ergonomic setup"}
{"title": "Nova Launcher added Facebook and Google Ads tracking", "url": "https://lemdro.id/post/lemdro.id/35049920", "content": "Nova Launcher added Facebook and Google Ads tracking", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["nover", "launcher", "added", "facebook", "and", "google", "ads", "tracking"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "nova launcher added facebook and google ads tracking"}
{"title": "British redcoat's lost memoir reveals realities of life as a disabled veteran", "url": "https://phys.org/news/2026-01-british-redcoat-lost-memoir-reveals.html", "content": "British redcoat's lost memoir reveals realities of life as a disabled veteran", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["british", "redcoat'", "lost", "memoir", "reveal", "realitier", "of", "life", "disabled", "veteran"], "num_tokens": 10, "token_loss_pct": 23.08, "normalized_content": "british redcoat's lost memoir reveals realities of life as a disabled veteran"}
{"title": "Show HN: Artificial Ivy in the Browser", "url": "https://da.nmcardle.com/grow", "content": "Show HN: Artificial Ivy in the Browser", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "artificial", "ivy", "in", "the", "browser"], "num_tokens": 7, "token_loss_pct": 0.0, "normalized_content": "show hn artificial ivy in the browser"}
{"title": "Porsche sold more electrified cars in Europe in 2025 than pure gas-powered cars", "url": "https://newsroom.porsche.com/en/2026/company/porsche-deliveries-2025-41516.html", "content": "Porsche sold more electrified cars in Europe in 2025 than pure gas-powered cars", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["porsche", "sold", "more", "electrified", "car", "in", "europe", "in", "2025", "than", "pur", "ger", "powered", "car"], "num_tokens": 14, "token_loss_pct": 6.67, "normalized_content": "porsche sold more electrified cars in europe in 2025 than pure gas-powered cars"}
{"title": "I was a top 0.01% Cursor user, then switched to Claude Code 2.0", "url": "https://blog.silennai.com/claude-code", "content": "I was a top 0.01% Cursor user, then switched to Claude Code 2.0", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["was", "top", "0.01", "cursor", "user", "then", "switched", "to", "claude", "code", "2.0"], "num_tokens": 11, "token_loss_pct": 15.38, "normalized_content": "i was a top 0.01 cursor user then switched to claude code 2.0"}
{"title": "Kahan on the 8087 and designing Intel's floating point (2016) [video]", "url": "https://www.youtube.com/watch?v=L-QVgbdt_qg", "content": "Kahan on the 8087 and designing Intel's floating point (2016) [video]", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["kahan", "the", "8087", "and", "designing", "intel'", "floating", "point", "2016", "video"], "num_tokens": 10, "token_loss_pct": 16.67, "normalized_content": "kahan on the 8087 and designing intel's floating point 2016 video"}
{"title": "Prediction markets are ushering in a world in which news becomes about gambling", "url": "https://www.theatlantic.com/technology/2026/01/america-polymarket-disaster/685662/", "content": "Prediction markets are ushering in a world in which news becomes about gambling", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["prediction", "market", "are", "ushering", "in", "world", "in", "which", "new", "become", "about", "gambling"], "num_tokens": 12, "token_loss_pct": 7.69, "normalized_content": "prediction markets are ushering in a world in which news becomes about gambling"}
{"title": "The assistant axis: situating and stabilizing the character of LLMs", "url": "https://www.anthropic.com/research/assistant-axis", "content": "The assistant axis: situating and stabilizing the character of LLMs", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["the", "assister", "axis", "situating", "and", "stabilizing", "the", "character", "of", "llm"], "num_tokens": 10, "token_loss_pct": 0.0, "normalized_content": "the assistant axis situating and stabilizing the character of llms"}
{"title": "Understanding ZFS Scrubs and Data Integrity", "url": "https://klarasystems.com/articles/understanding-zfs-scrubs-and-data-integrity/", "content": "Understanding ZFS Scrubs and Data Integrity", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["understanding", "zf", "scrub", "and", "dater", "integrity"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "understanding zfs scrubs and data integrity"}
{"title": "Show HN: E80: an 8-bit CPU in structural VHDL", "url": "https://github.com/Stokpan/E80", "content": "Show HN: E80: an 8-bit CPU in structural VHDL", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "e80", "an", "8-bit", "cpu", "in", "structural", "vhdl"], "num_tokens": 9, "token_loss_pct": 0.0, "normalized_content": "show hn e80 an 8-bit cpu in structural vhdl"}
{"title": "The microstructure of wealth transfer in prediction markets", "url": "https://www.jbecker.dev/research/prediction-market-microstructure", "content": "The microstructure of wealth transfer in prediction markets", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["the", "microstructure", "of", "wealth", "transfer", "in", "prediction", "market"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "the microstructure of wealth transfer in prediction markets"}
{"title": "Targeted Bets: An alternative approach to the job hunt", "url": "https://www.seanmuirhead.com/blog/targeted-bets", "content": "Targeted Bets: An alternative approach to the job hunt", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["targeted", "bet", "an", "alternative", "approach", "to", "the", "job", "hunt"], "num_tokens": 9, "token_loss_pct": 0.0, "normalized_content": "targeted bets an alternative approach to the job hunt"}
{"title": "From Nevada to Kansas by Glider", "url": "https://www.weglide.org/flight/978820", "content": "From Nevada to Kansas by Glider", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["from", "nevader", "to", "kanser", "by", "glider"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "from nevada to kansas by glider"}
{"title": "Face as a QR Code", "url": "https://bookofjoe2.blogspot.com/2025/12/your-face-as-qr-code.html", "content": "Face as a QR Code", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["face", "qr", "code"], "num_tokens": 3, "token_loss_pct": 40.0, "normalized_content": "face as a qr code"}
{"title": "I set all 376 Vim options and I'm still a fool", "url": "https://evanhahn.com/i-set-all-376-vim-options-and-im-still-a-fool/", "content": "I set all 376 Vim options and I'm still a fool", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["set", "all", "376", "vim", "option", "and", "i'", "still", "fool"], "num_tokens": 9, "token_loss_pct": 25.0, "normalized_content": "i set all 376 vim options and i'm still a fool"}
{"title": "How we made Python's packaging library 3x faster", "url": "https://iscinumpy.dev/post/packaging-faster/", "content": "How we made Python's packaging library 3x faster", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["how", "w", "made", "python'", "packaging", "library", "3x", "faster"], "num_tokens": 8, "token_loss_pct": 11.11, "normalized_content": "how we made python's packaging library 3x faster"}
{"title": "San Francisco coyote swims to Alcatraz", "url": "https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php", "content": "San Francisco coyote swims to Alcatraz", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["san", "francisco", "coyote", "swim", "to", "alcatraz"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "san francisco coyote swims to alcatraz"}
{"title": "Show HN: An interactive physics simulator with 1000’s of balls, in your terminal", "url": "https://github.com/minimaxir/ballin", "content": "Show HN: An interactive physics simulator with 1000’s of balls, in your terminal", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "an", "interactif", "physic", "simulator", "with", "1000s", "of", "balls", "in", "your", "terminal"], "num_tokens": 13, "token_loss_pct": 0.0, "normalized_content": "show hn an interactive physics simulator with 1000s of balls in your terminal"}
{"title": "Sending Data over Offline Finding Networks", "url": "https://cc-sw.com/find-my-and-find-hub-network-research/", "content": "Sending Data over Offline Finding Networks", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["sending", "dater", "over", "offline", "finding", "network"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "sending data over offline finding networks"}
{"title": "Conditions in the Intel 8087 floating-point chip's microcode", "url": "https://www.righto.com/2025/12/8087-microcode-conditions.html", "content": "Conditions in the Intel 8087 floating-point chip's microcode", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["condition", "in", "the", "intel", "8087", "floating", "point", "chip'", "microcode"], "num_tokens": 9, "token_loss_pct": 18.18, "normalized_content": "conditions in the intel 8087 floating-point chip's microcode"}
{"title": "Use Social Media Mindfully", "url": "https://danielleheberling.xyz/blog/mindful-social-media/", "content": "Use Social Media Mindfully", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["us", "social", "media", "mindfully"], "num_tokens": 4, "token_loss_pct": 0.0, "normalized_content": "use social media mindfully"}
{"title": "Show HN: Subth.ink – write something and see how many others wrote the same", "url": "https://subth.ink/", "content": "Show HN: Subth.ink – write something and see how many others wrote the same", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "subth.ink", "write", "something", "and", "se", "how", "many", "other", "wrote", "the", "same"], "num_tokens": 13, "token_loss_pct": 7.14, "normalized_content": "show hn subth.ink  write something and see how many others wrote the same"}
{"title": "F-16 Falcon Strike", "url": "https://webchrono.pl/F16FalconStrike/index.html", "content": "F-16 Falcon Strike", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["f-16", "falcon", "strik"], "num_tokens": 3, "token_loss_pct": 0.0, "normalized_content": "f-16 falcon strike"}
{"title": "Chatbot Psychosis", "url": "https://en.wikipedia.org/wiki/Chatbot_psychosis", "content": "Chatbot Psychosis", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["chatbot", "psychosi"], "num_tokens": 2, "token_loss_pct": 0.0, "normalized_content": "chatbot psychosis"}
{"title": "UK ministers launch consultation on whether to ban social media for under-16s", "url": "https://www.theguardian.com/uk-news/2026/jan/19/uk-ministers-launch-consultation-into-whether-to-ban-social-media-for-under-16s", "content": "UK ministers launch consultation on whether to ban social media for under-16s", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["uk", "minister", "launch", "consultation", "whether", "to", "ban", "social", "media", "for", "under-16"], "num_tokens": 11, "token_loss_pct": 8.33, "normalized_content": "uk ministers launch consultation on whether to ban social media for under-16s"}
{"title": "CSS Web Components for marketing sites (2024)", "url": "https://hawkticehurst.com/2024/11/css-web-components-for-marketing-sites/", "content": "CSS Web Components for marketing sites (2024)", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["cs", "web", "component", "for", "marketing", "site", "2024"], "num_tokens": 7, "token_loss_pct": 0.0, "normalized_content": "css web components for marketing sites 2024"}
{"title": "Legal Structures for Latin American Startups (2021)", "url": "https://latamlist.com/legal-structures-for-latin-american-startups/", "content": "Legal Structures for Latin American Startups (2021)", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["legal", "structure", "for", "latin", "american", "startups", "2021"], "num_tokens": 7, "token_loss_pct": 0.0, "normalized_content": "legal structures for latin american startups 2021"}
{"title": "Selling SaaS in Japan", "url": "https://embedworkflow.com/blog/what-saas-founders-should-know-about-entering-the-japanese-market/", "content": "Selling SaaS in Japan", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["selling", "saas", "in", "japan"], "num_tokens": 4, "token_loss_pct": 0.0, "normalized_content": "selling saas in japan"}
{"title": "Bypassing Gemma and Qwen safety with raw strings", "url": "https://teendifferent.substack.com/p/apply_chat_template-is-the-safety", "content": "Bypassing Gemma and Qwen safety with raw strings", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["bypassing", "gemma", "and", "qwen", "safety", "with", "raw", "string"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "bypassing gemma and qwen safety with raw strings"}
{"title": "Flux 2 Klein pure C inference", "url": "https://github.com/antirez/flux2.c", "content": "Flux 2 Klein pure C inference", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["flux", "klein", "pur", "inference"], "num_tokens": 4, "token_loss_pct": 33.33, "normalized_content": "flux 2 klein pure c inference"}
{"title": "Opening the AWS European Sovereign Cloud", "url": "https://aws.amazon.com/blogs/aws/opening-the-aws-european-sovereign-cloud/", "content": "Opening the AWS European Sovereign Cloud", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["opening", "the", "aws", "european", "sovereign", "cloud"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "opening the aws european sovereign cloud"}
{"title": "Show HN: Munimet.ro – ML-based status page for the local subways in SF", "url": "https://munimet.ro/", "content": "Show HN: Munimet.ro – ML-based status page for the local subways in SF", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "munimet.ro", "millilitre", "based", "statu", "pag", "for", "the", "local", "subways", "in", "sf"], "num_tokens": 13, "token_loss_pct": 13.33, "normalized_content": "show hn munimet.ro  ml-based status page for the local subways in sf"}
{"title": "Understanding C++ Ownership System", "url": "https://blog.aiono.dev/posts/understanding-c++-ownership-system.html", "content": "Understanding C++ Ownership System", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["understanding", "ownership", "system"], "num_tokens": 3, "token_loss_pct": 25.0, "normalized_content": "understanding c ownership system"}
{"title": "Show HN: Pipenet – A Modern Alternative to Localtunnel", "url": "https://pipenet.dev/", "content": "Show HN: Pipenet – A Modern Alternative to Localtunnel", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["show", "hn", "pipenet", "modern", "alternative", "to", "localtunnel"], "num_tokens": 7, "token_loss_pct": 22.22, "normalized_content": "show hn pipenet  a modern alternative to localtunnel"}
{"title": "Weight Transfer for RL Post-Training in under 2 seconds", "url": "https://research.perplexity.ai/articles/weight-transfer-for-rl-post-training-in-under-2-seconds", "content": "Weight Transfer for RL Post-Training in under 2 seconds", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["weight", "transfer", "for", "rl", "post-training", "in", "under", "second"], "num_tokens": 8, "token_loss_pct": 11.11, "normalized_content": "weight transfer for rl post-training in under 2 seconds"}
{"title": "Graphics In Flatland – 2D ray tracing [video]", "url": "https://www.youtube.com/watch?v=WYTOykSqf2Y", "content": "Graphics In Flatland – 2D ray tracing [video]", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["graphics", "in", "flatland", "2d", "ray", "tracing", "video"], "num_tokens": 7, "token_loss_pct": 12.5, "normalized_content": "graphics in flatland  2d ray tracing video"}
{"title": "Harvard legal scholars debate the state of the U.S. constitution (2025)", "url": "https://www.harvardmagazine.com/social-sciences/is-the-constitution-broken", "content": "Harvard legal scholars debate the state of the U.S. constitution (2025)", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["harvard", "legal", "scholar", "debate", "the", "stater", "of", "the", "u.s", "constitution", "2025"], "num_tokens": 11, "token_loss_pct": 8.33, "normalized_content": "harvard legal scholars debate the state of the u.s. constitution 2025"}
{"title": "Nearly a third of social media research has undisclosed ties to industry", "url": "https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims", "content": "Nearly a third of social media research has undisclosed ties to industry", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["nearly", "third", "of", "social", "media", "research", "ha", "undisclosed", "tier", "to", "industry"], "num_tokens": 11, "token_loss_pct": 8.33, "normalized_content": "nearly a third of social media research has undisclosed ties to industry"}
{"title": "Radboud University selects Fairphone as standard smartphone for employees", "url": "https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees", "content": "Radboud University selects Fairphone as standard smartphone for employees", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["radboud", "university", "select", "fairphone", "standard", "smartphone", "for", "employee"], "num_tokens": 8, "token_loss_pct": 11.11, "normalized_content": "radboud university selects fairphone as standard smartphone for employees"}
{"title": "Iterative image reconstruction using random cubic bézier strokes", "url": "https://tangled.org/luthenwald.tngl.sh/splined", "content": "Iterative image reconstruction using random cubic bézier strokes", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["iterative", "image", "reconstruction", "using", "random", "cubic", "bézier", "stroke"], "num_tokens": 8, "token_loss_pct": 0.0, "normalized_content": "iterative image reconstruction using random cubic bézier strokes"}
{"title": "Fix your robots.txt or your site disappears from Google", "url": "https://www.alanwsmith.com/en/37/wa/jz/s1/", "content": "Fix your robots.txt or your site disappears from Google", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["fi", "your", "robots.txt", "your", "site", "disappear", "from", "googl"], "num_tokens": 8, "token_loss_pct": 11.11, "normalized_content": "fix your robots.txt or your site disappears from google"}
{"title": "Go 1.26 Interactive Tour", "url": "https://antonz.org/go-1-26/", "content": "Go 1.26 Interactive Tour", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["go", "1.26", "interactif", "tour"], "num_tokens": 4, "token_loss_pct": 0.0, "normalized_content": "go 1.26 interactive tour"}
{"title": "Simple Sabotage Field Manual (1944) [pdf]", "url": "https://www.cia.gov/static/5c875f3ec660e092cf893f60b4a288df/SimpleSabotage.pdf", "content": "Simple Sabotage Field Manual (1944) [pdf]", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["simple", "sabotage", "field", "manual", "1944", "pdf"], "num_tokens": 6, "token_loss_pct": 0.0, "normalized_content": "simple sabotage field manual 1944 pdf"}
{"title": "Threads edges out X in daily mobile users, new data shows", "url": "https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/", "content": "Threads edges out X in daily mobile users, new data shows", "source": "HackerNews", "date": null, "author": null, "score": null, "tokens": ["threads", "edge", "out", "in", "daily", "mobile", "users", "new", "dater", "show"], "num_tokens": 10, "token_loss_pct": 9.09, "normalized_content": "threads edges out x in daily mobile users new data shows"}
{"title": "Issue #717: Unit Testing Performance, Cursor, Recursive match, and More (Jan. 13, 2026)", "url": "https://pycoders.com/issues/717", "content": "<p> <span>#717 – JANUARY 13, 2026</span><br /> <span><a href=\"https://pycoders.com/issues/717/feed\">View in Browser »</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s We", "source": "RSS", "date": "2026-01-13T19:30:00+00:00", "author": null, "score": null, "tokens": ["hashtag", "january", "13", "2026", "view", "in", "browser", "img", "altthe", "pycoderrsquo", "we"], "num_tokens": 11, "token_loss_pct": 15.38, "normalized_content": "hashtag  january 13 2026 view in browser  img altthe pycoderrsquos we"}
{"title": "Issue #716: Performance Numbers, async Web Apps, uv Speed, and More (Jan. 6, 2026)", "url": "https://pycoders.com/issues/716", "content": "<p> <span>#716 – JANUARY 6, 2026</span><br /> <span><a href=\"https://pycoders.com/issues/716/feed\">View in Browser »</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s Wee", "source": "RSS", "date": "2026-01-06T19:30:00+00:00", "author": null, "score": null, "tokens": ["hashtag", "january", "2026", "view", "in", "browser", "img", "altthe", "pycoderrsquos", "wee"], "num_tokens": 10, "token_loss_pct": 23.08, "normalized_content": "hashtag  january 6 2026 view in browser  img altthe pycoderrsquos wee"}
{"title": "Issue #715: Top 5 of 2025, LlamaIndex, Python 3.15 Speed, and More (Dec. 30, 2025)", "url": "https://pycoders.com/issues/715", "content": "<p> <span>#715 – DECEMBER 30, 2025</span><br /> <span><a href=\"https://pycoders.com/issues/715/feed\">View in Browser »</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s W", "source": "RSS", "date": "2025-12-30T19:30:00+00:00", "author": null, "score": null, "tokens": ["hashtag", "december", "30", "2025", "view", "in", "browser", "img", "altthe", "pycoderrsquos"], "num_tokens": 10, "token_loss_pct": 23.08, "normalized_content": "hashtag  december 30 2025 view in browser  img altthe pycoderrsquos w"}
{"title": "Traitement automatique des langues", "url": "https://fr.wikipedia.org/wiki/Traitement_automatique_des_langues", "content": "Le traitement automatique des langues (TAL ou TALN), en anglais natural language processing ou NLP, est un domaine multidisciplinaire impliquant la linguistique, l'informatique et l'intelligence artificielle, qui vise à créer des outils de traitement du langage naturel pour diverses applications. Il ne doit pas être confondu avec la linguistique informatique, qui vise à analyser les langues au moyen d'outils informatiques.\nLe TALN est sorti des laboratoires de recherche pour être progressivement mis en œuvre dans des applications informatiques nécessitant l'intégration du langage humain à la machine. Aussi le TALN est-il parfois appelé ingénierie linguistique.\n\nHistoire\nAnnées 1950-1960\nLes premiers travaux en traitement automatique du langage naturel commencent dans les années 1950, principalement aux États-Unis où le contexte politique, lié à la guerre froide, est propice au développement de la thématique de la traduction automatique.\nLes premières applications informatiques sont liées au traitement automatique des conversations. En 1950, dans son article fondateur de l'intelligence artificielle, « Computing machinery and intelligence », Alan Turing expose une méthode d'évaluation qui sera appelée par la suite « test de Turing » ou « critère de Turing ». Ce test mesure le degré d'intelligence d'une machine, à partir de la capacité d'un programme conversationnel à se faire passer pour un être humain : dans un échange de messages écrits, un sujet humain doit déterminer si son interlocuteur est une machine ou non. La base employée est cependant fragile pour évaluer l'intelligence artificielle, car l'impression d'un unique utilisateur dépend de trop de facteurs liés au milieu ambiant pour être érigée en règle.\nEn 1954, l'expérience Georgetown-IBM, réalisée conjointement par l'université de Georgetown et par la société IBM, comporte la traduction complètement automatique, en anglais, de plus de soixante phrases russes romanisées relatives aux domaines de la politique, du droit, des mathématiques et de la science. Les auteurs prétendent que dans un délai de trois à cinq ans, la traduction automatique ne sera plus un problème. Il apparaît cependant que les énoncés en russe ont été choisis avec soin et que nombre des opérations effectuées pour la démonstration ont été adaptées à des mots et des phrases particuliers. De plus, il n'y a pas d'analyse relationnelle ou syntaxique permettant d'identifier la structure des phrases. La méthode employée est une méthode essentiellement lexicographique reposant sur un dictionnaire où un mot donné est relié à des règles et des démarches spécifiques.\nLes notions introduites par Turing permirent à Joseph Weizenbaum de mettre au point, de 1964 à 1966, le premier automate conversationnel à tromper un être humain quant à sa nature. Simulant un psychothérapeute rogérien, l'automate, du nom d'ELIZA, bien que n'employant presque aucune information sur la pensée ou l'émotion humaine, parvient parfois à établir une interaction étonnamment similaire à l'interaction humaine. Ainsi, quand le « patient » dépasse les faibles capacités de la base de connaissances, ELIZA peut fournir une réponse générique, comme « Pourquoi dites-vous avoir mal à la tête ? » en réponse à « J'ai mal à la tête ».\nÀ la fin des années 1960, Terry Winograd, un chercheur du MIT, met au point un programme en langage naturel du nom de SHRDLU (prononcer « chreudeul »), qui permet à son utilisateur de converser avec un ordinateur pour gérer un « monde de cubes de construction » (a blocks world) s'affichant sur un des premiers écrans. C’est le premier programme qui sache comprendre et exécuter des ordres complexes en langage naturel. Mais les seules opérations qu'il peut faire, c’est de prendre des cubes, les déplacer, les rassembler ou les disperser. Il ne pourra jamais comprendre tout ce que les humains peuvent faire avec des objets physiques.\nLes progrès réels sont donc décevants. Le rapport ALPAC (en) de 1966 constate qu'en dix ans de recherches les buts n'ont pas été atteints. Cette prise de conscience de l'extrême complexité des langues a considérablement réduit l'ambition des travaux de recherche.\n\nAnnées 1970-1980\nPendant les années 1970 beaucoup de programmeurs ont commencé à écrire des « ontologies conceptuelles », dont le but était de structurer l'information en données compréhensibles par l'ordinateur. C'est le cas de MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), SCRUPULE (Lehnert, 1977), Politics (Carbonell, 1979), Plot Units (Lehnert, 1981).\n\nAnnées 1990-2000\nDepuis les années 2010\nEn janvier 2018, des modèles d'intelligence artificielle développés par Microsoft et Alibaba réussissent chacun de leur côté à battre les humains dans un test de lecture et de compréhension de l’université Stanford. Le traitement automatique du langage naturel imite la compréhension humaine des mots et des phrases et permet maintenant aux modèles d'apprentissage automatique de trai", "source": "Wikipedia", "date": null, "author": null, "score": null, "tokens": ["traitement", "automatique", "langue", "tal", "taln", "anglais", "natural", "languag", "processing", "nlp", "domaine", "multidisciplinaire", "impliquer", "linguistique", "informatique", "intelligence", "artificiel", "viser", "créer", "outil", "traitement", "langage", "naturel", "application", "confondre", "linguistique", "informatique", "viser", "analyser", "langue", "moyen", "outil", "informatique", "taln", "sortir", "laboratoire", "recherche", "progressivemer", "mettre", "œuvre", "application", "informatique", "nécessiter", "intégration", "langage", "humain", "machine", "taln", "il", "appeler", "ingénierie", "linguistique", "histoire", "anner", "1950", "1960", "premier", "travail", "traitement", "automatique", "langage", "naturel", "commencer", "année", "1950", "principalement", "états-unis", "contexte", "politique", "lier", "guerre", "froid", "propice", "développement", "thématique", "traduction", "automatique", "premier", "application", "informatique", "lier", "traitement", "automatique", "conversation", "1950", "article", "fondateur", "intelligence", "artificiel", "computing", "machinery", "and", "intelligence", "alan", "turing", "expose", "méthode", "évaluation", "appeler", "suite", "test", "turing", "critère", "turing", "test", "mesure", "degré", "intelligence", "machine", "partir", "capacité", "programme", "conversationnel", "faire", "passer", "humain", "échange", "message", "écrire", "sujet", "humain", "déterminer", "interlocuteur", "machine", "non", "base", "employer", "fragile", "évaluer", "intelligence", "artificiel", "impression", "unique", "utilisateur", "dépendre", "trop", "facteur", "lier", "milieu", "ambier", "ériger", "régler", "1954", "expérience", "georgetown", "ibm", "réaliser", "conjointemer", "université", "georgetown", "société", "ibm", "comporte", "traduction", "complètement", "automatique", "anglais", "phrase", "russe", "romaniser", "relatif", "domaine", "politique", "droit", "mathématique", "science", "auteur", "prétendre", "délai", "an", "traduction", "automatique", "problème", "apparaître", "énoncé", "russe", "être", "choisir", "soin", "nombre", "opération", "effectuer", "démonstration", "être", "adapter", "mot", "phrase", "particulier", "analyse", "relationnel", "syntaxique", "permettre", "identifier", "structure", "phrase", "méthode", "employer", "méthod", "essentiellement", "lexicographique", "reposer", "dictionnaire", "mot", "donner", "relier", "règle", "démarche", "notion", "introduire", "turing", "permettre", "joseph", "weizenbaum", "mettre", "point", "1964", "1966", "automate", "conversationnel", "tromper", "humain", "nature", "simuler", "psychothérapeute", "rogérien", "automate", "nom", "eliza", "bien", "employer", "presque", "aucun", "information", "pensée", "émotion", "humain", "parvenir", "établir", "interaction", "étonnammer", "similaire", "interaction", "humain", "patient", "dépasser", "faible", "capacité", "base", "connaissance", "eliza", "fournir", "réponse", "générique", "dire", "vous", "mal", "tête", "  ", "réponse", "mal", "tête", "fin", "année", "1960", "terry", "winograd", "chercheur", "mit", "mettre", "point", "programme", "langage", "naturel", "nom", "shrdlu", "prononcer", "chreudeul", "utilisateur", "converser", "ordinateur", "gérer", "monde", "cube", "construction", "block", "world", "afficher", "premier", "écran", "cest", "programme", "savoir", "comprendre", "exécuter", "ordre", "complexe", "langage", "naturel", "opération", "faire", "cest", "prendre", "cube", "déplacer", "rassembler", "disperser", "pouvoir", "jamais", "comprendre", "humain", "faire", "objet", "physique", "progrès", "réel", "décevant", "rapport", "alpac", "1966", "constater", "an", "recherche", "but", "être", "atteindre", "prise", "conscience", "extrême", "complexité", "langue", "considérablement", "réduire", "ambition", "travail", "recherche", "année", "1970", "1980", "année", "1970", "beaucoup", "programmeur", "commencer", "écrire", "ontologie", "conceptuel", "but", "structurer", "information", "donnée", "compréhensibler", "ordinateur", "cas", "margie", "schank", "1975", "sam", "cullingford", "1978", "pam", "wilensky", "1978", "talespin", "meehan", "1976", "scrupul", "lehnert", "1977", "politic", "carbonell", "1979", "plot", "units", "lehnert", "1981", "année", "1990", "2000", "année", "2010", "janvier", "2018", "modèle", "intelligence", "artificiel", "développer", "microsoft", "alibaber", "réussir", "côté", "battr", "humain", "test", "lecture", "compréhension", "luniversité", "stanford", "traitement", "automatique", "langage", "naturel", "imit", "compréhension", "humain", "mot", "phrase", "modèle", "apprentissage", "automatique", "trai"], "num_tokens": 410, "token_loss_pct": 50.54, "normalized_content": "le traitement automatique des langues tal ou taln en anglais natural language processing ou nlp est "}
{"title": "Apprentissage automatique", "url": "https://fr.wikipedia.org/wiki/Apprentissage_automatique", "content": "L'apprentissage automatique (en anglais : machine learning, litt. « apprentissage machine »), apprentissage artificiel ou apprentissage statistique est un champ d'étude de l'intelligence artificielle qui se fonde sur des approches mathématiques et statistiques pour donner aux ordinateurs la capacité d'« apprendre » à partir de données, c'est-à-dire d'améliorer leurs performances à résoudre des tâches sans être explicitement programmés pour chacune. Plus largement, il concerne la conception, l'analyse, l'optimisation, le développement et l'implémentation de telles méthodes. On parle d'apprentissage statistique car l'apprentissage consiste à créer un modèle dont l'erreur statistique moyenne est la plus faible possible.\nL'apprentissage automatique comporte généralement deux phases. La première consiste à estimer un modèle à partir de données, appelées observations, qui sont disponibles et en nombre fini, lors de la phase de conception du système. L'estimation du modèle consiste à résoudre une tâche pratique, telle que traduire un discours, estimer une densité de probabilité, reconnaître la présence d'un chat dans une photographie ou participer à la conduite d'un véhicule autonome. Cette phase dite « d'apprentissage » ou « d'entraînement » est généralement préalable à l'utilisation pratique du modèle. La seconde phase est la mise en production : le modèle étant déterminé, de nouvelles données peuvent alors être soumises afin d'obtenir le résultat correspondant à la tâche souhaitée. \nCertains systèmes peuvent continuer à apprendre une fois en production, s'ils disposent d'un retour sur la qualité des résultats produits. C'est l'apprentissage en ligne, ou l'apprentissage continu.\nSelon le type de données utilisées pour l'apprentissage, on distingue :\n\nl'apprentissage supervisé : l'algorithme apprend à partir de données étiquetées (la réponse à la tâche, qui est la donnée de sortie, est donc connue pour chaque données d'entrée). L'objectif est de prédire les sorties pour de nouvelles données ;\nl'apprentissage non supervisé : l'algorithme apprend à partir de données non étiquetées. Il cherche à découvrir des structures sous-jacentes, cachées (qui peuvent par exemple être une densité de probabilité) ; des motifs dans les données permettent la classification ou le classement des données ;\nl'apprentissage semi-supervisé : il tire parti d'une grande quantité de données non étiquetées pour améliorer la performance du modèle, tout en utilisant une moindre quantité de données étiquetées pour guider son apprentissage. Il diminue les coûts d'étiquetage manuel des données ;\nl'apprentissage auto-supervisé : c'est une forme d'apprentissage non supervisé, où le modèle génère ses propres étiquettes à partir des données brutes. Le modèle peut ainsi créer des représentations internes utiles, sans nécessiter de données étiquetées manuellement.\nL'apprentissage automatique peut être appliqué à divers types de données, tels des graphes, des arbres, des courbes, ou plus simplement des vecteurs de caractéristiques, qui peuvent être des variables qualitatives ou quantitatives continues ou discrètes.\nSi le modèle apprend de manière incrémentale, en fonction d'une récompense reçue par le programme pour chacune des actions entreprises, on parle d'apprentissage par renforcement.\n\nHistorique\nDepuis l'antiquité, le sujet des machines pensantes préoccupe les esprits. Ce concept est la base de pensées pour ce qui deviendra ensuite l'intelligence artificielle, ainsi qu'une de ses sous-branches : l'apprentissage automatique.\nLa concrétisation de cette idée est principalement due à Alan Turing (mathématicien et cryptologue britannique) et à son concept de la « machine universelle » en 1936, qui est à la base des ordinateurs d'aujourd'hui. Il continuera à poser les bases de l'apprentissage automatique, avec son article sur « L'ordinateur et l'intelligence » en 1950, dans lequel il développe, entre autres, le test de Turing.\nEn 1943, le neurophysiologiste Warren McCulloch et le mathématicien Walter Pitts publient un article décrivant le fonctionnement de neurones en les représentant à l'aide de circuits électriques. Cette représentation sera la base théorique des réseaux neuronaux.\nArthur Samuel, informaticien américain pionnier dans le secteur de l'intelligence artificielle, est le premier à faire usage de l'expression machine learning (en français, « apprentissage automatique ») en 1959 à la suite de la création de son programme pour IBM en 1952. Le programme jouait au Jeu de Dames et s'améliorait en jouant. À terme, il parvint à battre le 4e meilleur joueur des États-Unis.\nUne avancée majeure dans le secteur de l'intelligence machine est le succès de l'ordinateur développé par IBM, Deep Blue, qui est le premier à vaincre le champion mondial d'échecs Garry Kasparov en 1997. Le projet Deep Blue en inspirera nombre d'autres dans le cadre de l'intelligence artificielle, particulièrement un autre grand défi : IBM Watson, l'ordinateur dont le but est de", "source": "Wikipedia", "date": null, "author": null, "score": null, "tokens": ["apprentissage", "automatique", "anglais", "machine", "learning", "litt", "apprentissage", "machine", "apprentissage", "artificiel", "apprentissage", "statistique", "champ", "étude", "intelligence", "artificiel", "fondre", "approche", "mathématique", "statistique", "donner", "ordinateur", "capacité", "apprendre", "partir", "donnée", "améliorer", "performance", "résoudre", "tâche", "explicitement", "programmer", "largement", "concerner", "conception", "analyse", "optimisation", "développement", "implémentation", "méthode", "apprentissage", "statistique", "apprentissage", "consister", "créer", "modèle", "erreur", "statistique", "moyen", "faible", "apprentissage", "automatique", "comporte", "généralement", "phase", "consister", "estimer", "modèle", "partir", "donnée", "appeler", "observation", "disponible", "nombre", "finir", "phase", "conception", "système", "estimation", "modèle", "consister", "résoudre", "tâche", "pratique", "traduire", "discours", "estimer", "densité", "probabilité", "reconnaître", "présence", "chat", "photographie", "participer", "conduite", "véhicule", "autonome", "phase", "apprentissage", "entraînement", "généralement", "utilisation", "pratique", "modèle", "second", "phase", "mise", "production", "modèle", "déterminé", "nouveau", "donnée", "soumettre", "obtenir", "résultat", "correspondre", "tâche", "souhaiter", "système", "continuer", "apprendre", "fois", "production", "disposer", "qualité", "résultat", "produire", "apprentissage", "ligne", "apprentissage", "continu", "type", "donnée", "utiliser", "apprentissage", "distinguer", "apprentissage", "superviser", "algorithme", "apprendre", "partir", "donnée", "étiqueter", "réponse", "tâche", "donnée", "sortie", "connaître", "donnée", "entrée", "objectif", "prédir", "sortie", "nouveau", "donnée", "apprentissage", "non", "superviser", "algorithme", "apprendre", "partir", "donnée", "non", "étiqueter", "cherche", "découvrir", "structure", "sous-jacent", "cacher", "exemple", "densité", "probabilité", "motif", "donnée", "permettre", "classification", "classement", "donnée", "apprentissage", "semi-superviser", "tire", "partir", "grand", "quantité", "donnée", "non", "étiqueter", "améliorer", "performance", "modèle", "utiliser", "moindre", "quantité", "donnée", "étiqueter", "guider", "apprentissage", "diminuer", "coût", "étiquetage", "manuel", "donnée", "apprentissage", "auto-supervisé", "forme", "apprentissage", "non", "superviser", "modèle", "générer", "propre", "étiquette", "partir", "donnée", "brut", "modèle", "créer", "représentation", "interne", "utile", "nécessiter", "donnée", "étiqueter", "manuellemer", "apprentissage", "automatique", "appliquer", "type", "donnée", "graphe", "arbre", "courbe", "simplement", "vecteur", "caractéristique", "variable", "qualitatif", "quantitative", "continu", "discret", "modèle", "apprendre", "manière", "incrémental", "fonction", "récompense", "recevoir", "programme", "action", "entrepris", "apprentissage", "renforcement", "historique", "antiquité", "sujet", "machine", "pensant", "préoccuper", "esprit", "concept", "base", "pensée", "devenir", "ensuite", "intelligence", "artificiel", "sous-branche", "apprentissage", "automatique", "concrétisation", "idée", "principalement", "devoir", "alan", "turing", "mathématicien", "cryptologue", "britannique", "concept", "machine", "universel", "1936", "base", "ordinateur", "aujourd'hui", "continuer", "poser", "base", "apprentissage", "automatique", "article", "ordinateur", "intelligence", "1950", "développer", "test", "turing", "1943", "neurophysiologiste", "warren", "mcculloch", "mathématicien", "walter", "pitt", "publier", "article", "décrire", "fonctionnement", "neurone", "représentant", "aide", "circuit", "électrique", "représentation", "base", "théorique", "réseau", "neuronal", "arthur", "samuel", "informaticien", "américain", "pionnier", "secteur", "intelligence", "artificiel", "faire", "usage", "expression", "machine", "learning", "français", "apprentissage", "automatique", "1959", "suite", "création", "programme", "ibm", "1952", "programme", "jouer", "jeu", "dame", "améliorer", "jouant", "terme", "parvenir", "battre", "4e", "meilleur", "joueur", "états-unis", "avancée", "majeur", "secteur", "intelligence", "machine", "succès", "ordinateur", "développé", "ibm", "deep", "blu", "vaincre", "champion", "mondial", "échec", "garry", "kasparov", "1997", "projet", "deep", "blue", "inspirer", "nombre", "cadre", "intelligence", "artificiel", "particulièrement", "grand", "défi", "ibm", "watson", "ordinateur", "but"], "num_tokens": 376, "token_loss_pct": 54.15, "normalized_content": "l'apprentissage automatique en anglais  machine learning litt.  apprentissage machine  apprentissage"}
{"title": "Apprentissage profond", "url": "https://fr.wikipedia.org/wiki/Apprentissage_profond", "content": "L'apprentissage profond ou apprentissage en profondeur (en anglais : deep learning) est un sous-domaine de l’intelligence artificielle qui utilise des réseaux neuronaux artificiels formant de nombreuses couches pour résoudre des tâches complexes. L'apprentissage profond permet des progrès importants et rapides dans les domaines de l'analyse du signal sonore ou visuel, notamment de la reconnaissance faciale, de la reconnaissance vocale, de la vision par ordinateur, du traitement automatisé du langage. Les développements de l'apprentissage profond sont rendus possibles par des investissements privés et publics importants, notamment de la part des GAFAM (Google, Apple, Facebook, Amazon, Microsoft), durant les années 2000.\n\nDéfinition\nPour créer un modèle informatique prédictif de manière classique, on modélise les données par extraction de caractéristiques, cette dernière étant souvent effectuée au moyen d'un algorithme. Selon la méthode de l'apprentissage profond, l'extraction de caractéristiques résulte elle-même d'un processus d'apprentissage : on parle donc d'apprentissage de représentations. En pratique, la machine apprend des représentations hiérarchisées, souvent dans les couches cachées de réseaux de neurones artificiels, chacune étant définie à partir de représentations plus simples. Ces représentations étant apprises directement à partir des données, cela évite que les humains aient à expliciter la manière de les construire au moyen d'un algorithme. Si l'on représente la manière dont ces représentations sont construites les unes à partir des autres au moyen d'un graphe, celui-ci contiendra de multiples couches, justifiant ainsi la qualification de « profond ».\n\nHistorique\nL'apprentissage profond est considéré comme « la troisième vague » de développement, après le « cybernétique » des années 1940-1960, puis le « connexionniste »  des années 1980, chacun ayant été suivi par un hiver de l'intelligence artificielle.\nLe concept d'apprentissage profond prend forme dans les années 2010, avec la convergence de trois facteurs :\n\ndes avancées théoriques, notamment dues à Geoffrey Hinton, qui a proposé des approches de pré-entraînement permettant d'apprendre des architectures profondes ;\nle phénomène de Big data, qui a permis la mise à disposition de volumes colossaux de données numériques, nécessaires pour apprendre les architectures profondes ;\nl'avènement du GPGPU, consistant à effectuer des calculs génériques et utiles pour l'apprentissage d'architectures profondes au moyen de processeurs graphiques qui accélèrent les calculs.\nEn 2012, le modèle AlexNet, conçu par Alex Krizhevsky, Ilya Sutskever et leur directeur de thèse Geoffrey Hinton, obtient les meilleures performances lors de la campagne d'évaluation internationale ImageNet de reconnaissance d'images. Le réseau surpasse largement le deuxième et popularise ainsi les approches par apprentissage profond en vision par ordinateur.\nEn 2015, le programme AlphaGo, un modèle neuronal profond qui a « appris » à jouer au jeu de go grâce à l'apprentissage par renforcement, bat le champion européen Fan Hui par cinq parties à zéro. En mars 2016, le même programme bat le champion du monde Lee Sedol par 4 parties à 1. Ces matches ont eu un fort retentissement dans le grand public, en particulier en Asie.\nEn 2017, à la conférence NIPS, des chercheurs travaillant pour la plupart dans des équipes de recherche de Google proposent l'architecture transformeur, qui servira peu de temps après de base aux grands modèles de langage. L'année suivante, l'entreprise propose le modèle BERT, basée sur la partie « encodeur » du transformeur. Ce modèle de langage permettra une amélioration significative des performances en traitement automatique des langues. La même année, OpenAI propose le modèle GPT, qui est pour sa part fondé sur la partie « décodeur » des transformeurs.\nEn 2018, Yann Le Cun, Yoshua Bengio et Geoffrey Hinton sont récipiendaires du prix Turing « Pour les percées conceptuelles et techniques qui ont fait des réseaux neuronaux profonds une composante essentielle de l'informatique ». \nEn 2019, OpenAI publie GPT-2, un modèle de fondation capable de générer du texte. Tout en exprimant leurs inquiétudes sur les détournements possibles de ce type de technologie, les chercheurs de l'association renoncent à partager la version complète.\n\nDomaines d'application\nL'apprentissage profond s'applique à divers secteurs des NTIC, notamment :\n\nen vision par ordinateur, la reconnaissance de formes visuelles, par exemple la reconnaissance d'un panneau de signalisation par un robot ou une voiture autonome, ou la reconnaissance d'emplacements dans une image en combinant ses caractéristiques, comme un lit, une fenêtre et des affiches peuvent indiquer une chambre. Elle aide à prédire certaines propriétés (ex. : les propriétés d'un sol filmé par un robot) ;\nla reconnaissance ou la comparaison de formes ou d'objets hautement déformables ;\nl'analyse de mouvements et positions des doigts d'un", "source": "Wikipedia", "date": null, "author": null, "score": null, "tokens": ["apprentissage", "profond", "apprentissage", "profondeur", "anglais", "deep", "learning", "sous-domaine", "lintelligence", "artificiel", "utiliser", "réseau", "neuronal", "artificiel", "former", "couche", "résoudre", "tâche", "complexe", "apprentissage", "profond", "progrès", "important", "rapide", "domaine", "analyse", "signal", "sonore", "visuel", "reconnaissance", "facial", "reconnaissance", "vocal", "vision", "ordinateur", "traitement", "automatiser", "langage", "développement", "apprentissage", "profond", "rendre", "investissement", "priver", "public", "important", "part", "gafam", "google", "apple", "facebook", "amazon", "microsoft", "année", "2000", "définition", "créer", "modèle", "informatique", "prédictif", "manière", "classique", "modélise", "donnée", "extraction", "caractéristique", "dernier", "effectuer", "moyen", "algorithme", "méthode", "apprentissage", "profond", "extraction", "caractéristique", "résulter", "processus", "apprentissage", "apprentissage", "représentation", "pratique", "machine", "apprendre", "représentation", "hiérarchiser", "couche", "cacher", "réseau", "neurone", "artificiel", "définir", "partir", "représentation", "simple", "représentation", "apprendre", "partir", "donnée", "éviter", "humain", "avoir", "expliciter", "manière", "construire", "moyen", "algorithme", "représenter", "manière", "représentation", "construire", "partir", "moyen", "graphe", "contenir", "multiple", "couche", "justifier", "qualification", "profond", "historique", "apprentissage", "profond", "considérer", "vague", "développement", "cybernétique", "année", "1940", "1960", "connexionniste", "année", "1980", "être", "suivre", "hiver", "intelligence", "artificiel", "concept", "apprentissage", "profond", "prendre", "forme", "année", "2010", "convergence", "facteur", "avancée", "théorique", "devoir", "geoffrey", "hinton", "proposer", "approche", "pré-entraînement", "permettre", "apprendre", "architecture", "profonde", "phénomène", "big", "dater", "permettre", "mise", "disposition", "volume", "colossal", "donnée", "numérique", "nécessaire", "apprendre", "architecture", "profonde", "avènement", "gpgpu", "consister", "effectuer", "calcul", "générique", "utile", "apprentissage", "architecture", "profonde", "moyen", "processeur", "graphique", "accélérer", "calcul", "2012", "modèle", "alexnet", "concevoir", "ale", "krizhevsky", "ilya", "sutskever", "directeur", "thèse", "geoffrey", "hinton", "obtenir", "meilleur", "performance", "campagne", "évaluation", "international", "imagenet", "reconnaissance", "image", "réseau", "surpasser", "largement", "popularise", "approche", "apprentissage", "profond", "vision", "ordinateur", "2015", "programme", "alphago", "modèle", "neuronal", "profond", "apprendre", "jouer", "jeu", "go", "grâce", "apprentissage", "renforcement", "champion", "européen", "fan", "party", "zéro", "mars", "2016", "programme", "champion", "monde", "lee", "sedol", "party", "match", "fort", "retentissement", "grand", "public", "particulier", "asie", "2017", "conférence", "nip", "chercheur", "travailler", "plupart", "équipe", "recherche", "google", "proposer", "architecture", "transformeur", "servir", "temps", "base", "grand", "modèle", "langage", "année", "entreprise", "proposer", "modèle", "bert", "baser", "partie", "encodeur", "transformeur", "modèle", "langage", "permettre", "amélioration", "significatif", "performance", "traitement", "automatique", "langue", "année", "opener", "proposer", "modèle", "gpt", "part", "fonder", "partie", "décodeur", "transformeur", "2018", "yann", "cun", "yoshua", "bengio", "geoffrey", "hinton", "récipiendairer", "prix", "turing", "percée", "conceptuel", "technique", "réseau", "neuronal", "profond", "composant", "essentielle", "informatique", "2019", "openai", "publier", "gpt-2", "modèle", "fondation", "capable", "générer", "texte", "exprimer", "inquiétude", "détournement", "type", "technologie", "chercheur", "association", "renoncer", "partager", "version", "complet", "domaine", "application", "apprentissage", "profond", "applique", "secteur", "ntic", "vision", "ordinateur", "reconnaissance", "forme", "visuel", "exemple", "reconnaissance", "panneau", "signalisation", "robot", "voiture", "autonome", "reconnaissance", "emplacement", "image", "combiner", "caractéristique", "lit", "fenêtre", "affiche", "indiquer", "chambre", "aide", "prédir", "propriété", "ex", "propriété", "sol", "filmer", "robot", "reconnaissance", "comparaison", "forme", "objet", "hautement", "déformabler", "analyse", "mouvement", "position", "doigt"], "num_tokens": 382, "token_loss_pct": 52.01, "normalized_content": "l'apprentissage profond ou apprentissage en profondeur en anglais  deep learning est un sous-domaine"}
