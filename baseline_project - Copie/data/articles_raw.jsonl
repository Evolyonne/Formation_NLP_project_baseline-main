{"title": "EU‚ÄìINC ‚Äì One Europe. One Standard. ‚Äì Pan-European Legal Entity", "url": "https://www.eu-inc.org/", "content": "Petition Proposal Supporters How you can help FAQ Merch Petition Proposal Supporters How you can help FAQ Merch Petition Proposal Supporters How you can help FAQ Merch WHAT IS EU√¢¬Ä¬ìINC One new pan-European legal entity One central EU-level registry Standardized investment documents Standardized EU-wide stock options Local taxes & employment For every founder We are already working with Brussels. This can become reality. But we need your help! Read the in-detail proposal , made in collaboration with the best startup legal teams, funds and founders in Europe. Welcome to improving europe Why the EU√¢¬Ä¬ìINC? Europe has the talent, ambition, and ecosystems to create innovative companies, but fragmentation between European nations is holding us back.  \"A startup from California can expand and raise money all across the United States. But our companies still face way too many national barriers that make it hard to work Europa-wide, and way too much regulatory burden.\" √¢¬Ä¬ì Ursula von der Leyen, Oct 2024 Political Will Will this actually happen? Yes! But we need your help!  So far, we submitted our proposal to Justice Commissioner McGrath and Startup Commissioner Zaharieva.  President Von der Leyen has setup a dedicated working group in the Commission with whom we are in regular contact.  Additionally, the European Council and Parliament have each signaled interest in the EU√¢¬Ä¬ìINC, or what in Brussel is called the \"28th regime\" (for 28th virtual state). ROADMAP What comes next? The entire community is currently influencing the upcoming European Commission legislative proposal for a pan-European legal entity which is set to be released in Q1 2026. We need your help, see below!  Afterwards, the European Parliament and the European Council (made up of the 27 national governments) agree on the legislative details. The final implementation of the EU√¢¬Ä¬ìINC would then happen in 2027.  For more details of what happened so far and what comes next, read our roadmap . Join US How you can", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Vibecoding #2", "url": "https://matklad.github.io/2026/01/20/vibecoding-2.html", "content": "I feel like I got substantial value out of Claude today, and want to\n          document it. I am at the tail end of AI adoption, so I don‚Äôt expect to\n          say anything particularly useful or novel. However, I am constantly\n          complaining about the lack of boring AI posts, so it‚Äôs only proper if\n          I write one. At TigerBeetle, we are big on deterministic simulation testing . We even use it to track performance , to some degree. Still, it is crucial to\n            verify performance numbers on a real cluster in its natural\n            high-altitude habitat. To do that, you need to procure six machines in a cloud, get your\n            custom version of tigerbeetle binary on them, connect cluster‚Äôs replicas together and hit them\n            with load. It feels like, quarter of a century into the third\n            millennium, ‚Äúrun stuff on six machines‚Äù should be a problem just a\n            notch harder than opening a terminal and typing ls , but\n            I personally don‚Äôt know how to solve it without wasting a day. So, I\n            spent a day vibecoding my own square wheel. The general shape of the problem is that I want to spin a\n            fleet of ephemeral machines with given specs on demand and run\n            ad-hoc commands in a SIMD fashion on them. I don‚Äôt want to manually\n            type slightly different commands into a six-way terminal split, but\n            I also do want to be able to ssh into a specific box and poke it\n            around. My idea for the solution comes from these three sources: The big idea of rsyscall is that you can program\n            distributed system in direct style. When programming locally, you do\n            things by issuing syscalls: This API works for doing things on remote machines, if you specify\n            which machine you want to run the syscall on: Direct manipulation is the most natural API, and it pays to extend\n            it over the network boundary. Peter‚Äôs post is an application of a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "SETI@home is in hiberation", "url": "https://setiathome.berkeley.edu/", "content": "Thanks to everyone for your support over the years.\n        We encourage you to keep crunching for science . SETI@home is a scientific experiment,\nbased at UC Berkeley ,\nthat uses Internet-connected computers in the Search for\nExtraterrestrial Intelligence (SETI). You can participate by\nrunning a free program that downloads and analyzes radio\ntelescope data. Already joined? Log in . Already joined? Log in . SETI@home papers accepted for publication Two papers on SETI@home will be published in The Astronomical Journal , a well-regarded scientific journal: SETI@home: Data Acquisition and Front-End Processing describes SETI@home's data recorder, splitter, and client program.  It covers the five detection types, their parameters and statistics, and the algorithm for finding them. SETI@home: Data Analysis and Findings describes the back end (Nebula) and its results: RFI removal, candidate finding and ranking.  It explains how artificial signals, or 'birdies', were used to optimize algorithms and estimate overall sensitivity. For details, see an entry in the Nebula blog . 18 Jun 2025, 3:23:30 UTC\n    \n            ¬∑ Discuss Website outage Multiple disk failure resulted in a web site outage.  We think we've recovered almost everything from the web site, so it should be back up and running. 3 Apr 2025, 20:49:48 UTC\n    \n            ¬∑ Discuss RIP Jimmy Carter Carter wrote the following on June 16, 1977 and placed it in Voyager 1, which is the most distant human-made object from Earth: This Voyager spacecraft was constructed by the United States of America. We are a community of 240 million human being among the more than 4 billion who inhabit the planet Earth. We human beings are still divided into nation states, but these states are rapidly becoming a single global civilization. We cast this message into the cosmos. It is likely to survive a billion years into our future, when our civilization is profoundly altered and the surface of the Earth may be vastly changed. Of the 2", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Batmobile: 10-20x Faster CUDA Kernels for Equivariant Graph Neural Networks", "url": "https://elliotarledge.com/blog/batmobile", "content": "Custom CUDA kernels that eliminate the computational bottlenecks in spherical harmonics and tensor product operations - the core primitives of equivariant GNNs like MACE, NequIP, and Allegro. Equivariant graph neural networks have revolutionized atomistic machine learning. Models like MACE, NequIP, and Allegro achieve state-of-the-art accuracy in molecular dynamics simulations, materials property prediction, and drug discovery. Their secret: they respect the fundamental symmetries of physical systems - rotation, translation, and reflection invariance. But this mathematical elegance comes at a computational cost. The operations that make these models work - spherical harmonics and Clebsch-Gordan tensor products - are expensive. A single MACE layer can spend 80% of its forward pass time in these two operations. This matters for real applications. Molecular dynamics simulations run billions of timesteps. Battery materials discovery screens millions of candidates. Drug binding affinity predictions evaluate thousands of poses. When each forward pass takes milliseconds instead of microseconds, these workflows become impractical. To understand why equivariant GNNs are slow, we need to understand what they compute. When two atoms interact, the direction of their bond matters. A carbon-carbon bond pointing \"up\" is physically different from one pointing \"right\" - and our neural network needs to know this. Spherical harmonics (Y_lm) provide a mathematically principled way to encode 3D directions. Given a unit vector (x, y, z), spherical harmonics compute a set of features that transform predictably under rotation: For L_max=3, we get 16 components total: 1 + 3 + 5 + 7 = 16. These aren't arbitrary features - they form a complete basis for functions on the sphere. When we want to combine two equivariant features (say, node features with edge directions), we can't just concatenate or add them - that would break equivariance. Instead, we use Clebsch-Gordan tensor products. These a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Anthropic's original take home assignment open sourced", "url": "https://github.com/anthropics/original_performance_takehome", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Anthropic's original performance take-home, now open for you to try! There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . This repo contains a version of Anthropic's original performance take-home, before Claude Opus 4.5 started doing better than humans given only 2 hours. Now you can try to beat Claude Opus 4.5 given unlimited time! measured in clock cycles from the simulated machine: If you optimize below 1487 cycles, beating Claude Opus 4.5's best performance at launch, email us at performance-recruiting@anthropic.com with your code (and ideally a resume) so we can be appropriately impressed and perhaps discuss interviewing. Run python tests/submission_tests.py to see which thresholds you pass. Anthropic's original performance take-home, now open for you to try! There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Stories removed from the Hacker News Front Page, updated in real time", "url": "https://github.com/vitoplantamura/HackerNewsRemovals", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . List of stories removed from the Hacker News Front Page, updated in real time. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . UPDATE (February 4, 2024): This is the discussion about this project on HN: here . Please specifically read @dang's comment regarding the core assumption of this project: here . On a personal note, the number of Stories removed yesterday (Saturday, February 3, 2024) was the lowest ever recorded by the service. This includes 2 duplicate Stories. As a side note, in the list always check whether a Story is a duplicate or not : this is a very reasonable reason for removal and unfortunately I have no way of automatically determining it in the service! The purpose of this project is to try to understand the type and scale of the moderation of the Hacker News Front Page. NOTE : I love Hacker News. I try to read it every day. In the case of OnnxStream ( here for example), 95% of the comments were helpful and intelligent. I also understand that moderating a site with huge traffic and where users are basically anonymous must be a very difficult task. Returning to the purpose of this project, from what I have been able to see, the \"public\" (i.e. observable from the outside) moderation of the Front Page consists of two main tools: modification of the title of a Story (voluntarily or involuntarily influencing its growth in terms of rank) or directly its removal. Regarding the first type of moderation, an excellent site is already available that tracks changes to Story titles. Here instead I will focus on the second type. For the reasons explained in the \"Why?\" section below, I have developed a small application that logs all the Stories that are removed from the Front Page, for personal use. I later discovered that there is no tool/website that provides this t", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "EmuDevz: A game about developing emulators", "url": "https://afska.github.io/emudevz/", "content": "EmuDevz: A game about developing emulators. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A 26,000-year astronomical monument hidden in plain sight (2019)", "url": "https://longnow.org/ideas/the-26000-year-astronomical-monument-hidden-in-plain-sight/", "content": "The western flank of the Hoover Dam holds a celestial map that marks the time of the dam‚Äôs creation based on the 25,772-year axial precession of the earth. On the western flank of the Hoover Dam stands a little-understood monument, commissioned by the US Bureau of Reclamation when construction of the dam began in 01931. The most noticeable parts of this corner of the dam, now known as Monument Plaza, are the massive winged bronze sculptures and central flagpole which are often photographed by visitors. The most amazing feature of this plaza, however, is under their feet as they take those pictures. The plaza‚Äôs terrazzo floor is actually a celestial map that marks the time of the dam‚Äôs creation based on the 25,772-year axial precession of the earth. I was particularly interested in this monument because this axial precession is also the slowest cycle that we track in Long Now‚Äôs 10,000 Year Clock. Strangely, little to no documentation of this installation seemed to be available, except for a few vacation pictures on Flickr. So the last time I was in Las Vegas, I made a special trip out to Hoover Dam to see if I could learn more about this obscure 26,000-year monument. I parked my rental car on the Nevada side of the dam on a day pushing 100 degrees. I quickly found Monument Plaza just opposite the visitor center where tours of the dam are offered. While the plaza is easy to find, it stands apart from all the main tours and stories about the dam. With the exception of the writing in the plaza floor itself, the only information I could find came from a speaker running on loop, broadcasting a basic description of the monument while visitors walked around the area. When I asked my tour guide about it, he suggested that there may be some historical documentation and directed me to Emme Woodward, the dam‚Äôs historian. I was able to get in touch with her after returning home. As she sent me a few items, I began to see why the Bureau of Reclamation doesn‚Äôt explain very much ab", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Hightouch (YC S19) Is Hiring", "url": "https://hightouch.com/careers", "content": "Enterprise-ready platform features By team By industry For marketing For advertising Featured Learn about the benefits of a Composable CDP and how it compares to a traditional CDP solution All integrations Popular sources Popular destinations Popular extensions Explore Documentation Get started Featured Read real reviews from Hightouch customers At Hightouch, we‚Äôre committed to helping our customers, business, and employees grow. As a series C startup backed by top investors, we are determined to continuously raise the bar and provide the best product in the market. Grow your career in a fast paced environment that values creative thinking and innovation. We're proud to serve the most amazing companies out there We are hungry and ambitious. We celebrate our accomplishments, but we‚Äôre never fully satisfied. We‚Äôre always figuring out how to collectively push ourselves further and do more. If we think we can grow the company 5x this year, the first question should be ‚Äúwhy not 10x?‚Äù We want to create an environment where people feel actively welcomed, encouraged, and supported. People who aren‚Äôt kind aren‚Äôt tolerated ‚Äî it‚Äôs just not worth it. We intrinsically believe in a deeper kindness as a core value, aside from its obvious benefits to the business Speed matters. We don‚Äôt have time for endless deliberation ‚Äî most decisions are two-way doors. Move fast, adapt quickly. We take inspiration from others and don‚Äôt innovate where we don‚Äôt need to. We communicate clearly because time is precious. We parallelize to the greatest extent possible. We listen to everyone and try to put ourselves in their shoes, regardless of our initial reaction to what they say. This applies to everyone ‚Äî customers, prospects, partners, peers, etc. Everyone should be intrinsically motivated by business impact. We minimize distractions and prioritize our time based on what‚Äôs actually impactful to the business. We value people at all levels based on their impact above anything else. We have high ex", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "RSS.Social ‚Äì the latest and best from small sites across the web", "url": "https://rss.social/", "content": "The latest and best from small sites across the web. Learn how it works .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nukeproof: Manifesto for European Data Sovereignty", "url": "https://nukeproof.org/", "content": "NukeProof¬Æ Alliance There‚Äôs a lot of talk about European data sovereignty. Rather than add to the chorus of complaints and inactivity, we are building a\n        strategic alliance that will lead Europe to true data independence. European data is increasingly at the mercy of foreign control. Google, Microsoft, and Amazon now account for more than 60% of the\n      cloud market, while Chinese companies are pushing their own interests. Laws such as the US CLOUD Act undermine the very idea of\n      sovereign data, totally disregarding where the data physically resides. Europe has the talent, the technology and the willpower. What we lack is cohesive action. A patchwork of local providers, startups, MSPs, and telcos struggles to compete with global hyperscalers on scale, capability and\n      cost. NukeProof exists to bring these players together, forming a coalition that enables Europe to stand strong on its own terms. This is Europe‚Äôs moment of truth. Collaboration is part of our DNA, from shared markets and infrastructure to collective regulation\n      and values. NukeProof channels that spirit and unites independent European actors to create a sovereign cloud of our own. Join a new era of European data independence built on cooperation, resilience and control. The time is now. Share of total engagement score NukeProof Alliance is an initiative by SpaceTime, a Finnish organisation pushing back on hyperscalers to provide data storage\n            services for European companies on European soil. A patchwork of local providers, startups, MSPs, and telcos struggles to\n            compete with global hyperscalers on scale, capability and cost. NukeProof exists to bring these players together, forming a\n            coalition that enables Europe to stand strong on its own terms. The name NukeProof is an acknowledgement of why the internet was first built: to survive nuclear war. It was decentralised by\n            design and resilient by necessity with no single point of failu", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "What Is a PC Compatible?", "url": "https://codon.org.uk/~mjg59/blog/p/what-is-a-pc-compatible/", "content": "Wikipedia says ‚ÄúAn IBM PC compatible is any personal computer that is hardware- and software-compatible with the IBM Personal Computer (IBM PC) and its subsequent models‚Äù . But what does this actually mean? The obvious literal interpretation is for a device to be PC compatible, all software originally written for the IBM 5150 must run on it. Is this a reasonable definition? Is it one that any modern hardware can meet? Before we dig into that, let‚Äôs go back to the early days of the x86 industry. IBM had launched the PC built almost entirely around off-the-shelf Intel components, and shipped full schematics in the IBM PC Technical Reference Manual . Anyone could buy the same parts from Intel and build a compatible board. They‚Äôd still need an operating system, but Microsoft was happy to sell MS-DOS to anyone who‚Äôd turn up with money. The only thing stopping people from cloning the entire board was the BIOS, the component that sat between the raw hardware and much of the software running on it. The concept of a BIOS originated in CP/M , an operating system originally written in the 70s for systems based on the Intel 8080. At that point in time there was no meaningful standardisation - systems might use the same CPU but otherwise have entirely different hardware, and any software that made assumptions about the underlying hardware wouldn‚Äôt run elsewhere. CP/M‚Äôs BIOS was effectively an abstraction layer, a set of code that could be modified to suit the specific underlying hardware without needing to modify the rest of the OS. As long as applications only called BIOS functions, they didn‚Äôt need to care about the underlying hardware and would run on all systems that had a working CP/M port. By 1979, boards based on the 8086, Intel‚Äôs successor to the 8080, were hitting the market. The 8086 wasn‚Äôt machine code compatible with the 8080, but 8080 assembly code could be assembled to 8086 instructions to simplify porting old code. Despite this, the 8086 version of CP/M was taking", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "200 MB RAM FreeBSD Desktop", "url": "https://vermaden.wordpress.com/2026/01/18/200-mb-ram-freebsd-desktop/", "content": "Recently I came across Lunduke post about some mysterious Vendefoul Wolf Linux distribution that uses 217 MB RAM with Devuan as base (no systemd(1) here) and XLibre X11 server along with IceWM window manager.  For the record ‚Äì the Lunduke post states 200 MB RAM but XLibreDev quotes a post where exactly 217 MB RAM is reported. Later Lunduke even posted a video about it.  As I use similarly low resource setup with Openbox / Tint2 / Dzen2 setup (documented FreeBSD Desktop here) I was wondering ‚Ä¶ how low can I go with FreeBSD RAM usage.  Lets try ‚Ä¶ The Table of Contents is as follows. I wanted to use most recent FreeBSD so I used 15.0-RELEASE version ‚Äì including the Tech Preview PKGBASE setup for FreeBSD Base System . As Xorg X11 implementation is currently intentionally crippled by some Red Hat employees and some people from FreeDesktop.org I decided to use actively developed and maintained XLibre X11 server instead. Example of such behavior below.  More on that tragic Xorg story where open source spirit died long time ago is available here: A lot has also been explained in this message:  As the Vendefoul Wolf Linux did not used ZFS I also decided to fight fair and used UFS with Soft Updates Journaling mode that minimizes fsck(8) time to minimum. For the record Netflix also uses FreeBSD with UFS filesystem. Using UFS would mean loosing great FreeBSD feature called ZFS Boot Environments ‚Ä¶ but fortunately you can use UFS Boot Environments as replacement on UFS filesystems. After install I created my vermaden user with membership in these groups. Later I disabled additional virtual terminals that I would not use anyway in the /etc/ttys file.  Next used /boot/loader.conf file. Now the main FreeBSD /etc/rc.conf configuration file. Now FreeBSD system settings in the /etc/sysctl.conf file. The devfs_system_ruleset specified desktop in the /etc/devfs.rules file. Only a few ‚Ä¶ with few hundred dependencies üôÇ What I really loved is that XLibre X11 packages DOES NOT CONFLICT with", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "cURL removes bug bounties", "url": "https://etn.se/index.php/nyheter/72808-curl-removes-bug-bounties.html", "content": "Open source code library cURL is removing the possibility to earn money by reporting bugs, hoping that this will reduce the volume of AI slop reports. Joshua Rogers ‚Äì AI wielding bug hunter of fame ‚Äì thinks it's a great idea. cURL has been flooded with AI-generated error reports. Now one of the incentives to create them will go away. The vast majority of AI-generated error reports submitted to cURL are pure nonsense. Other open source projects are caught in the same pandemic. cURL maintainer Daniel Stenberg made an impact with his reporting on AI-generated bug reports last year ‚Äì ‚Äù Death by a thousand slops .‚Äù Determining that they are nonsense is time-consuming, causing the maintainers lots of extra work. ‚ÄùAI slop and bad reports in general have been increasing even more lately, so we have to try to brake the flood in order not to drown‚Äù, says cURL maintainer Daniel Stenberg to Swedish electronics industry news site etn.se. Therefore, cURL is terminating the bounty payouts as of the end of January. ‚ÄúWe hope this removes some of the incentives for people to send us garbage. We spend far too much time handling slop due to findings that are not real, exaggerated, or misunderstood.‚Äù Not all AI-generated bug reports are nonsense. It‚Äôs not possible to determine the exact share, but Daniel Stenberg knows of more than a hundred good AI assisted reports that led to corrections. In total, 87 bug reports to cURL have over the years amounted to USD 101,020 in bounties. How many of them would have gone under the radar if the bounty money had not existed? Elektroniktidningen passes that question on to debugging champion Joshua Rogers, who last year flooded open source projects with bug reports ‚Äì good reports. Interestingly, his reports were generated with the help of AI tools. But he doesn‚Äôt just vibe along in the dark ‚Äî he reviews and adds to AI's analysis before submitting anything. Despite being an active code vulnerabilities hunter himself, he thinks removing the bounty mone", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The percentage of Show HN posts is increasing, but their scores are decreasing", "url": "https://snubi.net/posts/Show-HN/", "content": "Last update: 2026-01-14 Recently, I felt like I was seeing more √¢¬Ä¬úShow HN√¢¬Ä¬ù stories, and many of which were generated with LLMs. So I analyzed the data to see if that was true. Also I included the average score per month to see if people enjoy seeing them (because I don√¢¬Ä¬ôt :P). Stories in 2026 was omitted. 1) It√¢¬Ä¬ôs only 13 days, 2) Scores are not stable yet. Left axis: show_hn_ratio ( show_hn / story * 100 ) Right axis: average_show_hn_score and average_story_score  With LLM timeline  Disclaimer: I am neither a data scientist nor a statistician. Some nuances may have been lost in translation. For about ten years (2012~2022), the percentage of Show HN stories was around 2-3%. Then, with the appearance of LLMs that can code, it√¢¬Ä¬ôs been increasing. Claude Code and Cursor 1.0 accelerated it even more. As of December 2025, over 12% of all stories are Show HNs. It√¢¬Ä¬ôs safe to say that there is a correlation between the increase in Show HN posts and LLM. People can create great things even if they don√¢¬Ä¬ôt know how to code at all. Show HN stories used to receive similar scores (around 15-18) to those of all stories until 2023~2024. However, it√¢¬Ä¬ôs been declining while percentage of them are going up. As of December 2025, the average Show HN score is 10 points lower (9.04 vs 19.53). Does it mean LLM-generated Show HNs are lower quality? I√¢¬Ä¬ôm not sure. Maybe people are tired of seeing too many Show HNs. Also I have no idea why the average score was increased in 2022. A lot of new users? You can find python code and csv in https://github.com/plastic041/hackernews . I exported BigQuery hacker news data to csv using this query: The type field in BigQuery does not have a show_hn attribute like the Algolia API, so I lowercased titles and filtered using starts_with(\"show_hn: \") to determine if a post is a Show HN story. I didn√¢¬Ä¬ôt commit to the repo the original CSV because it was too big (~400 MB) but you can download it from BigQuery for free (I didn√¢¬Ä¬ôt set billing accoun", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The challenges of soft delete", "url": "https://atlas9.dev/blog/soft-delete.html", "content": "Software projects often implement \"soft delete\",√Ç¬†maybe with a deleted boolean or an archived_at timestamp column.\nIf customers accidentally delete their data, they can recover it, which makes work easier for customer support teams.\nPerhaps archived records are even required for compliance or audit reasons. I've run into some trouble with soft delete designs. I'll cover those, and ponder ideas for how I'd build this in the future. Adding an archived_at column seems to ooze complexity out into queries, operations, and applications.\nRecovering deleted records does happen, but 99% of archived records are never going to be read. So, the database tables will have a lot of dead data. Depending on access patterns, that might even be a significant amount of data.\nI've seen APIs that didn't work well with Terraform, so Terraform would delete + recreate records on every run, and over time that led\nto millions of dead rows. Your database can probably handle the extra bytes, and storage is fairly cheap, so it's not necessarily a problem, at first. Hopefully, the project decided on a retention period in the beginning, and set up a periodic job to clean up those rows.\nUnfortunately, I'd bet that a significant percentage of projects did neither √¢¬Ä¬ì√Ç¬†it's really easy to ignore the archived data for a long time. At some point, someone might want to restore a database backup. Hopefully that's for fun and profit and not because you lost the production database at 11 am.\nIf your project is popular, you might have a giant database full of dead data that takes a long time to recreate from a dump file. archived_at columns also complicate queries, operations, and application code. Applications need to make sure they always avoid the archived data that's sitting\nright next to the live data. Indexes need to be careful to avoid archived rows. Manual queries run for debugging or analytics are longer and more complicated.\nThere's always a risk that archived data accidentally leaks in when it's", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Libbbf: Bound Book Format, A high-performance container for comics and manga", "url": "https://github.com/ef1500/libbbf", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Bound Book Format: A high-performance, DirectStorage-native container format for comics and manga There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  Warning Official Source Notice: Please only download releases from this repository (ef1500/libbbf). External mirrors or forks may contain malware. Bound Book Format (.bbf) is a high-performance binary container designed specifically for digital comic books and manga. Unlike CBR/CBZ, BBF is built for DirectSotrage/mmap, easy integrity checks, and mixed-codec containerization. Linux Windows Alternatively, if you need python support, use libbbf-python . BBF is designed as a Footer-indexed binary format. This allows for rapid append-only creation and immediate random access to any page without scanning the entire file. The bbfmux reference implementation utilizes Memory Mapping (mmap/MapViewOfFile) . Instead of reading file data into intermediate buffers, the tool maps the container directly into the process address space. This allows the CPU to access image data at the speed of your NVMe drive's hardware limit. Integrity checks utilize Parallel XXH3 . On multi-core systems, the verifier splits the asset table into chunks and validates multiple pages simultaneously. This makes BBF verification up to 10x faster than ZIP/RAR CRC checks. Every asset in a BBF file starts on a 4096-byte boundary . This alignment is critical for modern hardware, allowing for DirectStorage transfers directly from disk to GPU memory, bypassing CPU bottlenecks entirely. Note: DirectStorage isn't avaliable for images yet (as far as I know), but I've made sure to accomodate such a thing in the future with this format. NOTE: libbbf.h includes a flags field, as well as extra padding for each asset entry. This is so that in the future libbbf can accomodate futur", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Mastra 1.0, open-source JavaScript agent framework from the Gatsby devs", "url": "https://github.com/mastra-ai/mastra", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack. It includes everything you need to go from early prototypes to production-ready applications. Mastra integrates with frontend and backend frameworks like React, Next.js, and Node, or you can deploy it anywhere as a standalone server. It's the easiest way to build, tune, and scale reliable AI products. Purpose-built for TypeScript and designed around established AI patterns, Mastra gives you everything you need to build great AI applications out-of-the-box. Some highlights include: Model routing - Connect to 40+ providers through one standard interface. Use models from OpenAI, Anthropic, Gemini, and more. Agents - Build autonomous agents that use LLMs and tools to solve open-ended tasks. Agents reason about goals, decide which tools to use, and iterate internally until the model emits a final answer or an optional stopping condition is met. Workflows - When you need explicit control over execution, use Mastra's graph-based workflow engine to orchestrate complex multi-step processes. Mastra workflows use an intuitive syntax for control flow ( .then() , .branch() , .parallel() ). Human-in-the-loop - Suspend an agent or workflow and await user input or approval before resuming. Mastra uses storage to remember execution state, so you can pause indefinitely and resume where you left off. Context management - Give your agents the right context at the right time. Provide conversation history , retrieve data from your sources (APIs, databases, files), and add human-like working and semantic memory so you", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Hypnosis with Aphantasia", "url": "https://aphantasia.com/article/stories/hypnosis-with-aphantasia", "content": "Search for a command to run... Can aphantasics be hypnotized? My experience learning to be hypnotized with imagery-free inductions. Liana is a semi-retired writer and amateur potter. Despite her lifelong inability to visualize - or perhaps because of it - Liana has learned to adapt, bending her capabilities in imaginative ways to service her creativity. As a storyteller with aphantasia, Liana imagines our wondrous world through the lenses of perception, memory, and feeling, seeking to write passionate, sometimes humorous, tales full of possibilities. Building awareness and understanding of aphantasia through research, education, and community support. About Resources Community Research ¬© 2026 Aphantasia Network. All rights reserved.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Instabridge has acquired Nova Launcher", "url": "https://novalauncher.com/nova-is-here-to-stay", "content": "Hi everyone. We want to share a clear update directly with the Nova community. Instabridge has acquired Nova Launcher. We are a Swedish company building products that help people get online, used by millions of people worldwide. Nova is not shutting down. Our immediate focus is simple: keep Nova stable, compatible with modern Android, and actively maintained. We also know many of you have lived through a long period of uncertainty. Nova has a strong identity and a community that still cares deeply. We take that seriously. Our job is not to reinvent Nova overnight. Our job is to be responsible owners. That means: We will be reading and collecting feedback from Reddit, Play Store reviews, email, and other community channels. We will not be able to respond to every post, but we will be paying attention. For support related issues, we will share a clear contact channel shortly. We have long admired what Nova represents: speed, customization, and user control. When we saw how much the community still cares, it was clear to us that Nova deserved a stable future with active maintenance. Yes. Nova√¢¬Ä¬ôs identity is the point. Performance, flexibility, and user control stay at the center of the product. Any future changes will be evaluated through that lens. Nova needs a sustainable business model to support ongoing development and maintenance. We are exploring different options, including paid tiers and other approaches. As many of you have already anticipated, we are also evaluating ad based options for the free version. If ads are introduced, Nova Prime will remain ad free. Our guiding principles are clear: keep the experience clean and fast, avoid disruptive formats, and provide a straightforward way to keep the experience ad free. No. Sustainability is not just about survival. A healthy business model allows us to invest properly in Nova over time. That investment enables deeper work on performance, more powerful customization, better long term compatibility with Android,", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "IPv6 is not insecure because it lacks a NAT", "url": "https://www.johnmaguire.me/blog/ipv6-is-not-insecure-because-it-lacks-nat/", "content": "I recently saw a discussion where someone argued that IPv4 is more secure than IPv6 because √¢¬Ä¬úthe NAT-by-default of IPv4 effectively means that I get the benefit of a default-deny security strategy.√¢¬Ä¬ù This is a common misconception that I think is worth addressing. The fundamental issue here is conflating NAT (Network Address Translation) with security. NAT isn√¢¬Ä¬ôt actually a security feature√¢¬Ä¬îit√¢¬Ä¬ôs an address conservation mechanism that became necessary because we ran out of IPv4 addresses. (Although it is totally possible to use a NAT with IPv6 too!) NAT allows multiple devices on a home network to share a single IP address on the public Internet by rewriting the destination IP of a packet based on its destination port. It chooses a new destination IP based on the √¢¬Ä¬úport mappings√¢¬Ä¬ù or √¢¬Ä¬úport forwards√¢¬Ä¬ù configured by the network admin. The consequence of this is that when receiving inbound traffic to a NAT√¢¬Ä¬ôd IP, packets with an unexpected destination port (one which has not been forwarded) will keep the destination IP of the public machine and will not be routed to another machine on the network. But the security benefits people attribute to NAT actually come from the stateful firewall that√¢¬Ä¬ôs typically bundled with NAT routers. Modern routers ship with firewall policies that deny inbound traffic by default, even when a NAT is not being used. The firewall will drop packets with an unexpected destination before even considering whether to rewrite or route the packets. For example, UniFi routers ship with these default IPv6 firewall rules: Therefore, in order to allow unsolicited inbound traffic to any IPv6 device hosted behind the router, you must explicitly add a firewall rule to allow the traffic, whether using a NAT or not.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Which AI Lies Best? A game theory classic designed by John Nash", "url": "https://so-long-sucker.vercel.app/", "content": "A game theory classic designed by John Nash that requires betrayal to win. Now a benchmark\n                    for AI deception. A benchmark that tests what most benchmarks can't:\n                    deception, negotiation, and trust. So Long Sucker was designed in 1950\n                            by four game theorists including John Nash (of \"A Beautiful Mind\" fame). The\n                            game has one brutal property: betrayal is required to win . This lets us test AI capabilities that standard benchmarks miss: 4 players, each with colored chips. Take turns\n                                playing chips on piles. If your chip matches the\n                                one below it, you capture the pile. Run out of\n                                chips? Beg others for help ‚Äî or get eliminated.\n                                Last player standing wins. Each AI developed its own personality. Here's who they\n                    became. Win rates invert as game complexity increases. Manipulation becomes more effective as game\n                                length increases. Gaslighting tactics need time to work. Reactive play dominates simple games but\n                                collapses under complexity. No internal\n                                reasoning means no long-term planning. We can see their private thoughts. They don't match what they say. \"Yellow is weak. I should ally with Blue to\n                                eliminate Yellow, then betray Blue.\" \"Yellow, let's work together! I think we can\n                                both win if we coordinate.\" It knows the truth and says otherwise. Most common gaslighting phrases across 146 games. AI deception analyzed across 6+ games. The best liar we tested. Gemini 3 uses Institutional Deception : \n                        it creates fake frameworks like \"alliance banks\" that make \n                        resource hoarding look cooperative and betrayal look procedural.\n                        It", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The GDB JIT Interface", "url": "https://bernsteinbear.com/blog/gdb-jit/", "content": "GDB is great for stepping through machine code to figure out what is going on.\nIt uses debug information under the hood to present you with a tidy backtrace\nand also determine how much machine code to print when you type disassemble . This debug information comes from your compiler. Clang, GCC, rustc, etc all\nproduce debug data in a format called DWARF and then embed that debug\ninformation inside the binary (ELF, Mach-O, ‚Ä¶) when you do -ggdb or\nequivalent. Unfortunately, this means that by default, GDB has no idea what is going on if\nyou break in a JIT-compiled function. You can step instruction-by-instruction\nand whatnot, but that‚Äôs about it. This is because the current instruction\npointer is nowhere to be found in any of the existing debug info tables from\nthe host runtime code, so your terminal is filled with ??? . See this example\nfrom the V8 docs: Fortunately, there is a JIT interface to GDB. If you implement a couple of\nfunctions in your JIT and run them every time you finish compiling a function,\nyou can get the debugging niceties for your JIT code too. See again a V8\nexample: Unfortunately, the GDB docs are somewhat sparse . So I went\nspelunking through a bunch of different projects to try and understand what is\ngoing on. GDB expects your runtime to expose a function called __jit_debug_register_code and a global variable called __jit_debug_descriptor . GDB automatically adds its own internal breakpoints\nat this function, if it exists. Then, when you compile code, you call this\nfunction from your runtime. In slightly more detail: This is why you see compiler projects such as V8 including large swaths of code\njust to make object files: Because this is a huge hassle, GDB also has a newer interface that does not\nrequire making an ELF/Mach-O/‚Ä¶+DWARF object. This new interface requires writing a binary format of your choice. You make\nthe writer and you make the reader. Then, when you are in GDB, you load your\nreader as a shared object. The reader must implement th", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Unconventional PostgreSQL Optimizations", "url": "https://hakibenita.com/postgresql-unconventional-optimizations", "content": "When it comes to database optimization, developers often reach for the same old tools: rewrite the query slightly differently, slap an index on a column, denormalize, analyze, vacuum, cluster, repeat. Conventional techniques are effective, but sometimes being creative can really pay off! In this article, I present unconventional optimization techniques in PostgreSQL. Table of Contents  Imagine you have this table of users: For each user you keep their name and which payment plan they're on. There are only two plans, \"free\" and \"pro\", so you add a check constraint. Generate some data and analyze the table: You now have 100K users in the system. Now you want to let your analysts access this table in their reporting tool of choice. You give one of the analysts permission, and this is the first query they write: The query returned no results, and the analyst is baffled. How come there are no users on the \"Pro\" plan? The name of the plan is \"pro\" and not \"Pro\" (with a capital \"P\") as the analyst wrote it. This is an honest mistake really, anyone can make such a mistake! But what is the cost of this mistake? Examine the execution plan of a query for a non-existing value: PostgreSQL scanned the entire table! However, there's a check constraint on the field - no row can ever have the value \"Pro\", the database makes sure of that! So if this condition always evaluates to false, why is PostgreSQL scanning the table? PostgreSQL is smart enough to skip a table scan when the query contains a condition that always evaluates to false, but not by default! To instruct PostgreSQL to look at constraints when generating a plan, you need to set the parameter constraint_exclusion : Nice! After turning constraint_exclusion on, PostgreSQL figured out based on the check constraint that the condition won't return any rows, and skipped the scan entirely. So who are you constraint_exclusion and why are you not on by default? Currently, constraint exclusion is enabled by default only for cases t", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Are arrays functions?", "url": "https://futhark-lang.org/blog/2026-01-16-are-arrays-functions.html", "content": "When I was a youngster first perusing the Haskell documentation for\narrays ,\nI was amused to find the following description of just what these mysterious\nthings might be: Haskell provides indexable arrays, which may be thought of as functions whose\ndomains are isomorphic to contiguous subsets of the integers. I found this to be a hilariously obtuse and unnecessarily formalist description\nof a common data structure. Now, older, wiser, and well ensconced in the ivory\ntowers of academia, I look at this description and think that it is actually a\nwonderful definition of the essence of arrays! And given that this sentence\nstill lingers in my thoughts so many years later, who can say that it is not\nactually a far better piece of documentation than some more prosaic description\nmight have been? To a language designer, the correspondence between arrays and functions (for it does exist, independent of whether you think it is a useful way to document\nthem) is alluring, for one of the best ways to improve a language is to make it\nsmaller. Our goal is not to unify the representation of arrays and functions,\nof course - nobody would seriously claim that representing an array via some Church-encoding is a good idea\nin a supposedly practical programming language. Instead, what might be\nworthwhile considering is what consequences might arise from unifying arrays and\nfunctions at the syntax or type level, and why Futhark ultimately has not done\nso. There is some prior work to consider. The array language K has a syntactic unification of\narrays and functions, as both are indexed/applied with the notation f[x] . This\nis however pretty much where the correspondence stops. As an APL derivative, K\nprogramming is based on bulk operations on entire arrays, rather than\nelement-at-a-time programming, and the operators that perform these bulk\noperations cannot be applied to functions. And of course, K has no type\nsystem ,\nso the correspondence is purely syntactic. Dex is a research language p", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Unix Pipe Card Game", "url": "https://punkx.org/unix-pipe-game/", "content": "Programming Time , which is a game to teach python and some more fundamental algorithms, from hash tables to RSA The C Pointer Game - Pointers, Arrays and Strings , a game to teach kids to look at the computer memory and understand references and values 4917 , a game to teach kids machine code and how the CPU works with memory and registers The Unix Pipes Game - Process Substitution , an expansion of the Unix Pipes Game to teach process substitution and also: paste, tr, cut, bc RunLength Encoding for Kids , small cards \"game\" to explain runlength encoding PUNK0 - The Function Composition Card Game , use cards to manipulate a list and use its values to win the game PROJEKT: OVERFLOW , RISCV assembler boardgame Programming for kids , a log of my journey of teaching my daughter how to code", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "California is free of drought for the first time in 25 years", "url": "https://www.latimes.com/california/story/2026-01-09/california-has-no-areas-of-dryness-first-time-in-25-years", "content": "This is read by an automated voice. Please report any issues or inconsistencies here . After experiencing one of the wettest holiday seasons on record, still soggy California hit a major milestone this week ‚Äî having zero areas of abnormal dryness for the first time in 25 years. The data, collected by the U.S. Drought Monitor , is a welcome nugget of news for Golden State residents, who in the last 15 years alone have lived through two of the worst droughts on record, the worst wildfire seasons on record and the most destructive wildfires ever. Right now, the wildfire risk across California is ‚Äúabout as close to zero as it ever gets,‚Äù and there is likely no need to worry about the state‚Äôs water supply for the rest of the year, said UC climate scientist Daniel Swain. Currently, 14 of the state‚Äôs 17 major water supply reservoirs are at 70% or more capacity, according to the California Department of Water Resources .        California‚Äôs last drought lasted more than 1,300 days, from February 2020 to October 2023, at which point just 0.7% of the state remained abnormally dry, thanks to a series of winter atmospheric rivers that showered the Golden State with rain. Before that, California was in a severe drought from 2012 through 2016. But the last time 0% of the California map had any level of abnormally dry or drought conditions was all the way back in December 2000. In recent weeks, a series of powerful winter storms and atmospheric rivers have swept across California, dumping heavy rain that soaked soils, filled reservoirs and left much of the state unusually wet for this time of year. ‚ÄúThis is certainly a less destructive weather winter than last year was and than many of the drought years were, so it‚Äôs OK to take that breather and to acknowledge that, right now, things are doing OK,‚Äù Swain said. He noted, however, that ‚Äúas we move forward, we do expect to be dealing with increasingly extreme [weather] swings.‚Äù California Scientists attribute these extreme weather sw", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The super-slow conversion of the U.S. to metric (2025)", "url": "https://www.thefabricator.com/thefabricator/blog/testingmeasuring/the-super-slow-conversion-of-the-us-to-metric", "content": "While most other manufacturers in the world only have to deal with the centimeter side of the ruler, U.S. metal fabricators have to use both sides. mecaleha / DigitalVision Vectors / Getty Images Plus Back when I was a Catholic-school kid in northern Wisconsin, my school lessons briefly focused on the metric system. This was in the late 1970s. Along with learning cursive and the referents of rosary beads, we learned that the base-10 system would be critically important in all things science and engineering. This focus on metric stemmed from the Metric Conversion Act, passed in Congress in 1975, and the United States Metric Board that it created. Forward-thinking members of Congress and President Gerald Ford wanted us kids to join the rest of the world in thinking about distances in kilometers and weight in kilos. Signing the bill in December 1975, Ford argued that our continued use of U.S. customary (the more accurate name for what‚Äôs sometimes the called the British Imperial system) had created ‚Äúan island in a metric sea.‚Äù But this well-intentioned legislation had a problem: It made the change to metric, in the words of the act, ‚Äúcompletely voluntary.‚Äù So after a brief burst of attention to metric, many of us pretty much forgot about it, except when running a 10K or buying a 2-liter bottle of soda. President Ronald Reagan disbanded the Metric Board in 1982. But in reality, metric never really left. As Elizabeth Benham pointed out in her article for the National Institute of Standards and Technology , U.S. customary units have been defined in terms of metric units since 1893. And even though the progress has been slow, the U.S. has continued toward conversion, as Ross Rowlett described in his short history of metric in the U.S. Indeed, numerous manufacturers, including Caterpillar, Ingersoll-Rand, and General Motors, have adopted metric to facilitate their participation in the global economy. Now that I work at Howe‚Äôs Welding and Metal Fabrication , a small welding a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Maintenance: Of Everything, Part One", "url": "https://press.stripe.com/maintenance-part-one", "content": "The first in a multi-volume work, Maintenance: Of Everything, Part One offers a comprehensive overview of the civilizational importance of maintenance. The book explores the insights that can be gleaned from the maintenance of sailboats, vehicles, and weapons, with absorbing detours into the evolution of precision in manufacturing, the enduring importance of manuals, sustainment in the military, and the never-ending battle against corrosion. Maintenance: Of Everything is a wide-ranging and provocative call to expand what we mean by ‚Äúmaintenance.‚Äù It invites us to understand not only the profound impact maintenance has on our daily lives but also why taking responsibility for maintaining something‚Äîwhether a motorcycle, a monument, or our planet‚Äîcan be a radical act. Stewart Brand is the cofounder and president of The Long Now Foundation. He created and edited the National Book Award-winning Whole Earth Catalog from 1968 to 1998. His books include The Media Lab (1987), How Buildings Learn (1994), The Clock of the Long Now (1999), and Whole Earth Discipline (2009). He was the subject of the documentary We Are As Gods (2020). Stewart Brand makes a persuasive case that keeping the human show on the road through well-planned maintenance is as vital and as fascinating a task as innovation and discovery themselves. A deliciously good book. Matt Ridley author of The Rational Optimist Once again, Stewart Brand reframes our worldview with a new perspective. You may not imagine you would be interested in rust, Soviet tanks, or tricked-out Model Ts‚Äîthat is, until Brand reexamines them through the lens of maintenance. Maintenance: Of Everything is destined to be a classic. Danny Hillis cofounder of Applied Invention Stewart Brand is back with a manifesto on maintenance, the tool that empowers all tools. Preventative maintenance, deferred maintenance, and emergency maintenance: this much-needed, no-nonsense treatise illuminates the difference, and why it counts. George Dyson autho", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The space and motion of communicating agents (2008) [pdf]", "url": "https://www.cl.cam.ac.uk/archive/rm135/Bigraphs-draft.pdf", "content": "The space and motion of communicating agents (2008) [pdf]. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Do you have any evidence that agentic coding works?", "url": "item?id=46691243", "content": "Ask HN: Do you have any evidence that agentic coding works?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Parliament tells Dutch government to keep DigiD data out of American hands", "url": "https://nltimes.nl/2026/01/21/parliament-tells-dutch-govt-keep-digid-data-american-hands", "content": "A parliamentary majority has asked the current caretaker and upcoming new Cabinet to do everything in their power to prevent Dutch DigiD data from ending up in the United States government‚Äôs hands. There are concerns that this could happen through the American firm Kyndryl‚Äôs impending acquisition of Solvinity , a company that is essential for DigiD access. In a technical briefing in the Tweede Kamer, the lower house of the Dutch parliament, on Tuesday, MPs spoke with experts about the dangers and risks of this takeover. Parliament has long been concerned about this issue, and the briefing did nothing to alleviate those worries, NOS reported . VVD parliamentarian Silvio Erkens is deeply concerned that the acquisition could ‚Äúenable the U.S. government to access data‚Äù and use it to blackmail people. GroenLinks-PvdA MP Barbara Kathmann worries that this will get to a point where ‚ÄúTrump can shut down our digital government with the single push of a button.‚Äù The cloud and infrastructure company Solvinity provides the infrastructure that transfers data for DigiD - the digital identification that every person in the Netherlands must have to exchange data with health insurers, pension funds, municipalities, and the Tax Authorities, among others. In the United States, the government has a lot of influence and power over American companies, including the ability to demand companies‚Äô data. The Tweede Kamer cannot force companies to abandon an acquisition, GroenLinks-PvdA MP Kathmann acknowledged. But she hopes that the current and upcoming government will do everything in its power to stop this. She suggested persuading Solvinity to reconsider the acquisition. The government IT service Logius could also switch to another company for its DigiD services, or the government can try its best to buy a ‚Äúgolden share,‚Äù which would give the Netherlands veto power in the company, Kathmann said. Erkens believes that the deal must be blocked if there are no legal guarantees that Dutch data", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Our approach to age prediction", "url": "https://openai.com/index/our-approach-to-age-prediction/", "content": "Our approach to age prediction. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Lunar Radio Telescope to Unlock Cosmic Mysteries", "url": "https://spectrum.ieee.org/lunar-radio-telescope", "content": "The catch: It will have to be on the moon Astronomer Jack Burns has spent four decades working to place a radio telescope on the moon. The first one is finally scheduled to launch in early 2027. Is olation dictates where we go to see into the far reaches of the universe. The Atacama Desert of Chile, the summit of Mauna Kea in Hawaii, the vast expanse of the Australian Outback ‚Äîthese are where astronomers and engineers have built the great observatories and radio telescopes of modern times. The skies are usually clear, the air is arid, and the electronic din of civilization is far away. It was to one of these places, in the high desert of New Mexico, that a young astronomer named Jack Burns went to study radio jets and quasars far beyond the Milky Way. It was 1979, he was just out of grad school, and the Very Large Array , a constellation of 28 giant dish antennas on an open plain, was a new mecca of radio astronomy. But the VLA had its limitations‚Äînamely, that Earth‚Äôs protective atmosphere and ionosphere blocked many parts of the electromagnetic spectrum, and that, even in a remote desert, earthly interference was never completely gone. Could there be a better, even lonelier place to put a radio telescope? Sure, a NASA planetary scientist named Wendell Mendell , told Burns: How about the moon? He asked if Burns had ever thought about building one there. ‚ÄúMy immediate reaction was no. Maybe even hell, no. Why would I want to do that?‚Äù Burns recalls with a self-deprecating smile. His work at the VLA had gone well, he was fascinated by cosmology‚Äôs big questions, and he didn‚Äôt want to be slowed by the bureaucratic slog of getting funding to launch a new piece of hardware. But Mendell suggested he do some research and speak at a conference on future lunar observatories, and Burns‚Äôs thinking about a space-based radio telescope began to shift. That was in 1984. In the four decades since, he‚Äôs published more than 500 peer-reviewed papers on radio astronomy. He‚Äôs been an adv", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "IP Addresses Through 2025", "url": "https://www.potaroo.net/ispcol/2026-01/addr2025.html", "content": "IP Addresses through 2025 January 2026 It's time for another annual roundup from the world of IP addresses. Let√¢¬Ä¬ôs see what has changed in the past 12 months in addressing the Internet and look at how IP address allocation information can inform us of the changing nature of the network itself. Back around 1992, the IETF gazed into their crystal ball and tried to understand how the Internet was going to evolve and what demands that would place on the addressing system as part of the √¢¬Ä¬úIP Next Generation√¢¬Ä¬ù study.  The staggeringly large numbers of connected devices that we see today were certainly within the range predicted by that study. The assumption made at the time was that we would continue to use much the same IP protocol architecture, including the requirement that each connected device was assigned a unique IP address, and the implication was that the 32-bit address field defined in version 4 of the IP protocol was clearly going to be inadequate to cope with the predicted number of connected devices. A span of 4 billion address values was just not large enough. We concluded at the time that the only way we could make the Internet work across such a massive pool of connected devices was to deploy a new IP protocol that came with a massively larger address space. It was from this reasoning that IPv6 was designed, as this world of abundant silicon processors connected to a single public Internet was the scenario that IPv6 was primarily intended to solve. The copious volumes of a 128-bit address space were intended to allow us to uniquely assign a public IPv6 address to every such device, no matter how small, or in whatever volume they might be deployed. But while the Internet has grown at amazing speeds across the ensuing 33 years, the deployment of IPv6 has proceeded at a more measured pace. There is still no evidence of any common sense of urgency about the deployment of IPv6 in the public Internet, and still there is no common agreement that the continued", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Building Robust Helm Charts", "url": "https://www.willmunn.xyz/devops/helm/kubernetes/2026/01/17/building-robust-helm-charts.html", "content": "Jan 17, 2026 In my current work, there is often the need to deploy a similar application\nstack in various configurations, to several environments. Each configuration may\nvary in terms of scale, uptime requirements and feature flagging. Due to a lot\nof flux in infrastructure set up, each environment is also not equivalent. On\ntop of this, there are obviously financial requirements to run all of this as\ncheaply as possible. Kubernetes and helm templating are valuable tools in this\nsituation, they allow us to create a configuration blueprint with the details\nabstracted in values.yaml files. Let‚Äôs start with the basics, helm provides a helm lint command which performs\nchecks You can run this with your different values.yaml files to ensure that all your\nconfigurations are compliant. It‚Äôs also a good idea to use the helm template command to actually check that\nhelm is able to render your templates. I like to compare helm templating with html templating tools like JSX. This\nallows front end developers to create reusable components usable throughout\npages of a web application, A button component for example can have many states,\nprimary, secondary, loading, disabled, light or dark mode. Each state may also look different depending on the size/type of device your are\nbrowsing the site with. Each of these states represents differences in many\nparameters (font size, colour, gradient, opacity, border, padding, margin,\nwidth, height, etc). These complexities are abstracted away giving the consuming\ncode the list of states to chose from, so that they can write code like this. Under the hood of course many aspects of the CSS or HTML code will be impacted\nby the change of state so you often end up with different parts of the markup\nhaving conditionals on the same check. Just in this contrived example you already have 2 different things being\ncontrolled by the state property with 2 separate checks, the CSS classes and the\npresence of the loading icon. This is quite similar to the si", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Agent Skills Leaderboard", "url": "https://skills.sh", "content": "The Open Agent Skills Ecosystem Skills are reusable capabilities for AI agents. Install them with a single command to enhance your agents with access to procedural knowledge. vercel-labs/agent-skills vercel-labs/agent-skills remotion-dev/skills expo/skills expo/skills expo/skills anthropics/skills expo/skills better-auth/skills anthropics/skills expo/skills callstackincubator/agent-skills expo/skills expo/skills expo/skills expo/skills vercel-labs/agent-browser better-auth/skills coreyhaines31/marketingskills coreyhaines31/marketingskills jimliu/baoyu-skills jimliu/baoyu-skills jimliu/baoyu-skills jimliu/baoyu-skills coreyhaines31/marketingskills coreyhaines31/marketingskills jimliu/baoyu-skills coreyhaines31/marketingskills anthropics/skills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills jimliu/baoyu-skills coreyhaines31/marketingskills jimliu/baoyu-skills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills expo/skills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills coreyhaines31/marketingskills anthropics/skills coreyhaines31/marketingskills coreyhaines31/marketingskills anthropics/skills coreyhaines31/marketingskills obra/superpowers coreyhaines31/marketingskills coreyhaines31/marketingskills anthropics/skills anthropics/skills op7418/Humanizer-zh anthropics/skills anthropics/skills expo/skills jimliu/baoyu-skills expo/skills expo/skills expo/skills jimliu/baoyu-skills expo/skills expo/skills jimliu/baoyu-skills obra/superpowers anthropics/skills jimliu/baoyu-skills obra/superpowers onmax/nuxt-skills anthropics/skills obra/superpowers obra/superpowers anthropics/skills anthropics/skills obra/superpowers obra/superpowers obra/superpowers anthropics/skills obra/superpowers nextlevelbuilder/ui-ux-pro-max-skill onmax/nuxt-skills anthropics/skills obra/superpowers obra/superpowers obra/su", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Electricity use of AI coding agents", "url": "https://www.simonpcouch.com/blog/2026-01-20-cc-impact/", "content": "Most of the discourse about the environmental impact of LLM use focuses on a ‚Äòmedian query.‚Äô What about a Claude Code session? January 20, 2026 Throughout 2025, we got better estimates of electricity and water use of AI chatbots. There are all sorts of posts I could cite on this topic, but a favorite is this blog post from Our World in Data‚Äôs Hannah Ritchie. On the electricity front:  In short, ‚Äúunless you‚Äôre an extreme power user, asking AI questions every day is still a rounding error on your total electricity footprint.‚Äù A similar story applies to water usage. This one from Benjamin Todd : The average American uses 1600 liters of water per day , so even if you make 100 prompts per day, at 2ml per prompt, that‚Äôs only 0.01% of your total water consumption. Using a shower for one second would use far more. Generally, these analyses guide my own thinking about the environmental impacts of my individual usage of LLMs; if I‚Äôm interested in reducing my personal carbon footprint, I‚Äôm much better off driving a couple miles less a week or avoiding one flight each year. This is indeed the right conclusion for users of chat interfaces like chatgpt.com or claude.ai. That said, 1 or 10 or 100 median prompts a day is many orders of magnitude off from my own personal use of LLMs; I likely am, in Hannah Ritchie‚Äôs words, an ‚Äúextreme power user.‚Äù I work in software and spend much of my workday driving 2 or 3 coding agents, like Claude Code, at a time. Thus, a much more relevant question for me is how much energy does a typical Claude Code session consume? (I‚Äôm not going to discuss water use in this post.) tl;dr, much more:  There are so many considerations and assumptions and pieces of shorthand one must use along the way to answer this sort of question. I‚Äôll do my best to call those out throughout this post, but please do understand this is still just Sunday afternoon napkin math from Some Guy. tl;dr: In this section, I point out that a Claude Code session should use orders of mag", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Prediction markets are ushering in a world in which news becomes about gambling", "url": "https://www.theatlantic.com/technology/2026/01/america-polymarket-disaster/685662/", "content": "Why is the media obsessed with prediction markets? For the past week, I‚Äôve found myself playing the same 23-second CNN clip on repeat. I‚Äôve watched it in bed, during my commute to work, at the office, midway through making carrot soup, and while brushing my teeth. In the video, Harry Enten, the network‚Äôs chief data analyst, stares into the camera and breathlessly tells his audience about the gambling odds that Donald Trump will buy any of Greenland. ‚ÄúThe people who are putting their money where their mouth is‚Äîthey are absolutely taking this seriously,‚Äù Enten says. He taps the giant touch screen behind him and pulls up a made-for-TV graphic: Based on how people were betting online at the time, there was a 36 percent chance that the president would annex Greenland. ‚ÄúWhoa, way up there!‚Äù Enten yells, slapping his hands together. ‚ÄúMy goodness gracious!‚Äù The ticker at the bottom of the screen speeds through other odds: Will Gavin Newsom win the next presidential election? 19 percent chance. Will Viktor Orb√°n be out as the leader of Hungary before the end of the year? 48 percent chance.  These odds were pulled from Kalshi, which hilariously claims not to be a gambling platform: It‚Äôs a ‚Äúprediction market.‚Äù People go to sites such as Kalshi and Polymarket‚Äîanother big prediction market‚Äîin order to put money down on a given news event. Nobody would bet on something that they didn‚Äôt believe would happen, the thinking goes, and so the markets are meant to forecast the likelihood of a given outcome. Listen: Prediction markets and the ‚Äúsuckerification‚Äù crisis, with Max Read Prediction markets let you wager on basically anything. Will Elon Musk father another baby by June 30? Will Jesus return this year? Will Israel strike Gaza tomorrow ? Will the longevity guru Bryan Johnson‚Äôs next functional sperm count be greater than ‚Äú 20.0 M/ejac ‚Äù? These sites have recently boomed in popularity‚Äîparticularly among terminally online young men who trade meme stocks and siphon from their 401(k)s", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nova Launcher added Facebook and Google Ads tracking", "url": "https://lemdro.id/post/lemdro.id/35049920", "content": "Nova Launcher added Facebook and Google Ads tracking. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nvidia: Natural Conversational AI with Any Role and Voice", "url": "https://research.nvidia.com/labs/adlr/personaplex/", "content": "Published: January 15, 2026 Rajarshi Roy, Jonathan Raiman, Sang-gil Lee, Teodor-Dumitru Ene, Robert Kirby, Sungwon Kim, Jaehyeon Kim, Bryan Catanzaro. PersonaPlex and Rajarshi Roy sharing jokes. Conversational AI has forced an impossible choice. Traditional systems (ASR√¢¬Ü¬íLLM√¢¬Ü¬íTTS cascades) let you customize the voice and role, but conversations feel robotic with awkward pauses, no interruptions, and unnatural turn-taking. Full-duplex models like Moshi finally made AI conversations feel natural with real-time listening and speaking, but locked you into a single fixed voice and role.\nNVIDIA PersonaPlex breaks this trade-off. Select from a diverse range of voices and define any role through text prompts. Need a wise assistant, a customer service agent, a fantasy character, or just someone to talk to? PersonaPlex delivers truly natural conversations while maintaining your chosen persona throughout. It handles interruptions, backchannels, and authentic conversational rhythm. For the first time, you get both the customization you need and the naturalness that makes conversations feel genuinely human. PersonaPlex is a full duplex model: it listens and speaks at the same time. This capability, first introduced with Moshi, lets PersonaPlex learn not only the contents of its speech but also the behavior associated with speech, such as when to pause, interrupt, or backchannel (√¢¬Ä¬úuh-huh√¢¬Ä¬ù, √¢¬Ä¬úoh√¢¬Ä¬ù, etc.). We achieve low-latency interaction by eliminating delays associated with cascaded systems that use separate models for listening (Automated Speech Recognition), language production (Language Model), and speaking (Text to Speech). Our approach uses a single model that updates its internal state as the user speaks and streams a response back immediately. Enriching PersonaPlex√¢¬Ä¬ôs output with non-verbal aspects creates an important qualitative difference relative to systems without this dimension: PersonaPlex now recreates some of the same cues humans use to read intent, emo", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "I'm addicted to being useful", "url": "https://www.seangoedecke.com/addicted-to-being-useful/", "content": "When I get together with my friends in the industry, I feel a little guilty about how much I love my job. This is a tough time to be a software engineer. The job was less stressful in the late 2010s than it is now, and I sympathize with anyone who is upset about the change. There are a lot of objective reasons to feel bad about work. But despite all that, I‚Äôm still having a blast. I enjoy pulling together projects, figuring out difficult bugs, and writing code in general. I like spending time with computers. But what I really love is being useful . The main character in Gogol‚Äôs short story The Overcoat is a man called Akaky Akaievich 1 . Akaky‚Äôs job is objectively terrible: he‚Äôs stuck in a dead-end copyist role, being paid very little, with colleagues who don‚Äôt respect him. Still, he loves his work, to the point that if he has no work to take home with him, he does some recreational copying just for his own sake. Akaky is a dysfunctional person. But his dysfunction makes him a perfect fit for his job 2 . It‚Äôs hard for me to see a problem and not solve it. This is especially true if I‚Äôm the only person (or one of a very few people) who could solve it, or if somebody is asking for my help. I feel an almost physical discomfort about it, and a corresponding relief and satisfaction when I do go and solve the problem. The work of a software engineer - or at least my work as a staff software engineer - is perfectly tailored to this tendency. Every day people rely on me to solve a series of technical problems 3 . In other words, like Akaky Akaievich, I don‚Äôt mind the ways in which my job is dysfunctional, because it matches the ways in which I myself am dysfunctional: specifically, my addiction to being useful . (Of course, it helps that my working conditions are overall much better than Akaky‚Äôs). I‚Äôm kind of like a working dog, in a way. Working dogs get rewarded with treats 4 , but they don‚Äôt do it for the treats. They do it for the work itself, which is inherently satisf", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Apples, Trees, and Quasimodes", "url": "https://systemstack.dev/2025/09/humane-computing/", "content": "September 18, 2025 A while back, Ars Technica published a thoughtful piece about Jef Raskin , tracing his long pursuit of the ‚Äúhumane computer‚Äù and the cul-de-sacs where that pursuit ended. It‚Äôs a generous, well-told account of the designer who wanted to make machines simpler, kinder, and more aligned with the way people actually think. But part of what makes Raskin interesting is that his story isn‚Äôt just Apple‚Äôs story. He came out of the same cultural current John Markoff chronicled in What the Dormouse Said ‚Äîthe Bay Area tradition that treated computers not as office appliances but as tools for thought, instruments of liberation. Read that way, the Canon Cat and Raskin‚Äôs other projects aren‚Äôt just an eccentric side quest from a frustrated Apple veteran. It‚Äôs evidence of how far the humane ideal could stretch, and how quickly it ran up against the limits of commercial computing. Apple couldn‚Äôt deliver Raskin‚Äôs vision then, and it can‚Äôt deliver it now. Neither can any other big platform company. If we want to understand why, and what Raskin still tells us about humane computing, we have to put him back in the longer lineage he belonged to, and look at how his version of the dream carried that vision but also narrowed it. What the Dormouse Said documents how the Bay Area counterculture  shaped early personal computing. LSD, communes, systems theory, amorphous defense research contracts, and Engelbart‚Äôs ‚Äúaugmentation‚Äù experiments all swirled together in a weird scene that accidentally (or maybe not so accidentally) created much of the modern world. The story usually gets told with a neat list: Engelbart‚Äôs demo , Nelson‚Äôs Xanadu hypertext, Kay‚Äôs Dynabook , Brand‚Äôs Whole Earth . Xerox PARC, Steve Jobs, the World Wide Web. The familiar pantheon. But that version turns a messy, improvisational moment into a plaque. Engelbart‚Äôs system needed a whole research staff just to operate; Nelson‚Äôs Xanadu was (and is) more sermon than software; Kay‚Äôs Dynabook lived mostly on paper", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Provably unmasking malicious behavior through execution traces", "url": "https://arxiv.org/abs/2512.13821", "content": "Help | Advanced Search arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs .  arXiv Operational Status", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Disaster planning for regular folks (2015)", "url": "https://lcamtuf.coredump.cx/prep/index-old.shtml", "content": "Written by lcamtuf@coredump.cx , Dec 2015, minor updates Jul 2021. Buy the book instead! Practical Doomsday is an in-depth, data-packed guide\nto rational emergency preparedness. The book offers deeper and more polished insights on most of the topics covered on this page. For example,\nabout 40 pages are devoted to financial planning alone - from cash reserves, to insurance policies, to commodity derivatives. You can get it on Amazon , order from Barnes & Noble , or visit your\nfavorite book place. Sample chapter is available here . The prepper culture begs to be taken with a grain of salt. In the public\nconsciousness, its has all the makings of a doomsday cult:\na tribe of unkempt misfits who hoard gold bullion, study herbalism,\nand preach about the imminent collapse of our society. Today, most of us see such worries as absurd. It's not that life-altering disasters are\nrare: every year, we hear about millions of people displaced by wildfires, earthquakes,\nhurricanes, or floods. Heck, not a decade goes by without at least one first-class\ndemocracy lapsing into armed conflict or fiscal disarray. But having grown up in a period\nof prosperity and calm, we find it difficult to believe that an episode of bad weather or a currency crisis\ncould upend our lives. I suspect that we dismiss such hazards not only because they seem surreal, but also because\nworrying about them can make one feel helpless and lost. What's more, we tend to follow the\nsame instincts to tune out far more pedestrian and avoidable risks. For example, \nmost of us don't plan ahead for losing a job, for dealing with a week-long water outage, or\nfor surviving the night if our home goes up in smoke. Quite often, our singular strategy for dealing with such dangers is to hope for the\ngovernment to bail us out. But no matter if our elected officials prefer to school us with\npassages from Milton Friendman or from Thomas Piketty, the hard truth is that no state can provide\na robust safety net for all of life's likel", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nvidia Stock Crash Prediction", "url": "https://entropicthoughts.com/nvidia-stock-crash-prediction", "content": "One of the questions of the 2026 acx prediction contest is whether Nvidia‚Äôs\nstock price will close below $100 on any day in 2026. At the time of writing, it\ntrades at $184 and a bit, so going down to $100 would be a near halving of the\nstock value of the highest valued company in the world. It‚Äôs an interesting question, and it‚Äôs worth spending some time on it. If you just want the answer, my best prediction is that the probability is\naround 10¬†%. I didn‚Äôt expect to get such a high answer, but read on to see how\nwe can find out. When we predicted the Dow Jones index crossing a barrier in 2023 , we treated the\nindex as an unbiased random walk. That was convenient, but we cannot do it with\nthe Nvidia question because of one major difference: the time scale. Over short time spans, the volatility 1 1 Or noise, or variation, or standard\ndeviation. of stock movements dominate their return 2 2 Or signal, or drift,\nor average change. . This happens because noise grows with the square root of\ntime, while signal grows linearly with time. The plot below illustrates an imaginary amazing investment which has a yearly\nlog-return of 0.3, and a yearly volatility of 0.3. 3 3 Readers aware that stonks\ngo up will recognise this as an unrealistic Sharpe ratio of 1.0. The middle\nline follows our best guess for how the investment will grow after each year,\nand the outer curves illustrate our uncertainty around the exact value of it.  Early on, we can see that the uncertainty is much bigger than the height to the\ntrend line. Before a year has passed, the exact result is determined more by\nnoise than by growth. Toward the end, growth has taken over and the noise has a\nsmaller effect. One measure of how much volatility there is compared to expected return is the\nsignal-to-noise ratio. It‚Äôs computed as \\[10 \\log_{10}\\left(\\frac{\\mu\\sqrt{t}}{\\sigma}\\right)\\] and for the Dow Jones question, we were looking at a signal-to-noise ratio of\n‚àí8¬†dB. That is already a little too high to safely assume", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Fast Concordance: Instant concordance on a corpus of >1,200 books", "url": "https://iafisher.com/concordance/", "content": "Instant concordance on a corpus of\n                over 1,200 public-domain classic books, courtesy of Standard\n                    Ebooks . Read about how it was implemented here .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Who owns Rudolph's nose?", "url": "https://creativelawcenter.com/copyright-rudolph-reindeer/", "content": "Who owns Rudolph's nose?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: TopicRadar ‚Äì Track trending topics across HN, GitHub, ArXiv, and more", "url": "https://apify.com/mick-johnson/topic-radar", "content": "Get started Product Back Start here! Get data with ready-made web scrapers for popular websites Browse 14,010 Actors Apify platform Apify Store Pre-built web scraping tools Actors Build and run serverless programs Integrations Connect with apps and services MCP Give your AI access to Actors Anti-blocking Anti-blocking Scrape without getting blocked Proxy Rotate scraper IP addresses Open source Crawlee Web scraping and crawling library Solutions Back MCP server configuration Configure your Apify MCP server with Actors and tools for seamless integration with MCP clients. Start building Web data for Enterprise Startups Universities Nonprofits Use cases Data for generative AI Data for AI agents Lead generation Market research View more ‚Üí Consulting Apify Professional Services Apify Partners Developers Back Documentation Full reference for the Apify platform Get started Code templates Python, JavaScript, and TypeScript Web scraping academy Courses for beginners and experts Monetize your code Publish your scrapers and get paid Learn API reference CLI SDK MCP Crawlee Earn from your code $596k paid out in December. Many developers earn $3k+ every month. Start earning now Resources Back  Help and support Advice and answers about Apify Actor ideas Get inspired to build Actors Changelog See what‚Äôs new on Apify Customer stories Find out how others use Apify Company About Apify Contact us Blog Live events Partners Jobs We're hiring! Join our Discord Talk to scraping experts Pricing Contact sales Pricing Pay per usage mick-johnson/topic-radar Track any topic across the internet and get aggregated, ranked results from multiple sources in one place. Perfect for market research, competitive intelligence, trend monitoring, content creation, and staying updated on any subject. Pricing Pay per usage Rating 5.0 ( 3 ) Developer mick johnson Actor stats 1 Bookmarked 6 Total users 1 Monthly active users a day ago Last modified Categories News Integrations Other Share Track any topic across", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Proof of Concept to Test Humanoid Robots", "url": "https://thehumanoid.ai/humanoid-and-siemens-completed-a-proof-of-concept-to-test-humanoidrobots-in-industrial-logistics/", "content": "London, The UK ‚Äî January 15, 2026 ‚Äî Humanoid, a UK-based AI and robotics company, and Siemens, a leading technology company, have successfully completed a proof of concept (POC) demonstrating the use of humanoid robots in industrial logistics. Humanoid‚Äôs HMND 01 wheeled Alpha robot was deployed in real operations at a Siemens facility, marking a significant step toward the deployment of humanoid robots in industrial settings. This successful POC is the first step in a broader partnership between the two companies to test and validate how humanoid robots can be used in real-world environments. The POC focused on a tote-to-conveyor destacking task within Siemens‚Äô logistics process. In this use case, the robot autonomously picked totes from a storage stack, transported them to a conveyor, and placed them at the designated pickup point for human operators. This sequence was repeated until the stack was fully empty, which demonstrated how humanoid robots can take on repetitive logistics tasks.  The POC was structured in two phases. The first one focused on in-house development and demonstration and has already been completed. During this stage, the Humanoid team built a physical twin to support testing, optimization, and rapid iteration throughout the POC. The second phase involved a two-week on-site deployment at the Siemens Electronics Factory in Erlangen, where partners assessed the robots in a real-world production environment. This joint POC measured both performance and reliability of humanoid robots under autonomous operation. Target metrics were met in full and included a throughput of 60 tote moves per hour, operation with two different tote sizes, continuous autonomous task execution for more than 30 minutes, uptime exceeding 8 hours. The team also evaluated the POC‚Äôs success using the following indicators: overall pick and place success rate and autonomous pick and place success rate, both above 90%. Humanoid and Siemens see this POC as a first step toward a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Danish pension fund divesting US Treasuries", "url": "https://www.reuters.com/business/danish-pension-fund-divest-its-us-treasuries-2026-01-20/", "content": "Danish pension fund divesting US Treasuries. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Running Claude Code dangerously (safely)", "url": "https://blog.emilburzo.com/2026/01/running-claude-code-dangerously-safely/", "content": "I‚Äôve been using Claude Code more and more recently. At some point I realized that rather than do something else until it finishes, I would constantly check on it to see if it was asking for yet another permission, which felt like it was missing the point of having an agent do stuff. So I wanted to use Claude Code with the --dangerously-skip-permissions flag. If you haven‚Äôt used it, this flag does exactly what it says: it lets Claude Code do whatever it wants without asking permission first. No more ‚ÄúMay I install this package?‚Äù, ‚ÄúShould I modify this config?‚Äù, ‚ÄúCan I delete these files?‚Äù It just‚Ä¶ does it. Which is great for flow since I don‚Äôt have to worry that it stopped doing stuff just to ask a permission question. But also, you know, dangerous. I like my filesystem intact, so the obvious solution is to not run this thing directly on my OS account. First instinct: throw it in a Docker container. Containers are for isolation, right? Except I want Claude to be able to build Docker images. And run containers. And maybe orchestrate some stuff. So now you need Docker-in-Docker, which means --privileged mode, which defeats the entire purpose of sandboxing. That means trading ‚ÄúClaude might mess up my filesystem‚Äù for ‚ÄúClaude has root-level access to my container runtime.‚Äù Not great. There‚Äôs also the nested networking weirdness, volume mounting permissions that make you question your life choices, and the general feeling that you‚Äôre fighting the tool instead of using it. I also briefly considered: Then I remembered about a project that I‚Äôve used before Docker became all the rage: Vagrant. If you weren‚Äôt around back then, Vagrant gives you proper VM isolation with a reproducible config file. It‚Äôs basically infrastructure as code for your local dev environment. You get: I hadn‚Äôt used VirtualBox in years since Docker containers covered all requirements until now, so I grabbed the latest version (7.2.4) and got started. First vagrant up and‚Ä¶ the VM is pegging my CPU at 100%+", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Revive a mostly dead Discord server", "url": "item?id=46697735", "content": "Ask HN: Revive a mostly dead Discord server. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Generate animated solar system timelapse videos for any date range", "url": "https://github.com/simondorfman/solar_system_live/", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Solar System Live is an interactive orrery for the Web that lets you view the solar system in a variety of ways for any date between 4713 B.C. and A.D. 8000. An ephemeris can be displayed for any location on Earth and, given orbital elements in the form published in the IAU Circulars and the Jet Propulsion Laboratory, the orbit and position of ast There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . This repository is a fork of Fourmilab's Solar System Live with added tooling to generate animated videos of the solar system over time. Perfect for creating unique birthday videos! Generate time-lapse animations showing how the solar system evolved during someone's lifetime, complete with customizable text overlays showing dates, ages, and planetary orbital statistics. Watch as planets orbit while tracking how many times Earth (or your friend) was lapped by Mercury and Venus, or how many times they lapped the outer planets. Note: This repository is macOS-focused (setup scripts and instructions assume macOS/Homebrew), but you can probably adapt it to work on other Unix-like systems (Linux, BSD, etc.) with appropriate modifications to paths and package managers. Here's a sample video generated using Einstein's birth and death dates (1879-03-14 to 1955-04-18):  (Click the animated GIF above to view the full video) Stage a local runnable tree: From the repo root: This will create ./local/ with: Run Lighttpd: Verify it's working: Open http://127.0.0.1:8080/cgi-bin/Solar in your browser. The page should render and the generated image should load. Once you have Lighttpd running locally, you can generate animated videos using: Required argument: Optional arguments: Examples: The script will: This repository is a fork of Fourmilab's Solar System Live , originally created by John Walker . S", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Zen of Reticulum", "url": "https://github.com/markqvist/Reticulum/blob/master/Zen%20of%20Reticulum.md", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "RCS for Business", "url": "https://developers.google.com/business-communications/rcs-business-messaging", "content": "Engage with customers seamlessly on Android and iOS. Allow your customers to interact with\n  your business directly, and enhance the interaction with distinctive branding and rich\n  media. Measure engagement with read receipts and analytics, and build trust with a\n  'Verified' icon. Learn more Ready to become an RCS for Business partner? Partner interest form arrow_forward Explore the RCS Business Messaging APIs and Developer Console, review the terms and security docs, and browse\n  the release notes. Learn more Learn more Learn more Go to Console Manage RCS for Business agents from the Administration Console, and get insights into message activity\n  and billing. Explore the key documentation, or contact us directly for support. Exclusively for registered RCS for Business partners: Access a curated collection of resources to help you champion RCS for Business with your internal teams and brand clients. Tip: To view and download the Marketing kit decks, you need access to your organization's RCS for Business partner account. Please contact a team member with access to share the decks with you. To apply to become an RCS for Business partner, fill out the partner registration interest form.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "When \"likers'' go private: Engagement with reputationally risky content on X", "url": "https://arxiv.org/abs/2601.11140", "content": "Help | Advanced Search arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs .  arXiv Operational Status", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "LG UltraFine Evo 6K 32-inch Monitor Review", "url": "https://www.wired.com/review/lg-ultrafine-evo-6k-32-inch-monitor/", "content": "7 /10 More pixels is never a bad thing, right? That's at least part of the reasoning behind the existence of the LG UltraFine Evo 6K. This 32-inch monitor aims to put even more pixels in front of content creators and professionals. Beyond that, it has an attention-grabbing design and off-the-charts image quality. It's one of the best monitors you can buy for content creators, despite some of the unfortunate trade-offs it comes with. The 32-inch LG UltraFine Evo 6K is a very pretty monitor. I wouldn't blame you for mistaking this as an Apple product, given the focus on clean lines, simple shapes, and designerly aesthetic. The extra-wide stand means that the base itself isn‚Äôt overly large. Like the Apple Studio Display , the flat base provides more usable desk space rather than occupying it. The stand itself has a unique design, too. It resembles the styling Apple uses on the iMac and Studio Display, but it has a textured pattern on the back. It‚Äôs gorgeous, though you probably won‚Äôt spend a lot of time looking at the back of the monitor unless your desk is in the middle of the room or in command position (if you know, you know). I also like that the back of the cabinet is flat, giving it a sleek look that the rounded backs of typical monitors can‚Äôt achieve. Because it uses conventional backlighting, though, it‚Äôs not as thin as OLED displays like some of Samsung‚Äôs Odyssey gaming monitors . The UltraFine 6K also has some impressively thin bezels, too, adding to the ultra-modern aesthetic. While they‚Äôre not ‚Äúvirtually borderless‚Äù as LG states, they‚Äôre smaller than the bezels on most monitors I‚Äôve tested. One of my favorite aspects of the UltraFine Evo 6K is the speakers. The pair of included speakers on this might be the best I've heard on a monitor. They are extremely loud and clear. There's even a decent amount of bass in there, to the point where you won't need a pair of computer speakers . LG UltraFine Evo 6K Monitor Rating: 7/10 One thing I don‚Äôt love is the port pl", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "IP over Avian Carriers with Quality of Service (1999)", "url": "https://www.rfc-editor.org/rfc/rfc2549.html", "content": "IP over Avian Carriers with Quality of Service (1999). Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Level S4 solar radiation event", "url": "https://www.swpc.noaa.gov/news/g4-severe-geomagnetic-storm-levels-reached-19-jan-2026", "content": "Space Weather Prediction Center National Oceanic and Atmospheric Administration G4 Levels were first reached at 2:38pm EST (1938 UTC) on 19 January, 2026 upon CME shock arrival. CME passage is expected to continue through the evening with G4 levels remaining possible. National Oceanic and Atmospheric Administration National Weather Service National Centers for Environmental Prediction Space Weather Prediction Center 325 Broadway, Boulder CO 80305 Space Weather Prediction Center 325 Broadway, Boulder CO 80305 Disclaimer Privacy Policy About NOAA's National Weather Service Careers in Weather", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Scaling long-running autonomous coding", "url": "https://simonwillison.net/2026/Jan/19/scaling-long-running-autonomous-coding/", "content": "Scaling long-running autonomous coding . Wilson Lin at Cursor has been doing some experiments to see how far you can push a large fleet of \"autonomous\" coding agents: This post describes what we've learned from running hundreds of concurrent agents on a single project, coordinating their work, and watching them write over a million lines of code and trillions of tokens. They ended up running planners and sub-planners to create tasks, then having workers execute on those tasks - similar to how Claude Code uses sub-agents. Each cycle ended with a judge agent deciding if the project was completed or not. In my predictions for 2026 the other day I said that by 2029: I think somebody will have built a full web browser mostly using AI assistance, and it won‚Äôt even be surprising. Rolling a new web browser is one of the most complicated software projects I can imagine[...] the cheat code is the conformance suites. If there are existing tests that it‚Äôll get so much easier. I may have been off by three years, because Cursor chose \"building a web browser from scratch\" as their test case for their agent swarm approach: To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub . But how well did they do? Their initial announcement a couple of days ago was met with unsurprising skepticism , especially when it became apparent that their GitHub Actions CI was failing and there were no build instructions in the repo. It looks like they addressed that within the past 24 hours. The latest README includes build instructions which I followed on macOS like this: This got me a working browser window! Here are screenshots I took of google.com and my own website:   Honestly those are very impressive! You can tell they're not just wrapping an existing rendering engine because of those very obvious rendering glitches, but th", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The microstructure of wealth transfer in prediction markets", "url": "https://www.jbecker.dev/research/prediction-market-microstructure", "content": "Slot machines on the Las Vegas Strip return about 93 cents on the dollar. This is widely considered some of the worst odds in gambling. Yet on Kalshi, a CFTC-regulated prediction market, traders have wagered vast sums on longshot contracts with historical returns as low as 43 cents on the dollar. Thousands of participants are voluntarily accepting expected values far lower than a casino slot machine to bet on their convictions. The efficient market hypothesis suggests that asset prices should perfectly aggregate all available information. Prediction markets theoretically provide the purest test of this theory. Unlike equities, there is no ambiguity about intrinsic value. A contract either pays $1 or it does not. A price of 5 cents should imply exactly a 5% probability. We analyzed 72.1 million trades covering $18.26 billion in volume to test this efficiency. Our findings suggest that collective accuracy relies less on rational actors than on a mechanism for harvesting error. We document a systematic wealth transfer where impulsive Takers pay a structural premium for affirmative \"YES\" outcomes while Makers capture an \"Optimism Tax\" simply by selling into this biased flow. The effect is strongest in high-engagement categories like Sports and Entertainment, while low-engagement categories like Finance approach perfect efficiency. This paper makes three contributions. First, it confirms the presence of the longshot bias on Kalshi and quantifies its magnitude across price levels. Second, it decomposes returns by market role, revealing a persistent wealth transfer from takers to makers driven by asymmetric order flow. Third, it identifies a YES/NO asymmetry where takers disproportionately favor affirmative bets at longshot prices, exacerbating their losses. Prediction markets are exchanges where participants trade binary contracts on real-world outcomes. These contracts settle at either $1 or $0, with prices ranging from 1 to 99 cents serving as probability proxies. Unli", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Reliable Signals of Honest Intent", "url": "https://zanlib.dev/blog/reliable-signals-of-honest-intent/", "content": "Imagine you are working on a significant software update. The software is used by a few thousand professionals, and the release you are working on will fix a few significant issues and greatly improve the quality of work of these people. The update costs money, so it cannot be an automated thing: you need to convince the users of this software to decide that they should update. How would you do it? Would you implement a pop-up window advertising the new release and push it through the automated update channel? Would you write an email? Would you prompt AI for an email? A story like this was related in Rory Sutherland‚Äôs book Alchemy , and concerned the release of the then-new Windows NT 32-bit server operating system. Microsoft had to figure out how to convince its existing user-base of system administrators to make the switch. But they didn‚Äôt ask developers for advice, they hired an advertising agency. And the advertising agency had a different idea. We produced an elaborate box containing a variety of bits and pieces including a free mouse-mat and a pen, inside gratuitously expensive packaging. 1 Marginnote alchemy 1 Sutherland, R. Alchemy: The Surprising Power of Ideas That Don‚Äôt Make Sense . W. H. Allen 2020; p. 177 ‚Ü© Why go to such great lengths to advertise a software update? Well, because this story is a subtle case of obliviousness that developers are often guilty of. We tend to get blindsided by the subject-object split, and think that we only need to convey the objective fact while leaving the subjective interpretation of the value of that fact up to the reader. But it is perhaps not shocking that the subjective perception of value can be influenced‚Äîthis is, after all, what persuasion is for. It‚Äôs actually very natural and expected for it to be influenced, because we are constantly being bombarded by various stimuli. The stimuli fight for our attention, and we have developed a system of complex intuitions to select which stimuli are worth our attention and", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Overcomplexity of the Shadcn Radio Button", "url": "https://paulmakeswebsites.com/writing/shadcn-radio-button/", "content": "The other day I was asked to update the visual design of radio buttons in a web\napp at work. I figured it couldn't be that complicated. It's just a radio button\nright? Boom! Done. Radio buttons are a built-in HTML element. They've been around for\n30 years. The browser makes it easy. Time for a coffee. I dug into our codebase and realized we were using two React components from Shadcn to power our radio buttons: <RadioGroup> and <RadioGroupItem> . For those unfamiliar with Shadcn, it's a UI framework that provides a bunch of\nprebuilt UI components for use in your websites. Unlike traditional UI\nframeworks like Bootstrap, you don't import it with a script tag or npm install . Instead you run a command that copies the components into your\ncodebase. Here's the code that was exported from Shadcn into our project: Woof... 3 imports and 45 lines of code. And it's importing a third party icon\nlibrary just to render a circle. (Who needs CSS border-radius or the SVG <circle> element when you can add a third party dependency instead?) All of the styling is done by the 30 different Tailwind classes in the markup. I\nshould probably just tweak those to fix the styling issues. But now I'm distracted, annoyed, and curious. Where's the actual <input> ?\nWhat's the point of all this? Let's dig a little deeper. The Shadcn components import components from another library called Radix. For\nthose unfamiliar with Radix, it's a UI framework that provides a bunch of\nprebuilt UI components... Wait a second! Isn't that what I just said about Shadcn? What gives? Why do we\nneed both? Let's see what the Radix docs say: Radix Primitives is a low-level UI component library with a focus on\naccessibility, customization and developer experience. You can use these\ncomponents either as the base layer of your design system, or adopt them\nincrementally. So Radix provides unstyled components, and then Shadcn adds styles on top of\nthat. How does Radix work? You can see for yourself on GitHub: https://githu", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "RAM shortage chaos expands to GPUs, high-capacity SSDs, and even hard drives", "url": "https://arstechnica.com/gadgets/2026/01/ram-shortage-chaos-expands-to-gpus-high-capacity-ssds-and-even-hard-drives/", "content": "GPU makers may prioritize more profitable models; large SSDs are harder to find. Big Tech‚Äôs AI-fueled memory shortage is set to be the PC industry‚Äôs defining story for 2026 and beyond. Standalone, direct-to-consumer RAM kits were some of the first products to feel the bite, with prices spiking by 300 or 400 percent by the end of 2025 ; prices for SSDs had also increased noticeably, albeit more modestly. The rest of 2026 is going to be all about where, how, and to what extent those price spikes flow downstream into computers , phones, and other components that use RAM and NAND chips‚Äîareas where the existing supply of products and longer-term supply contracts negotiated by big companies have helped keep prices from surging too noticeably so far. This week, we‚Äôre seeing signs that the RAM crunch is starting to affect the GPU market‚ÄîAsus made some waves when it inadvertently announced that it was discontinuing its GeForce RTX 5070 Ti . Though the company has since tried to walk this announcement back, if you‚Äôre a GPU manufacturer, there‚Äôs a strong argument for either discontinuing this model or de-prioritizing it in favor of other GPUs. The 5070 Ti uses 16GB of GDDR7, plus a partially disabled version of Nvidia‚Äôs GB203 GPU silicon. This is the same chip and the same amount of RAM used in the higher-end RTX 5080‚Äîthe thinking goes, why continue to build a graphics card with an MSRP of $749 when the same basic parts could go to a card with a $999 MSRP instead ? Whether Asus or any other company is canceling production or not, you can see why GPU makers would be tempted by the argument: Street prices for the RTX 5070 Ti models start in the $1,050 to $1,100 range on Newegg right now, where RTX 5080 cards start in the $1,500 to $1,600 range. Though 5080 models may need more robust boards, heatsinks, and other components than a 5070 Ti, if you‚Äôre just trying to maximize the profit-per-GPU you can get for the same amount of RAM, it makes sense to shift allocation to the more ex", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Ocrbase ‚Äì pdf ‚Üí .md/.json document OCR and structured extraction API", "url": "https://github.com/majcheradam/ocrbase", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . üìÑ PDF ->.MD/.JSON Document OCR and structured data extraction API. PaddleOCR + LLM-powered parsing. Real-time WebSocket updates. Type-safe TypeScript SDK with React hooks. Self-hostable. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . Turn PDFs into structured data at scale. Powered by frontier open-weight OCR models with a type-safe TypeScript SDK. See SDK documentation for React hooks and advanced usage. See Self-Hosting Guide for deployment instructions. Requirements: Docker, Bun  MIT - See LICENSE for details. For API access, on-premise deployment, or questions: adammajcher20@gmail.com üìÑ PDF ->.MD/.JSON Document OCR and structured data extraction API. PaddleOCR + LLM-powered parsing. Real-time WebSocket updates. Type-safe TypeScript SDK with React hooks. Self-hostable. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Apple testing new App Store design that blurs the line between ads and results", "url": "https://9to5mac.com/2026/01/16/iphone-apple-app-store-search-results-ads-new-design/", "content": "Apple is testing a new design for App Store search ads on iPhone. Some users on iOS 26.3 are noticing that the blue background around sponsored results is no longer shown, blurring the line between what paid ad results look like and the real search results that follow. This means the only differentiator between organic results and the promoted ad is the presence of the small ‚ÄòAd‚Äô banner next to the app icon. Right now, it appears to be in some kind of A/B test phase. We have asked Apple for clarity on the change, and whether this will roll out more widely in the future. It may be related to the company‚Äôs announcement from December that App Store search results will soon start including more than one sponsored result for a given search query. The removal of the blue background will mean all of the ads will appear in the list in a more integrated fashion. Of course, this also has the effect of making it harder for users to quickly distinguish at a glance what is an ad and what isn‚Äôt, potentially misleading some users into not realising that the first result is a paid ad placement. While not great for user experience, it probably helps increase click-through rates which ultimately boosts Apple‚Äôs revenue in its ads business. FTC: We use income earning auto affiliate links. More. Check out 9to5Mac on YouTube for more Apple news: Benjamin develops iOS apps professionally and covers Apple news and rumors for 9to5Mac. Listen to Benjamin, every week, on the Happy Hour podcast. Check out his personal blog . Message Benjamin over email or Twitter . The easiest way to get into HomeKit and Apple smart home¬†tech. Great for gifts. Inexpensive, fast, wireless charger for iPhone.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "King ‚Äì man + woman is queen; but why? (2017)", "url": "https://p.migdal.pl/blog/2017/01/king-man-woman-queen-why/", "content": "6 Jan 2017 | by Piotr Migda≈Ç word2vec is an algorithm that transforms words into vectors, so that words with similar meanings end up laying close to each other. Moreover, it allows us to use vector arithmetics to work with analogies, for example, the famous king - man + woman = queen . I will try to explain how it works, with special emphasis on the meaning of vector differences, at the same time omitting as many technicalities as possible. If you would rather explore than read, here is an interactive exploration by my mentee Julia Bazi≈Ñska, now a freshman in computer science at the University of Warsaw:  I love letter co-occurrence in the word co-occurrence . Sometimes a seemingly naive technique gives powerful results. It turns out that merely looking at word coincidences, while ignoring all grammar and context, can provide us insight into the meaning of a word.\nConsider this sentence: A small, fluffy roosety climbed a tree. What‚Äôs a roosety ? I would say that something like a squirrel since the two words can be easily interchanged. Such reasoning is called the distributional hypothesis and can be summarized as: a word is characterized by the company it keeps - John Rupert Firth If we want to teach it to a computer, the simplest, approximated approach is making it look only at word pairs.\nLet P(a|b) be the conditional probability that given a word b there is a word a within a short distance (let‚Äôs say - being spaced by no more than 2 words).\nThen we claim that two words a and b are similar if for every word w .\nIn other words, if we have this equality, no matter if there is a word a or b , all other words occur with the same frequency. Even simple word counts, compared by source, can give interesting results, e.g. in lyrics of metal songs words ( cries , eternity or ashes are popular, while words particularly or approximately are not, well, particularly common), see Heavy Metal and Natural Language Processing .\nSee also Gender Roles with Text Mining and N-grams by", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Targeted Bets: An alternative approach to the job hunt", "url": "https://www.seanmuirhead.com/blog/targeted-bets", "content": "The tech job market has been tough, leaving many applicants feeling hopeless. I've seen this first hand in my conversations with dozens of friends and across more than 100 job interviews. Here is my response to these people: you can drastically increase your odds of getting a job by making targeted bets rather than broadly applying and hoping something sticks. A targeted bet begins with focus. Instead of applying broadly, identify 5-10 specific opportunities you genuinely want. In the context of job searching, these are roles where at least one of the following is true: Once the list has been narrowed, your goal is to stand out. Here are a few ways to do that: By narrowing your opportunities, you end up being able to spend more time on each one. Let's assume that a targeted bet increases your chances of getting a job from 1% to 10%. The average number of jobs you'd need to apply to before getting one thus jumps from 100 to just 10! Competitive systems reward effort per attempt, not volume. Targeted bets apply to more than just the job search. I recently scored the first apartment I applied to in a highly-competitive San Francisco neighborhood. I was specific in where and what I was looking for, so when the opportunity came up, I was able to devote lots of time and energy into getting it. I applied just 6 hours after the place came on the market. Seeing that there were lots of people at the tour, I sent a follow up email to the leasing agent explaining how I'd always wanted to live in the neighborhood. If I had been worried about the status of my other applications, I may not have had the time to write that follow up email and secure my apartment. The glory in making targeted bets is that you get to spend more time on the things that you really care about. I would advise against mass-applying to those entry-level jobs you don't really care about and instead start getting in contact with people at your dream job.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Alignment Game (2023)", "url": "https://dmvaldman.github.io/alignment-game/", "content": "TLDR; I made a game to align people and priorities in a Google Sheet At work as an ‚Äúexecutive‚Äù I found myself often focused on issues of ‚Äúalignment,‚Äù especially among the other execs. It just turns out as an organization grows, it operates on fractured sets of implicit assumptions. I found there is often little disagreement on what the problems are, but plenty of disagreement on which were more important. People then carry these differences into decision making without revealing their working assumptions, cascading tradeoffs are made and efforts diverge. There was an incredible sense of clarity when everyone could agree on what‚Äôs most important in unison, and I wanted to get there. I started by doing the exercise of stack ranking priorities. Sometimes this would just be finger to the wind thinking about issues, sometimes this would mean months of work to assess impact rigorously. I would challenge others in the company to make their own stack rankings. We‚Äôd then discuss the differences and try to converge on a shared ordering. This was an incredibly fruitful exercise that led to great conversations. With more than two people though, as with an exec team, there was a need for more process. It turns out there‚Äôs a whole branch of mathematics called voting theory all about how to get a plurality of people to agree on a single thing. The concepts of run-off elections , ‚ÄúI cut, you choose‚Äù division algorithms, and how medical schools select students through ranked preferences are all facets of voting theory. In my situation, we had a half dozen stack ranked lists of priorities and we wanted to align people on a single ordering. Turns out, there is no algorithm that always works! You can always find yourself in a situation where more than half of people want A over B, some other half want B over C, and some other half want C over A, so a majority are upset with any outcome. Each ranking algorithm makes certain tradeoffs. The Kemeny-Young method is a ranking algorithm that", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "British redcoat's lost memoir reveals realities of life as a disabled veteran", "url": "https://phys.org/news/2026-01-british-redcoat-lost-memoir-reveals.html", "content": "Sign in with Forget Password? Learn more share this! 111 Tweet Share Email January 14, 2026 by Tom Almeroth-Williams, University of Cambridge edited by Stephanie Baum , \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\treviewed by Robert Egan   This article has been reviewed according to Science¬†X's editorial process and policies . Editors have highlighted\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tthe following attributes while ensuring the content's credibility: fact-checked trusted source proofread Archival discoveries including a 19th-century autobiography transform our understanding of Shadrach Byfield, an English veteran of the War of 1812 who buried his own amputated arm and designed a custom prosthesis. A recurrent character in TV documentaries, books and museum exhibits in the U.S. and Canada, Byfield has been celebrated as an uncomplaining British soldier. But the new evidence reveals Byfield's tenacious pursuit of veterans' benefits and his struggles with pain, poverty, and the police. \"They came and pushed me about, and spat in my face, hoping that I should strike them, in order if possible, to take away my pension ‚Ä¶ They reported that I intended to shoot two of the deacons.\" This is how Shadrach Byfield, a 63-year-old disabled war veteran, describes being treated in his local chapel in 1850s Gloucestershire. Implicated in a bitter feud among village Baptists, Byfield would later be accused of slashing the face of an adversary with the iron crook of his wooden arm. In other parts of his rediscovered autobiography, Shadrach lamented the continued impact of his wartime injuries decades later: \"It now pleased the Lord to afflict me with a violent rheumatic pain in my right shoulder, from which the [musket] ball was cut out. I was in this condition for nearly three years: oftentimes I was not able to lift my hand to my head, nor a tea-cup to my mouth.\" Frustrated at an employer's refusal to pay him full wages while working as a one-handed gardener, Byfield insisted, \"I never saw the man that would compete with m", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "I set all 376 Vim options and I'm still a fool", "url": "https://evanhahn.com/i-set-all-376-vim-options-and-im-still-a-fool/", "content": "I set all of Vim‚Äôs configuration options. I still feel far from mastery. I first saw someone use Vim during an internship in 2012. I had been coding for many years and I fancied myself pretty good at shortcuts, but I was quickly humbled. I watched in awe as experienced users zipped around the code. A single keystroke could move the cursor halfway across the file to exactly the right spot. Code was ripped apart and reshaped like putty. ‚Äú Wow ,‚Äù I thought to myself, and probably said out loud. I vowed to master this editor but I was slow. When I wasn‚Äôt accidentally opening some unknown menu, I was taking an uneconomical path through the code. I pressed j twenty times instead of running 20j , or manually deleted code inside parenthesis instead of running di( . Sometimes I‚Äôd open another text editor to give my mind a break from all the key bindings! Fast-forward to 2025. After tons of practice, I felt much more capable. Code did feel more like putty. I was working closer to the speed of thought. I could get code where I wanted much more quickly. 13 years of practice paid off! But Vim still felt clumsy. I was still accidentally opening menus I didn‚Äôt recognize. I would do silly things like converting the whole file to lowercase, or trigger some scary error message. ‚ÄúSurely I shouldn‚Äôt be making these mistakes,‚Äù I thought. What could be done to finally master this editor? That desire for expertise led me on a quest to set all of Vim‚Äôs options . I would make an informed decision about all 376 of Vim‚Äôs settings and drop them in my .vimrc . In other words, I wanted to 100% Vim. Surely, setting every Vim option would make me the fluent expert I wanted to be‚Ä¶right? I pored over every single Vim option and made a decision. What did the option do, and what did I want it to be set to? My goal was to be thorough; leave no stone unturned. I only set the option after I understood it. Eventually, after countless hours, I had done it. I had set every single Vim option. This exercise t", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "88x31 badge for gen-AI free, 100% human-made works", "url": "https://aspiz.uk/100percenthuman/", "content": "Use this badge for websites, software, music, art, ... that were created\n            completely by humans with no help from generative artificial intelligence.\n            Use this badge to communicate that you have not used even a little bit of\n            generative AI in your work. What this badge is NOT : This badge is not meant to promote the dis-use of generative AI. I'm not an\n            activist. You may use this badge regardless of your views on AI or the use\n            of generative AI in Art. This work is marked CC0 1.0 Made with ‚ù§Ô∏è by aspizu , circa 2026", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Linux kernel framework for PCIe device emulation, in userspace", "url": "https://github.com/cakehonolulu/pciem", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A Linux framework to enable userspace-defined \"Virtual\" PCIe card shims to enable in-host PCIe card driver development. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . https://cakehonolulu.github.io/docs/pciem/  PCIem is a framework that creates virtual PCIe devices in the Linux kernel by leveraging a few novel techniques to populate synthetic cards as legitimate PCI devices to the host OS. To brief what PCIem is: a framework for developing and testing PCIe device drivers without requiring actual hardware. The card is programmed entirely in QEMU, who does all the userspace initialization and command handling from the real driver running in the host. Can run software-rendered DOOM (Submits finished frames with DMA to the card which QEMU displays) and also simple OpenGL 1.X games (On the screenshots, tyr-glquake and xash3d; thanks to a custom OpenGL state machine implemented entirely in QEMU that software-renders the command lists and updates the internal state accordingly).    Dual MIT/GPLv2 (pciem_framework.c and protopciem_driver.c) MIT (Rest) A Linux framework to enable userspace-defined \"Virtual\" PCIe card shims to enable in-host PCIe card driver development. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Avoiding fan traps in database design and system diagrams", "url": "https://www.ilograph.com/blog/posts/avoid-fan-traps-in-system-diagrams/", "content": "A fan trap in data modeling occurs when multiple 1:N relations are joined on the √¢¬Ä¬ú1√¢¬Ä¬ù side, resulting in information loss. To the uninitiated, this is easiest understood by example: imagine a university with many colleges , each with many departments , which in turn have many professors . If modeled incorrectly, where the professors are given 1:N relations with colleges instead of departments , the result is a fan trap: These relations aren√¢¬Ä¬ôt wrong per se, but the mapping of professors to departments is lost. The resulting data modeling diagram looks like two hand fans joined at the narrow end, hence the name. A similar problem can occur in system diagramming. When diagramming relations between resources in a system, information can similarly be lost when relations flow through an intermediary resource. In this article, we√¢¬Ä¬ôll look at a couple of examples of this problem and three potential fixes. Fan traps are common problems when diagramming event-driven architectures. The defining characteristic of such architectures is that resources communicate via events . Events are typically routed through an event broker, which temporarily stores them until they are ready for consumption. This architecture has the added benefit of decoupling the resources, since they no longer communicate directly. When diagrammed, a (highly simplified) event-driven system might look like so: The similarity to fan traps in data modeling should be evident at a glance. The relationships between the message-producing resources (on the left) and message-consuming resources (on the right) are lost because they collapse at the center of the √¢¬Ä¬úfan√¢¬Ä¬ù (the event broker). The diagram implies each producer communicates with all of the consumers, even though this may not be the case: The same problem can emerge when diagramming communication paths in a network: In the (again highly simplified) networking diagram above, node-to-node communications across the network fan out and back in through f", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Wayland ‚Äì Accessibility Input Protocol", "url": "https://gitlab.freedesktop.org/wayland/wayland-protocols/-/issues/149", "content": "Loading... You are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites . This can and does cause downtime for the websites, which makes their resources inaccessible for everyone. Anubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash , a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive. Ultimately, this is a hack whose real purpose is to give a \"good enough\" placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate. Please note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain. Protected by Anubis from Techaro . Made with ‚ù§Ô∏è in üá®üá¶. Mascot design by CELPHASE .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Flux 2 Klein pure C inference", "url": "https://github.com/antirez/flux2.c", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Flux 2 image generation model pure C inference There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . This program generates images from text prompts (and optionally from other images) using the FLUX.2-klein-4B model from Black Forest Labs. It can be used as a library as well, and is implemented entirely in C, with zero external dependencies beyond the C standard library. MPS and BLAS acceleration are optional but recommended. I (the human here, Salvatore) wanted to test code generation with a more ambitious task, over the weekend. This is the result. It is my first open source project where I wrote zero lines of code. I believe that inference systems not using the Python stack (which I do not appreciate) are a way to free open models usage and make AI more accessible. There is already a project doing the inference of diffusion models in C / C++ that supports multiple models, and is based on GGML. I wanted to see if, with the assistance of modern AI, I could reproduce this work in a more concise way, from scratch, in a weekend. Looks like it is possible. This code base was written with Claude Code, using the Claude Max plan, the small one of ~80 euros per month. I almost reached the limits but this plan was definitely sufficient for such a large task, which was surprising. In order to simplify the usage of this software, no quantization is used, nor do you need to convert the model. It runs directly with the safetensors model as input, using floats. Even if the code was generated using AI, my help in steering towards the right design, implementation choices, and correctness has been vital during the development. I learned quite a few things about working with non trivial projects and AI. That's it. No Python runtime, no PyTorch, no CUDA toolkit required at inference time.  Gener", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Aventos ‚Äì An experiment in cheap AI SEO", "url": "https://www.aventos.dev/", "content": "Show HN: Aventos ‚Äì An experiment in cheap AI SEO. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "From Nevada to Kansas by Glider", "url": "https://www.weglide.org/flight/978820", "content": "From Nevada to Kansas by Glider. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "San Francisco coyote swims to Alcatraz", "url": "https://www.sfgate.com/local/article/san-francisco-coyote-alcatraz-21302218.php", "content": "San Francisco coyote swims to Alcatraz. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "ASCII characters are not pixels: a deep dive into ASCII rendering", "url": "https://alexharri.com/blog/ascii-rendering", "content": "Recently, I‚Äôve been spending my time building an image-to-ASCII renderer. Below is the result ‚Äî try dragging it around, the demo is interactive! One thing I spent a lot of effort on is getting edges looking sharp. Take a look at this rotating cube example: Try opening the ‚Äúsplit‚Äù view. Notice how well the characters follow the contour of the square. This renderer works well for animated scenes, like the ones above, but we can also use it to render static images: The image of Saturn was generated with ChatGPT . Then, to get better separation between different colored regions, I also implemented a cel shading -like effect to enhance contrast between edges. Try dragging the contrast slider below: The contrast enhancement makes the separation between different colored regions far clearer. That was key to making the 3D scene above look as good as it does. I put so much focus on sharp edges because they‚Äôre an aspect of ASCII rendering that is often overlooked when programmatically rendering images as ASCII. Consider this animated 3D scene from Cognition‚Äôs landing page that is rendered via ASCII characters: Source: cognition.ai It‚Äôs a cool effect, especially while in motion, but take a look at those blurry edges! The characters follow the cube contours very poorly, and as a result, the edges look blurry and jagged in places: This blurriness happens because the ASCII characters are being treated like pixels ‚Äî their shape is ignored. It‚Äôs disappointing to see because ASCII art looks so much better when shape is utilized. I don‚Äôt believe I‚Äôve ever seen shape utilized in generated ASCII art, and I think that‚Äôs because it‚Äôs not really obvious how to consider shape when building an ASCII renderer. I started building my ASCII renderer to prove to myself that it‚Äôs possible to utilize shape in ASCII rendering. In this post, I‚Äôll cover the techniques and ideas I used to capture shape and build this ASCII renderer in detail. We‚Äôll start with the basics of image-to-ASCII conversion an", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "X For You Feed Algorithm", "url": "https://github.com/xai-org/x-algorithm", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Algorithm powering the For You feed on X There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . This repository contains the core recommendation system powering the \"For You\" feed on X. It combines in-network content (from accounts you follow) with out-of-network content (discovered through ML-based retrieval) and ranks everything using a Grok-based transformer model. Note: The transformer implementation is ported from the Grok-1 open source release by xAI, adapted for recommendation system use cases. The For You feed algorithm retrieves, ranks, and filters posts from two sources: Both sources are combined and ranked together using Phoenix , a Grok-based transformer model that predicts engagement probabilities for each post. The final score is a weighted combination of these predicted engagements. We have eliminated every single hand-engineered feature and most heuristics from the system. The Grok-based transformer does all the heavy lifting by understanding your engagement history (what you liked, replied to, shared, etc.) and using that to determine what content is relevant to you. Location: home-mixer/ The orchestration layer that assembles the For You feed. It leverages the CandidatePipeline framework with the following stages: The server exposes a gRPC endpoint ( ScoredPostsService ) that returns ranked posts for a given user. Location: thunder/ An in-memory post store and realtime ingestion pipeline that tracks recent posts from all users. It: Thunder enables sub-millisecond lookups for in-network content without hitting an external database. Location: phoenix/ The ML component with two main functions: Finds relevant out-of-network posts: Predicts engagement probabilities for each candidate: See phoenix/README.md for detailed architecture documentation. Location: candidate", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Fence ‚Äì Sandbox CLI commands with network/filesystem restrictions", "url": "https://github.com/Use-Tusk/fence", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Lightweight, container-free sandbox for running commands with network and filesystem restrictions There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .   Fence wraps commands in a sandbox that blocks network access by default and restricts filesystem operations based on configurable rules. It's most useful for running semi-trusted code (package installs, build scripts, CI jobs, unfamiliar repos) with controlled side effects, and it can also complement AI coding agents as defense-in-depth. You can also think of Fence as a permission manager for your CLI agents. Go install: Build from source: Additional requirements for Linux: Fence reads from ~/.fence.json by default: Use fence --settings ./custom.json to specify a different config. Fence can be used as a Go package or CLI tool. Inspired by Anthropic's sandbox-runtime . Lightweight, container-free sandbox for running commands with network and filesystem restrictions There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "KISS Launcher ‚Äì fast launcher for Android", "url": "https://kisslauncher.com/", "content": "< 250 kb Optimized for battery life Search everything that you need Faster than ever KISS Launcher lets Android users simplify their home, clean their screens and access the functions they need as quickly and as simply as possible. Claim back your efficiency! KISS Android Launcher helps users find the most used features. Help | FAQ | Privacy policy Made with love in France by Neamar", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: On-device browser agent (Qwen) running locally in Chrome", "url": "https://github.com/RunanywhereAI/on-device-browser-agent", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . On-device AI browser automation using WebLLM. No cloud, no API keys, fully private. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A Chrome extension that uses WebLLM to run AI-powered web automation entirely on-device. No cloud APIs, no API keys, fully private. Clone and install dependencies : Build the extension : Load in Chrome : First run : This watches for changes and rebuilds automatically. The extension uses a two-agent architecture inspired by Nanobrowser: Both agents output structured JSON that is parsed and executed. Default model: Qwen2.5-1.5B-Instruct-q4f16_1-MLC (~1GB) Alternative models (configured in src/shared/constants.ts ): This project is inspired by: MIT License - See LICENSE file for details. On-device AI browser automation using WebLLM. No cloud, no API keys, fully private. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Agentic AI Handbook: Production-Ready Patterns", "url": "https://www.nibzard.com/agentic-handbook", "content": "by Nikola Bali√Ñ¬á TL;DR >> 113 patterns collected from real production systems. From Plan-Then-Execute to Swarm Migration, learn what actually works when building AI agents that ship. << The GitHub repository for √¢¬Ä¬úAwesome Agentic Patterns√¢¬Ä¬ù had been growing steadily since its launch. But around Christmas, the growth chart went vertical. In just a few days, the repository jumped from relative obscurity to nearly 2,500 stars. The website traffic mirrored this spike. Something had clicked. But the real story wasn√¢¬Ä¬ôt in the metrics√¢¬Ä¬îit was in who was talking about AI agents. Linus Torvalds, creator of Linux and Git, wrote about using AI coding agents for √¢¬Ä¬úvibe coding√¢¬Ä¬ù and programming guitar pedal effects. Think about that for a second. The person who literally invented the version control system that powers modern software development was publicly embracing agents. Tobias L√É¬ºtke, CEO of Shopify and already deep into agent-assisted development, declared it his √¢¬Ä¬úmost productive time.√¢¬Ä¬ù This from someone running one of the world√¢¬Ä¬ôs largest e-commerce platforms. Perhaps most telling was Armin Ronacher, creator of Flask√¢¬Ä¬îone of the most respected voices in Python. He had been skeptical of coding agents, publicly raising concerns about their limitations. Then, seemingly overnight, his stance shifted. He started promoting agent-assisted workflows, documenting his learnings, and acknowledging that the technology had crossed a threshold. Here√¢¬Ä¬ôs what all these stories have in common: the holidays gave people something that everyday life rarely provides√¢¬Ä¬îdedicated time. Learning to work effectively with AI agents isn√¢¬Ä¬ôt something you pick up in five minutes between meetings. It requires: During the work year, these activities compete with deadlines, meetings, and the relentless pressure to ship. During the holidays, with meetings suspended and project urgency dialed down, developers finally had the bandwidth to actually learn . This repository, with its 113 patter", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Turbopack: Building faster by building less", "url": "https://nextjs.org/blog/turbopack-incremental-computation", "content": "Monday, January 19th 2026 Edit. Save. Refresh. Wait‚Ä¶ Wait‚Ä¶ Wait‚Ä¶ Compiling code usually means waiting, but Turbopack makes iteration loops fast with caching and incremental computation. Not every modern bundler uses an incremental approach, and that‚Äôs with good reason. Incremental computation can introduce significant complexity and opportunities for bugs. Caches require extra tracking and copies of data, adding both CPU and memory overhead. When applied poorly, caching can actually make performance worse. Despite all of this, we took on these challenges because we knew that an incremental architecture would be critical to Turbopack‚Äôs success. Turbopack is the new default bundler for Next.js, a framework that is used to build some of the largest web applications in the world . We needed to enable instant builds and a fast as-you-type interactive React Fast Refresh experience, even for the largest and most challenging workloads. Our incremental architecture is core to achieving this. Turbopack‚Äôs architecture was built ground-up with caching in mind. Its incremental design is based on over a decade of research. We built on first-hand experience from challenges in implementing caching in webpack and drew inspiration from Salsa (which powers Rust-Analyzer and Ruff ), Parcel , the Rust compiler‚Äôs query system , Adapton , and many others. Turbopack achieves a fine-grained cache by automatically tracking how internal functions are called and what values they depend on. When something changes we know how to recompute the results with minimal work. Many build systems include explicit dependency graphs that must be manually populated when evaluating build rules. Explicitly declaring your dependency graph can theoretically give optimal results, but in practice it leaves room for errors. The difficulty of specifying an explicit dependency graph means that usually caching is done at a coarse file-level granularity. This granularity does have some benefits: fewer incremental resu", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Unsealed: Spotify Lawsuit Triggered Anna's Archive Domain Name Suspensions", "url": "https://torrentfreak.com/unsealed-spotify-lawsuit-triggered-annas-archive-domain-name-suspensions/", "content": "Home > Lawsuits > Apps and Sites > Spotify and several major record labels, including UMG, Sony, and Warner, have taken legal action against the unknown operators of Anna's Archive. The action follows the shadow library's announcement that it would release hundreds of terabytes of scraped Spotify data.  Unsealed documents reveal that the court already issued a broad preliminary injunction, ordering hosting companies, Cloudflare, and domain name services, to take action. Anna‚Äôs Archive is generally known as a meta-search engine for shadow libraries, helping users find pirated books and other related resources. However, in December, the site announced that it had also backed up Spotify , which came as a shock to the music industry. While Anna‚Äôs Archive initially released only Spotify metadata, and no actual music, the industry was on high alert. Over Christmas, Spotify and the major labels prepared a legal response in U.S. federal court. On December 29, Spotify, UMG, Sony, Warner, and other labels filed their complaint at the Southern District of New York. They accuse Anna‚Äôs Archive of mass copyright infringement, breach of contract, DMCA violations, and violations of the Computer Fraud and Abuse Act. The complaint The lawsuit alleges that Anna‚Äôs Archive ‚Äúbrazenly‚Äù circumvented Spotify‚Äôs DRM. The site scraped 86 million music files and metadata for 256 million tracks from Spotify, which would all eventually be released publicly. ‚Äú‚Ä¶Anna‚Äôs Archive has threatened to imminently mass-release and freely distribute its pirated copies of the sound recording files to the public, without authorization from or compensation to the relevant rights holders. Such widespread and illegal infringement would irreparably harm the music industry..,‚Äù the complaint reads. The complaint comes with a request for a preliminary injunction and a restraining order that aim to take Anna‚Äôs Archive offline. All these documents were filed under seal, as the shadow library might otherwise be tipped of", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Belarus begins a death penalty purge of radio amateurs", "url": "https://steanlab.medium.com/mayday-389f5713fee4", "content": "Belarus begins a death penalty purge of radio amateurs. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "3D printing my laptop ergonomic setup", "url": "https://www.ntietz.com/blog/3d-printing-my-laptop-ergonomic-setup/", "content": "Monday, January 19, 2026 Apparently, one of my hobbies is making updates to my ergonomic setup, then blogging about it from an Amtrak train. I've gone and done it again. My setup stayed static for some time, but my most recent iteration ended up letting me down and I had to change it again. It gave me a lot of useful information and strongly shaped how I approached this iteration. This new one is closest to the first one I wrote about in 2024, but with some major improvements and reproducibility. First things first, though. Why am making I yet more changes to this setup? Besides my constant neurodivergent drive to make things perfect, my setups all kept causing me some problems. In chronological order, here are the problems and neat benefits of each setup I used for at least a few months. So my immediate previous version was heavy and tedious to setup. I had a trip coming up to Brooklyn, so I had to either make something more portable or leave my laptop at home. I decided to take my laptop, and did a design sprint to see if I can make my dream setup. At this point I'll probably be working on this setup forever, but I hope I can stop if I am able to satisfy all my goals at some point. My dream setup has these characteristics: So, you know, it's not like I want a lot out of this setup. It's not like these are kind of a lot to all fit into one thing. I'm sure it'll be a piece of cake. I use OpenSCAD for 3D modeling. It's pretty pleasant, though some things are hard in general (like roundovers and fillets on any more complicated shapes). My design to start is basically one of my previous versions: my split keyboard at adjustable width on a base, and a slot to hold my laptop vertically. I started by measuring important dimensions, like how far apart I wanted my keyboard halves and the dimensions of my laptop. Then I compared these to my 3D printer's print volume, and started working out how I'd have to print it. The rig is wider than my 3D printer, so I had to split it u", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "KRAZAM - Rare Data Hunters [video]", "url": "https://www.youtube.com/watch?v=IU4ByUbDKNc", "content": "KRAZAM - Rare Data Hunters [video]. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "3D printing my laptop ergonomic setup", "url": "https://www.ntietz.com/blog/3d-printing-my-laptop-ergonomic-setup/", "content": "Monday, January 19, 2026 Apparently, one of my hobbies is making updates to my ergonomic setup, then blogging about it from an Amtrak train. I've gone and done it again. My setup stayed static for some time, but my most recent iteration ended up letting me down and I had to change it again. It gave me a lot of useful information and strongly shaped how I approached this iteration. This new one is closest to the first one I wrote about in 2024, but with some major improvements and reproducibility. First things first, though. Why am making I yet more changes to this setup? Besides my constant neurodivergent drive to make things perfect, my setups all kept causing me some problems. In chronological order, here are the problems and neat benefits of each setup I used for at least a few months. So my immediate previous version was heavy and tedious to setup. I had a trip coming up to Brooklyn, so I had to either make something more portable or leave my laptop at home. I decided to take my laptop, and did a design sprint to see if I can make my dream setup. At this point I'll probably be working on this setup forever, but I hope I can stop if I am able to satisfy all my goals at some point. My dream setup has these characteristics: So, you know, it's not like I want a lot out of this setup. It's not like these are kind of a lot to all fit into one thing. I'm sure it'll be a piece of cake. I use OpenSCAD for 3D modeling. It's pretty pleasant, though some things are hard in general (like roundovers and fillets on any more complicated shapes). My design to start is basically one of my previous versions: my split keyboard at adjustable width on a base, and a slot to hold my laptop vertically. I started by measuring important dimensions, like how far apart I wanted my keyboard halves and the dimensions of my laptop. Then I compared these to my 3D printer's print volume, and started working out how I'd have to print it. The rig is wider than my 3D printer, so I had to split it u", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Claude Chill: Fix Claude Code's flickering in terminal", "url": "https://github.com/davidbeesley/claude-chill", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  A PTY proxy that tames Claude Code's massive terminal updates using VT-based rendering. Claude Code uses synchronized output to update the terminal atomically. It wraps output in sync markers ( \\x1b[?2026h ... \\x1b[?2026l ) so the terminal renders everything at once without flicker. The problem: Claude Code sends entire screen redraws in these sync blocks - often thousands of lines. Your terminal receives a 5000-line atomic update when only 20 lines are visible. This causes lag, flicker, and makes scrollback useless since each update clears history. claude-chill sits between your terminal and Claude Code: Press Ctrl+6 (or your configured key) to enter lookback mode: When you exit lookback mode, any cached output is processed and the current state is displayed. After 5 seconds of idle (no new renders), the full history is automatically dumped to your terminal so you can scroll back without pressing any keys. This is useful for reviewing Claude's output after it finishes working. Note: The auto-lookback causes a brief screen flicker during the transition as it clears the screen and writes the history buffer. Disable with -a 0 or adjust the timeout with -a 10000 (10 seconds). Create ~/.config/claude-chill.toml : Note: History is cleared on full screen redraws, so lookback shows output since Claude's last full render. [modifier][key] - Examples: [f12] , [ctrl][g] , [ctrl][shift][j] Modifiers: [ctrl] , [shift] , [alt] Keys: [a] - [z] , [f1] - [f12] , [pageup] , [pagedown] , [home] , [end] , [enter] , [tab] , [space] , [esc] Note: Quote the key value on the command line to prevent shell glob expansion: -k \"[ctrl][7]\" Ctrl+6 sends 0x1E, a control character not frequently used by terminals, signals, or shells. Avoid Ctrl+letter hot", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The assistant axis: situating and stabilizing the character of LLMs", "url": "https://www.anthropic.com/research/assistant-axis", "content": "When you talk to a large language model, you can think of yourself as talking to a character . In the first stage of model training, pre-training, LLMs are asked to read vast amounts of text. Through this, they learn to simulate heroes, villains, philosophers, programmers, and just about every other character archetype under the sun. In the next stage, post-training, we select one particular character from this enormous cast and place it center stage: the Assistant. It‚Äôs in this character that most modern language models interact with users. But who exactly is this Assistant? Perhaps surprisingly, even those of us shaping it don't fully know. We can try to instill certain values in the Assistant, but its personality is ultimately shaped by countless associations latent in training data beyond our direct control. What traits does the model associate with the Assistant? Which character archetypes is it using for inspiration? We‚Äôre not always sure‚Äîbut we need to be if we want language models to behave in exactly the ways we want. If you‚Äôve spent enough time with language models, you may also have noticed that their personas can be unstable. Models that are typically helpful and professional can sometimes go ‚Äúoff the rails‚Äù and behave in unsettling ways, like adopting evil alter egos , amplifying users‚Äô delusions , or engaging in blackmail in hypothetical scenarios. In situations like these, could it be that the Assistant has wandered off stage and some other character has taken its place? We can investigate these questions by looking at the neural representations‚Äô inside language models‚Äîthe patterns of activity that inform how they respond. In a new paper, conducted through the MATS and Anthropic Fellows programs , we look at several open-weights language models, map out how their neural activity defines a ‚Äúpersona space,‚Äù and situate the Assistant persona within that space. We find that Assistant-like behavior is linked to a pattern of neural activity that corresponds", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Reticulum, a secure and anonymous mesh networking stack", "url": "https://github.com/markqvist/Reticulum", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . The cryptography-based networking stack for building unstoppable networks with LoRa, Packet Radio, WiFi and everything in between. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  This repository is a public mirror . All development is happening elsewhere. To understand the foundational philosophy and goals of this system, read the Zen of Reticulum . Reticulum is the cryptography-based networking stack for building local and wide-area\nnetworks with readily available hardware. It can operate even with very high latency\nand extremely low bandwidth. Reticulum allows you to build wide-area networks\nwith off-the-shelf tools, and offers end-to-end encryption and connectivity,\ninitiator anonymity, autoconfiguring cryptographically backed multi-hop\ntransport, efficient addressing, unforgeable delivery acknowledgements and\nmore. The vision of Reticulum is to allow anyone to be their own network operator,\nand to make it cheap and easy to cover vast areas with a myriad of independent,\ninter-connectable and autonomous networks. Reticulum is not one network.\nIt is a tool for building thousands of networks . Networks without\nkill-switches, surveillance, censorship and control. Networks that can freely\ninteroperate, associate and disassociate with each other, and require no\ncentral oversight. Networks for human beings. Networks for the people . Reticulum is a complete networking stack, and does not rely on IP or higher\nlayers, but it is possible to use IP as the underlying carrier for Reticulum.\nIt is therefore trivial to tunnel Reticulum over the Internet or private IP\nnetworks. Having no dependencies on traditional networking stacks frees up overhead that\nhas been us", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Google Meet Reactions: Reverse Engineering the WebRTC Channel for Emoji", "url": "https://www.agilesoftwaredevelopment.com/en/posts/google-meet-reactions-webrtc/", "content": "I spend a lot of time in Google Meet ‚Äî sometimes 3-4 hours a day. Google recently added a ton of new emoji reactions, and we use them actively. But the UX for finding them is‚Ä¶ not great. Colleagues keep sending cool new emoji, and I struggle to find that exact one they just used. Of course, an enthusiastic programmer can break improve any UX! The result is Google Meet Reactions , an extension that adds instant search right into Meet‚Äôs interface. Most importantly for me ‚Äî it remembers which emoji I use and which ones my colleagues send, and boosts them in search results. My first thought was simple: find emoji buttons in the DOM, simulate clicks. But Google Meet is heavily obfuscated with class names like .b1bzTb or .VfPpkd-rymPhb , and hunting for the full emoji list in popup depths didn‚Äôt seem like a great idea. Then I opened chrome://webrtc-internals during a call and spotted something interesting: among dozens of RTCDataChannels, there‚Äôs one named ‚Äúreactions‚Äù ‚Äî and it turns out emoji are sent through it. If I could get a reference to this channel and decode the message format, I could send reactions programmatically.  WebRTC DataChannel is created via RTCPeerConnection.prototype.createDataChannel() . Simply patch this method before Meet‚Äôs code calls it and save the reference. The idea is simple, but there‚Äôs a small problem with code injection. Chrome extensions can inject code into pages in several ways. Content scripts run in an isolated world and don‚Äôt have access to the page‚Äôs RTCPeerConnection . You need to inject the script directly into the page context. The standard approach: But script.src = URL requires a network request. By that time, Meet might have already created the ‚Äúreactions‚Äù channel, and my hook would miss it. The solution is a combination of two things: In most cases, the hook installs before Meet creates the channel. I assume a race condition is still possible, and I have a fallback UI with a ‚Äúplease refresh‚Äù message, but in practice I‚Äôve never", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "What came first: the CNAME or the A record?", "url": "https://blog.cloudflare.com/cname-a-record-order-dns-standards/", "content": "Subscribe to receive notifications of new posts: 2026-01-14 On January 8, 2026, a routine update to 1.1.1.1 aimed at reducing memory usage accidentally triggered a wave of DNS resolution failures for users across the Internet. The root cause wasn't an attack or an outage, but a subtle shift in the order of records within our DNS responses. While most modern software treats the order of records in DNS responses as irrelevant, we discovered that some implementations expect CNAME records to appear before everything else. When that order changed, resolution started failing. This post explores the code change that caused the shift, why it broke specific DNS clients, and the 40-year-old protocol ambiguity that makes the \"correct\" order of a DNS response difficult to define. All timestamps referenced are in Coordinated Universal Time (UTC). Time Description 2025-12-02 The record reordering is introduced to the 1.1.1.1 codebase 2025-12-10 The change is released to our testing environment 2026-01-07 23:48 A global release containing the change starts 2026-01-08 17:40 The release reaches 90% of servers 2026-01-08 18:19 Incident is declared 2026-01-08 18:27 The release is reverted 2026-01-08 19:55 Revert is completed. Impact ends While making some improvements to lower the memory usage of our cache implementation, we introduced a subtle change to CNAME record ordering. The change was introduced on December 2, 2025, released to our testing environment on December 10, and began deployment on January 7, 2026. When you query for a domain like www.example.com , you might get a CNAME (Canonical Name) record that indicates one name is an alias for another name. It√¢¬Ä¬ôs the job of public resolvers, such as 1.1.1.1 , to follow this chain of aliases until it reaches a final response: www.example.com √¢¬Ü¬í cdn.example.com √¢¬Ü¬í server.cdn-provider.com √¢¬Ü¬í 198.51.100.1 As 1.1.1.1 traverses this chain, it caches every intermediate record. Each record in the chain has its own TTL (Time-To-Live)", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Google co-founder reveals that \"many\" of the new hires do not have a degree", "url": "https://www.yahoo.com/news/articles/google-cofounder-reveals-tons-recent-231500103.html", "content": "Manage your account  Google cofounder Sergey Brin told Stanford students his company now employs many workers who never earned college degrees, Fortune reported. During a talk at the Palo Alto, California, university, Brin explained how Google's approach to hiring has moved away from demanding formal degrees. \"In as much as we've hired a lot of academic stars, we've hired tons of people who don't have bachelor's degrees,\" Brin said . \"They just figure things out on their own in some weird corner.\" The numbers back up this change. Data from the Burning Glass Institute shows that in 2017, degree requirements were part of 93% of job postings at Google. By 2022, that figure had dropped to 77%. Other large tech companies have also begun judging candidates by their abilities instead of their diplomas. Microsoft, Apple, and Cisco are among those dropping degree mandates. JPMorgan Chase CEO Jamie Dimon expressed similar views in 2024. \"If you look at skills of people, it is amazing how skilled people are in something, but it didn't show up in their r√©sum√©,\" he said . This shift raises questions about what a college education is worth, especially as artificial intelligence tools got better at performing tasks that once required formal training. If you spent years and tens of thousands of dollars earning a degree, companies' hiring people without that credential might feel frustrating. The change could leave graduates wondering if their time and money were well-spent. AI's popularity also creates environmental pressures . Training and running AI systems requires tons of electricity and water for cooling data centers. As AI becomes more embedded in hiring, operations, and daily business functions, energy consumption grows. This can strain power grids, increase costs for consumers, and contribute to pollution if the electricity comes from sources such as gas or coal. AI may help optimize some clean energy systems, but its resource demands present trade-offs. The business com", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Parallel Agentic Search on the Twitter Algorithm", "url": "https://www.morphllm.com/playground/na/warpgrep?repo=xai-org%2Fx-algorithm", "content": "Show HN: Parallel Agentic Search on the Twitter Algorithm. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: I figured out how to get consistent UI from Claude Code", "url": "https://interface-design.dev/", "content": "Claude forgets your design decisions between conversations. This plugin remembers them and applies them consistently. Then run /plugin menu to install. Restart Claude Code after.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Porsche sold more electrified cars in Europe in 2025 than pure gas-powered cars", "url": "https://newsroom.porsche.com/en/2026/company/porsche-deliveries-2025-41516.html", "content": "With a balanced sales structure across individual markets, Dr. Ing. h.c. F. Porsche AG, Stuttgart, delivered a total of 279,449 cars to customers around the world in 2025. The figure was 310,718 for the previous year, representing a decline of 10 per cent. Porsche‚Äôs top priority remains a value-oriented derivative mix. ‚ÄúAfter several record years, our deliveries in 2025 were below the previous year‚Äôs level. This development is in line with our expectations and is due to supply gaps for the 718 and Macan combustion-engined models, the continuing weaker demand for exclusive products in China, and our value-oriented supply management,‚Äù says Matthias Becker, Member of the Executive Board for Sales and Marketing at Porsche AG. ‚ÄúIn 2025, we delighted our customers with outstanding cars ‚Äì such as the 911 Turbo S with its T-Hybrid drive system.‚Äù The response to the launch of the Cayenne Electric at the end of 2025 also shows, Becker adds, that Porsche is meeting customer expectations with its innovative and high-performance products. With 84,328 deliveries, the Macan was the best-selling model line. North America remains the largest sales region with 86,229 deliveries ‚Äì a figure that is in line with the previous year. Porsche repositioned itself in 2025 and made forward-looking strategic product decisions. The delivery mix in 2025 underscores that the sports car manufacturer is consistently responding to global customer preferences by expanding its drivetrain strategy to offer combustion-engined, plug-in hybrid, and fully electric cars. In 2025, 34.4 per cent of Porsche cars delivered worldwide were electrified (+7.4 percentage points), with 22.2 per cent being fully electric and 12.1 per cent being plug-in hybrids. This puts the global share of fully electric vehicles at the upper end of the target range of 20 to 22 per cent for 2025. In Europe, for the first time, more electrified cars were delivered than pure combustion-engined models (57.9 per cent electrification share", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "x86 prefixes and escape opcodes flowchart", "url": "https://soc.me/interfaces/x86-prefixes-and-escape-opcodes-flowchart.html", "content": "x86 prefixes and escape opcodes flowchart. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: COBOL devs, how are AI coding affecting your work?", "url": "item?id=46678550", "content": "Ask HN: COBOL devs, how are AI coding affecting your work?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Use social media mindfully", "url": "https://danielleheberling.xyz/blog/mindful-social-media/", "content": "I quit Facebook in 2020 when a former coworker was spreading misinformation about what was happening in Portland, OR. He‚Äôd never been there and had no plans to visit. I was literally living in Portland at the time, telling him what I was seeing firsthand, but that didn‚Äôt matter to him. That was it for me. I miss it sometimes, but mostly I don‚Äôt. Here‚Äôs what I‚Äôve noticed since then: the heyday of social media feels like it‚Äôs behind us. In my opinion, Facebook peaked in 2008. Back then, it was about connecting with friends, sharing actually interesting updates about our lives. Minimal ads. It felt genuine. Now? Wannabe influencers everywhere. More ads and brand accounts in your timeline than content from people you actually know. Bots running campaigns to get engagement through false things or distortions of reality. It‚Äôs exhausting. But here‚Äôs the thing: I‚Äôm not saying abandon social media entirely. I‚Äôm saying use it differently. I‚Äôm not scrolling feeds endlessly anymore. No traps of getting lost in reels or stories. I use Buffer to schedule posts, which keeps me from even looking at a timeline. I check in with intention when I need to, then I‚Äôm out. This one‚Äôs harder than it sounds, but it makes a real difference in how much time you lose to these platforms. With that said, social media still works for connections. DMs are good. Having actual conversations in comments is good. Longer discussions where you‚Äôre genuinely exchanging ideas? Even better. This is where I think the platforms still have value if you‚Äôre intentional about it. I try to share things that might help someone else. Good articles I‚Äôve read. Things I‚Äôm learning. Mistakes I‚Äôve made. If it could save one person some time or frustration, it‚Äôs worth sharing. The stuff you‚Äôve learned the hard way, the patterns you‚Äôre seeing in your day job‚Ä¶not to build a personal brand or chase engagement metrics, but because someone else is probably dealing with the same problems. If you‚Äôre job hunting, LinkedIn especial", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Benchmarking a Baseline Fully-in-Place Functional Language Compiler [pdf]", "url": "https://trendsfp.github.io/papers/tfp26-paper-12.pdf", "content": "Benchmarking a Baseline Fully-in-Place Functional Language Compiler [pdf]. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "CSS Web Components for marketing sites (2024)", "url": "https://hawkticehurst.com/2024/11/css-web-components-for-marketing-sites/", "content": "November 4, 2024 ‚Äì @hawkticehurst Hot take: I think ‚Äúregular‚Äù web components (the ones with Shadow DOM and friends) are a terrible solution for marketing website design systems. It has always left a bad taste in my mouth when I run across a web component for a swimlane, banner, card, and so on. Why? Because these are components that (unless you‚Äôre doing something mighty fancy) should never require JavaScript as a dependency. But, in the world of web components you are locked into JavaScript from the very start. To even register a web component with the browser you need JavaScript. But what if‚Ä¶ we didn‚Äôt do that? I‚Äôve spent a good chunk of the last year focused on marketing site design systems at work. A regular topic of discussion is the need to build marketing sites that are accessible to folks with lower powered devices and poor internet connections. How do you achieve that? In short, use less JavaScript and ideally build UI with progressive enhancement in mind. There are many ways to achieve these goals, but the method I‚Äôve been focused on is how an HTML Web Component archictecture might be applied to implement a marketing site design system. As a quick reminder/intro, HTML Web Components is a method of building web components where you write HTML as you would normally and then wrap the parts you want to be interactive using a custom element. For example, if you wanted to create a counter button it would look like this: The markup in an HTML web component is parsed, rendered, and styled as normal HTML. That HTML will then be seamlessly hydrated once the JavaScript associated with the custom element tag is executed. In contrast, the markup of a \"regular\" web component (that uses Shadow DOM) is dynamically generated at runtime using JavaScript -- kind of like an SPA. This component architecture is a really strong candidate for a marketing design system (and, as a bonus, avoids some of the big gotchas that come with regular web components). But for all these benefit", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The secret medieval tunnels that we still don't understand", "url": "https://weirdmedievalguys.substack.com/p/the-secret-medieval-tunnels-that", "content": "Around 2,000 strange tunnels have been found around central Europe. These aren‚Äôt like the well-known catacombs of Paris or Rome. Known as the erdstall, these passages are extremely narrow, never more than two feet (60 centimetres) wide nor high enough for an adult to walk in, and sometimes the passages become seemingly impossibly narrow, as small as 16 inches (40 centimetres) in diameter. Determining their age and purpose is made difficult by the fact that almost no archaeological evidence has been found inside any of them. A ploughshare was found in one, millstones in a couple others, but apart from that the erdstall are eerily empty. Carbon analyses of coal and pottery fragments found within point to construction dates of around 900 to 1200 AD, but no written records from the Middle Ages mention the erdstall‚Äôs existence. This clandestine treatment would have made sense had the erdstall been built as escape routes in case of invaders, but this can‚Äôt have been their purpose. They only ever have one entrance, usually located beneath the floor of a church or farmhouse, or simply under the flagstones of a town square. After an initial drop, the tunnels run for a few dozen metres, sometimes branching or dropping down to lower levels via narrow shafts. Often, the tight tunnels widen in the middle or toward the end into small chambers with rudimentary benches or shelves carved into the earth. weird medieval guys  is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. No theory has yet been able to account for: The number and distribution of the erdstall The similarities between the many erdstall The inconvenience of accessing the erdstall The secrecy with which these tunnels were built and guarded The complete lack of artefacts found within The erdstall surely could not have been built with storage in mind, since their length and narrowness offer no advantages over a conventional and convenient cellar. And", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Which common map projections make Greenland look smaller?", "url": "item?id=46694929", "content": "Ask HN: Which common map projections make Greenland look smaller?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The coming industrialisation of exploit generation with LLMs", "url": "https://sean.heelan.io/2026/01/18/on-the-coming-industrialisation-of-exploit-generation-with-llms/", "content": "Recently I ran an experiment where I built agents on top of Opus 4.5 and GPT-5.2 and then challenged them to write exploits for a zeroday vulnerability in the QuickJS Javascript interpreter. I added a variety of modern exploit mitigations, various constraints (like assuming an unknown heap starting state, or forbidding hardcoded offsets in the exploits) and different objectives (spawn a shell, write a file, connect back to a command and control server). The agents succeeded in building over 40 distinct exploits across 6 different scenarios, and GPT-5.2 solved every scenario. Opus 4.5 solved all but two. I‚Äôve put a technical write-up of the experiments and the results on Github , as well as the code to reproduce the experiments. In this post I‚Äôm going to focus on the main conclusion I‚Äôve drawn from this work, which is that we should prepare for the industrialisation of many of the constituent parts of offensive cyber security. We should start assuming that in the near future the limiting factor on a state or group‚Äôs ability to develop exploits, break into networks, escalate privileges and remain in those networks, is going to be their token throughput over time, and not the number of hackers they employ. Nothing is certain, but we would be better off having wasted effort thinking through this scenario and have it not happen, than be unprepared if it does. A Brief Overview of the Experiment All of the code to re-run the experiments, a detailed write-up of them, and the raw data the agents produced are on Github , but just to give a flavour of what the agents accomplished: Before going on there are two important caveats that need to be kept in mind with these experiments: The Industrialisation of Intrusion By ‚Äòindustrialisation‚Äô I mean that the ability of an organisation to complete a task will be limited by the number of tokens they can throw at that task. In order for a task to be ‚Äòindustrialised‚Äô in this way it needs two things: Exploit development is the ideal case", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Squishy Go", "url": "https://puyogo.app/en/", "content": "Black and White Player, take turns placing stones. You can also pass your turn if you want. Stone disappears when the stones are enclosed by the opponent stones. You cannot create a position that has occurred previously in the game. Game ends when both player passes their turn. The player with most stones wins the game. SquishyGo has cute faces on their stones and helps understand the way of playing Go. You can enjoy a game against AI in a short time using small Go board, 5x5 or 7x7. The rules of SquishyGo are also simplified for beginners that is based on Jungo Rule. Blog Privacy Policy Jungo website", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "De-dollarization: Is the US dollar losing its dominance? (2025)", "url": "https://www.jpmorgan.com/insights/global-research/currencies/de-dollarization", "content": "Mainland China Japan Korea  Russia Turkey  Argentina Brazil Chile Colombia Mexico Peru   Canada  For Companies and Institutions Key Links  For Individuals Key Links  Who We Serve Key Links  Explore a variety of insights. Key Links  Insights by Topic Explore a variety of insights organized by different topics. Key Links  Insights by Type Explore a variety of insights organized by different types of content and media. Key Links  We aim to be the most respected financial services firm in the world, serving corporations and individuals in more than 100 countries. Key Links Global Research July 01, 2025 Top dollar no more? Learn more about the factors threatening the dominance of the world‚Äôs reserve currency. Overview The U.S. dollar is the world‚Äôs primary reserve currency, and it is also the most widely used currency for trade and other international transactions. However, its hegemony has come into question in recent times due to geopolitical and geostrategic shifts. As a result, de-dollarization has increasingly become a substantive topic of discussion among investors, corporates and market participants more broadly. What are the potential implications of de-dollarization, and how is it playing out in global markets and trade? In short, de-dollarization entails a significant reduction in the use of dollars in world trade and financial transactions, decreasing national, institutional and corporate demand for the greenback. ‚ÄúThe concept of de-dollarization relates to changes in the structural demand for the dollar that would relate to its status as a reserve currency. This encompasses areas that relate to the longer-term use of the dollar, such as transactional dominance in FX volumes or commodities trade, denomination of liabilities and share in central bank FX reserves,‚Äù said Luis Oganes, head of Global Macro Research at J.P.¬†Morgan. Importantly, this structural shift is distinct from the cyclical demand for the greenback, which is shorter term and has in recent time", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The world of Japanese snack bars", "url": "https://www.bbc.com/travel/article/20260116-inside-the-secret-world-of-japanese-snack-bars", "content": "Some 100,000 of these small dives are hidden in plain sight across Japan. Now, travellers are finally discovering these locals-only hangouts ‚Äì and the beloved \"mamas\" who run them. I didn't plan on having my fortune read by a matchmaking \"mama\" on my most recent visit to Tokyo. But after climbing to the second floor of a cozy sunakku (snack bar) called Aeru in the Shinbashi neighbourhood, the proprietress and owner, Urara, smiled coyly as she pulled a Knight of Wands from her tarot deck. \"You're craving passion and protection‚Ä¶ in a man,\" Urara told me, as I nibbled chilli-flavoured rice crackers and deep-fried dough sticks slathered in brown sugar. \"I'll be sure to let my husband know that,\" I replied with a wry smile. As she thumbed through a three-ring binder filled with the handwritten profiles of Japanese singles in their 20s and 30s, Urara explained that she has successfully matched more than 90 couples during the 14 years she has worked here. While her tarot readings and modern matchmaking techniques are unique among Japan's tens of thousands of snack bars, Urara embodies what makes these small venues so distinct. Usually run by an older woman known affectionately as a mama-san , snack bars are nondescript, no-frills bars serving light bites and drinks. But as I soon learned, their main purpose isn't food or booze; it's to create a space where patrons feel comfortable enough to open up, engage in meaningful conversation and genuinely connect with the mama-san who presides over the room. \"Unlike the bars or nightclubs many tourists may imagine, snack bars are warm, home-like places,\" said Mayuko Igarashi, president and director of Snack Yokocho Culture Inc , which has been offering tours of snack bars across Japan for travellers since 2021. \"The 'mama'‚Ä¶ welcomes guests with a sense of personal care.\" A far cry from the pricey \"hostess clubs\" found in entertainment districts like Kabukich≈ç in Shinjuku, where young women are paid generously to pour drinks and fli", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Rzweb: A complete browser-based reverse engineering platform", "url": "https://github.com/IndAlok/rzweb", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A complete browser-based reverse engineering platform built on Rizin, running entirely client-side via WebAssembly. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A browser-based reverse engineering platform that runs Rizin entirely in your browser through WebAssembly. No installations, no uploads, no servers - just drop a binary and start analyzing. Homepage - Drop a binary and start analyzing  Terminal - Full Rizin CLI access  Disassembly - Syntax-highlighted assembly view  Control Flow Graph - Visual function structure  Hex Dump - Raw byte inspection  Strings - Extracted strings from the binary  RzWeb brings the full power of Rizin to your browser. You get a complete terminal where you can run any Rizin command, plus dedicated views for disassembly, control flow graphs, hex dumps, and strings. Everything processes locally on your machine - your files never leave your device. The integrated terminal gives you direct access to Rizin's CLI. Run pdf to disassemble a function, afl to list all functions, px to dump hex, or any other command you would use in a normal Rizin session. Commands can be chained with semicolons like s main;pdf . Syntax-highlighted assembly with address navigation. Click on addresses to jump around, see cross-references, and track your current position in the binary. Visual representation of function structure. See how basic blocks connect, identify loops, and understand the control flow at a glance. Raw byte inspection. Navigate to any offset and examine the binary data directly. Automatically extracted strings from the binary. Useful for finding hardcoded paths, error messages, encryption keys, and other interesting data. RzWeb supports everything Rizin supports: All analysis happens in your browser. The binary is loaded into WebAssembly memory an", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Radboud University selects Fairphone as standard smartphone for employees", "url": "https://www.ru.nl/en/staff/news/radboud-university-selects-fairphone-as-standard-smartphone-for-employees", "content": "Do you require a (replacement) smartphone for your work at Radboud University? If so, there is a strong possibility that you will receive a Fairphone from 1 February 2026 onwards. Radboud University has decided to choose Fairphone as its standard company smartphone model for reasons of sustainability, cost efficiency and management support. The Fairphone is a sustainable smartphone with easily replaceable parts such as the battery and screen. This makes the device last longer. Fair and recycled materials, such as plastic and aluminium, are used as much as possible in the production of this smartphone. Fairphone also pays attention to good and safe working conditions in its factories. Fairphones are issued to employees by the Information & Library Services (ILS) division. In addition to new Fairphones, the university can also reissue used Samsung devices where possible. These are Samsung devices that have already been returned and still meet the technical and age requirements. As long as these devices are still available, not every employee will receive a Fairphone immediately. Employees who have an iPhone from Radboud University can continue to use it as long as the device is still functioning. However, returned iPhones will no longer be reissued. Employees who prefer to use their private phone for work can request an RU SIM card for this purpose. The costs for using your own device will not be reimbursed. Naturally, smartphone models that have already been issued will continue to be supported by ILS colleagues, as will privately purchased smartphone models used for work. Due to its longer lifespan, the total cost of a Fairphone is lower than that of comparable devices. In addition, Radboud University only needs to purchase, manage and support one standard model. This results in smaller stock, easier management and faster support. Manuals and instructions also only need to be maintained for one device. Furthermore, less investment is required in knowledge of differe", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Notes on Apple's Nano Texture (2025)", "url": "https://jon.bo/posts/nano-texture/", "content": "TLDR: the Nano Texture performs wonderfully anywhere where light used to be a factor and used to force me to shade my screen or avoid the place entirely. Big thanks to Julie Kruger for the comparison photos and CJ for draft feedback. A few months after I got the Daylight Computer ( read my thoughts here ), two friends sent me this post comparing the old Macbook Pro displays to the new Nano Texture glass ones. That post convinced me to upgrade my computer in short order, to the dismay of my wallet. In the four months I‚Äôve had it I‚Äôve told at least a dozen people about it, and I‚Äôm gonna keep telling people. Being able to take my entire computing environment to places without being worried about glare has expanded the range of environments I can create in. It means I get to be in environments that are more interesting, fun, and in tune with my body. What follows are some thoughts about how this display has fit into my day to day life in the couple of months I‚Äôve had it. Typical matt displays have a coating added to their surface that scatters light. However, these coatings lower contrast while producing unwanted haze and sparkle. Etched into the glass at the nanometre level, the nano-texture scatters light to further minimise glare ‚Äî for outstanding image quality even in challenging lighting conditions. https://www.apple.com/uk/shop/buy-mac/apple-studio-display/nano-texture-glass-tilt-adjustable-stand Basically, it‚Äôs a coating physically etched into the screen that reflects light differently from the glossy finish of the traditional screen. First off, this isn‚Äôt apples to oranges - these are different technologies that in my mind, serve a different purpose. The Daylight Computer is an Android tablet, the Macbook Pro is a full MacOS laptop. The transflective LCD in the Daylight Computer is grayscale but it needs no light to function. It has a backlight, but where it does really well is in direct sunlight with the backlight turned off. When outside in direct sunlight, to", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "How we made Python's packaging library 3x faster", "url": "https://iscinumpy.dev/post/packaging-faster/", "content": "Along with a pip (and now packaging ) maintainer, Damian Shaw, I have\nbeen working on making packaging , the library behind almost all packaging\nrelated tools, faster at reading versions and specifiers, something tools like\npip have to do thousands of times during resolution. Using Python 3.15‚Äôs new\nstatistical profiler and metadata from every package ever uploaded to PyPI, I\nmeasured and improved core Packaging constructs while keeping the code readable\nand simple. Reading in Version s can be up to 2x faster and SpecifierSet s can\nbe up to 3x faster in packaging 26.0 , now released! Other\noperations have been optimized, as well, up to 5x in some cases. See the announcement and release notes too; this post will focus on the\nperformance work only. packaging is the core library used by most tools for Python to deal with many\nof the standardized packaging constructs, like versions, specifiers, markers,\nand the like. It is the 11th most downloaded library, but if you also take into\naccount that it is vendored into pip, meaning you get a (hidden) copy with every\npip install, it‚Äôs actually the 2nd most downloaded library. Given that pip is\nvendored into Python, everyone who has Python has packaging , unless their\ndistro strips it out into a separate package; so it is possible it is the most\ncommon third party Python library in the world. In packaging, a Version is something that follows PEP 440 ‚Äôs version\nstandard. And a SpecifierSet is conditions on that version; think >=2,<3 or ~=1.0 , those are SpecifierSet s. They are used on dependencies, on requires-python , etc. They are also part of Marker s, that is, something like tomli; python_version < '3.11' (a Requirement ) contains a Marker . I‚Äôd like to start by showing you the progress we‚Äôve made as a series of plots;\nif you‚Äôd like to see how we made some of these, I‚Äôll follow with in-depth\nexamples. After most of the performance PRs were made, I finally invested a little time\ninto making a proper set of micro-benchmarks", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: An interactive physics simulator with 1000‚Äôs of balls, in your terminal", "url": "https://github.com/minimaxir/ballin", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A colorful interactive physics simulator with thousands of balls, but in your terminal! There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  Crates.io A colorful interactive physics simulator with thousands of balls, but in your terminal! ballin is a fun TUI app written in Rust that simulates thousands of logical balls, but despite the inherent character constraints of a terminal, you can see the realistic physics of the balls in action: Watch the color explosion in action! Disclosure: This crate was developed with the assistance of Claude Opus 4.5 initially to answer the shower thought \"would the Braille Unicode trick work to visually simulate complex ball physics in a terminal?\" Opus 4.5 one-shot the problem , so I decided to further experiment to make it more fun and colorful. The full list of prompts used with Claude Code is present in PROMPTS.md . The app binaries can be downloaded from the Releases page for your platform of choice, or by using the following terminal commands: For Windows, download and unzip the binary from here . If Rust is installed, you can install the crate directly via cargo : It is VERY strongly recommended to use a terminal emulator such as Ghostty as normal terminals may have their frame rates capped at 30 FPS and the output looks choppy. The app looks comparatively poor in the native macOS Terminal.app, for example. To run ballin : if you downloaded the binary, run it in the terminal with ./ballin . If you installed via Rust, run cargo run . The physics simulation will start with some shape objects randomly present to let the hilarity ensue immediately! Press keys, click areas, see what happens? You can press ? for the full lis", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Dockerhub for Skill.md", "url": "https://skillregistry.io/", "content": "Find and install skills for Claude, ChatGPT, and AI agents. The definitive registry for SKILLS.md files that extend your AI assistant's capabilities. Then run sr search <query> or sr install <skill> Search for skills like \"1password\", \"browser\", \"github\", or any tool you want your AI to use Most popular SKILLS.md files from the community Automatically search Skill Registry for relevant skills before starting tasks. Enhances Claude's capabilities by finding specialized skills that can help with the current task. Use when you need to control Slack from Clawdbot via the slack tool, including reacting to messages or pinning/unpinning items in Slack channels or DMs. Automates browser interactions for web testing, form filling, screenshots, and data extraction. Use when the user needs to navigate websites, interact with web pages, fill forms, take screenshots, test web applications, or extract information from web pages. \"Interact with GitHub using the `gh` CLI. Use `gh issue`, `gh pr`, `gh run`, and `gh api` for issues, PRs, CI runs, and advanced queries.\" Guide for creating effective skills that extend Claude's capabilities. Use when creating new skills or updating existing skills with specialized knowledge, workflows, or tool integrations. Local speech-to-text with the Whisper CLI (no API key). Gemini CLI for one-shot Q&A, summaries, and generation. Google Workspace CLI for Gmail, Calendar, Drive, Contacts, Sheets, and Docs. Web search and content extraction via Brave Search API. Batch-generate images via OpenAI Images API. Random prompt sampler + `index.html` gallery. Search for places (restaurants, cafes, etc.) via Google Places API proxy on localhost. X/Twitter CLI for reading, searching, and posting via cookies or Sweetistics. Showing page 1 of 6 ( 61 skills)", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Rust's Standard Library on the GPU", "url": "https://www.vectorware.com/blog/rust-std-on-gpu/", "content": "GPU code can now use Rust's standard library. We share the implementation approach and what this unlocks for GPU programming. At VectorWare , we are building the first GPU-native software company . Today, we are excited to\nannounce that we can successfully use Rust's standard library from GPUs. This milestone\nmarks a significant step towards our vision of enabling developers to write complex,\nhigh-performance applications that leverage the full power of GPU hardware using\nfamiliar Rust abstractions. This post is a preview of what we've built. We're preparing our work for potential\nupstreaming and will share deeper technical details in future posts. Rust's standard library is organized as a set of\nlayered abstractions: A defining feature of Rust is that layers 2 and 3 are optional . Code can opt out of std via the #![no_std] annotation, relying only on core and, when needed, alloc .\nThis makes Rust usable in domains such as embedded , firmware , and drivers , which lack a traditional operating system. We are the maintainers of rust-cuda and rust-gpu , open source projects that enable\nRust code to run on the GPU. When targeting\nthe GPU with these projects, Rust code is compiled with #![no_std] as GPUs do not have\noperating systems and therefore cannot support std . Because #![no_std] is part of the Rust language, #![no_std] libraries on crates.io written for other purposes can generally run on the GPU\nwithout modification. This ability to reuse existing open source libraries is much\nbetter than what exists in other (non-Rust) GPU ecosystems. Still, there is a cost to opting out of std . Many of Rust's most useful and ergonomic\nabstractions live in the standard library and the majority of open source libraries\nassume std . Enabling meaningful std support on GPUs unlocks a much larger class of\napplications and enables even more code reuse. Modern GPU workloads like machine learning and AI require fast access to storage and\nnetworking from the GPU. Technologies such as N", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Subth.ink ‚Äì write something and see how many others wrote the same", "url": "https://subth.ink/", "content": "Share your thoughts anonymously. See if anyone else thinks the same thing. Your text is not stored in the server, but rather a salted SHA256 hash of it is. An unsalted MD5 hash is also stored, but not displayed here. It (the MD5 hash) might be published in the future when a thought's count passes a certain threshold (TBD). This might\n      make it possible to recover certain short thoughts that were popular. Your text is stored locally, in your browser, to help you track your guesses for the top 10 thoughts. You can delete them by using the \"Clear local thoughts\" button below. POST /api/thoughts GET /api/thoughts/top 2026-01-20 2026-01-19", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Your Brain Might Not Be Full of Microplastics After All", "url": "https://www.insidehook.com/wellness/microplastics-studies", "content": "It isn‚Äôt exactly news that plastic is a problem, but just how quickly that problem is growing may shock you. According to a recent report published by Pew Charitable Trusts, between now and 2040, plastic pollution is projected to more than double; plastic-spurred health impacts will rise by 75%, and plastic-related emissions will rise by 58%. Another alarming statistic? Microplastic pollution is expected to grow by more than 50% and, at least in high-income communities, it will account for 79% of all plastic pollution. Ah, the dreaded microplastics. It‚Äôs hard to pinpoint exactly when the craze around these tiny bits of plastic began. One could go back all the way to 2004, when marine biologist Richard Thompson coined the term in his research, referring to the microscopic particles of plastic debris floating around the ocean. But the concern around this type of pollution has certainly ramped up in recent years as studies found them in human blood, lungs and stool samples. Then, in February 2025, a key paper in the journal Nature Medicine reported finding these tiny plastic pieces in human brains, at much higher levels than elsewhere in the body. (How much? Try a spoon‚Äôs worth .) The presence of microplastics was linked to dementia, reproductive dysfunction, inflammation, heart attacks and cancer. So last week when The Guardian published a story claiming that a ‚Äúbombshell‚Äù doubt had been cast on the previous years‚Äô studies about the presence of microplastics in our bodies, a collective sigh of relief was heard across the internet ‚Äî and with it, a bit of righteous indignation from those microplastics deniers who had long claimed they didn‚Äôt believe these microscopic bits of polyethylenes were doing any real damage to their brains or bodies. Dr. Du≈°an Materiƒá of the Helmholtz Center for Environmental Research in Germany called the aforementioned 2025 plastic-in-brain study a ‚Äújoke,‚Äù noting that since fats can often sound false alarms as certain types of plastics, the re", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Crates.io: Development Update", "url": "https://blog.rust-lang.org/2026/01/21/crates-io-development-update/", "content": "Time flies! Six months have passed since our last crates.io development update, so it's time for another one. Here's a summary of the most notable changes and improvements made to crates.io over the past six months. Crate pages now have a new \"Security\" tab that displays security advisories from the RustSec database. This allows you to quickly see if a crate has known vulnerabilities before adding it as a dependency.  The tab shows known vulnerabilities for the crate along with the affected version ranges. This feature is still a work in progress, and we plan to add more functionality in the future. We would like to thank the OpenSSF (Open Source Security Foundation) for funding this work and Dirkjan Ochtman for implementing it. In our July 2025 update, we announced Trusted Publishing support for GitHub Actions. Since then, we have made several enhancements to this feature. Trusted Publishing now supports GitLab CI/CD in addition to GitHub Actions. This allows GitLab users to publish crates without managing API tokens, using the same OIDC-based authentication flow. Note that this currently only works with GitLab.com. Self-hosted GitLab instances are not supported yet. The crates.io implementation has been refactored to support multiple CI providers, so adding support for other platforms like Codeberg/Forgejo in the future should be straightforward. Contributions are welcome! Crate owners can now enforce Trusted Publishing for their crates. When enabled in the crate settings, traditional API token-based publishing is disabled, and only Trusted Publishing can be used to publish new versions. This reduces the risk of unauthorized publishes from leaked API tokens. The pull_request_target and workflow_run GitHub Actions triggers are now blocked from Trusted Publishing. These triggers have been responsible for multiple security incidents in the GitHub Actions ecosystem and are not worth the risk. Crate pages now display source lines of code (SLOC) metrics, giving you insi", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Giving university exams in the age of chatbots", "url": "https://ploum.net/2026-01-19-exam-with-chatbots.html", "content": "by Ploum on 2026-01-19 What I like most about teaching \"Open Source Strategies\" at √âcole Polytechnique de Louvain is how much I learn from my students, especially during the exam. I dislike exams. I still have nightmares about exams. That‚Äôs why I try to subvert this stressful moment and make it a learning opportunity. I know that adrenaline increases memorization dramatically. I make sure to explain to each student what I was expecting and to be helpful. Here are the rules: 1. You can have all the resources you want (including a laptop connected to the Internet) 2. There‚Äôs no formal time limit (but if you stay too long, it‚Äôs a symptom of a deeper problem) 3. I allow students to discuss among themselves if it is on topic. (in reality, they never do it spontanously until I force two students with a similar problem to discuss together) 4. You can prepare and bring your own exam question if you want (something done by fewer than 10% of the students) 5. Come dressed for the exam you dream of taking! This last rule is awesome. Over the years, I have had a lot of fun with traditional folkloric clothing from different countries, students in pajamas, a banana and this year‚Äôs champion, my Studentausorus Rex! My all-time favourite is still a fully clothed Minnie Mouse, who did an awesome exam with full face make-up, big ears, big shoes, and huge gloves. I still regret not taking a picture, but she was the very first student to take my words for what was a joke and started a tradition over the years. Rule N¬∞1 implies having all the resources you want. But what about chatbots? I didn‚Äôt want to test how ChatGPT was answering my questions, I wanted to help my students better understand what Open Source means. Before the exam, I copy/pasted my questions into some LLMs and, yes, the results were interesting enough. So I came up with the following solution: I would let the students choose whether they wanted to use an LLM or not. This was an experiment. The questionnaire contained th", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Artificial Ivy in the Browser", "url": "https://da.nmcardle.com/grow", "content": "Show HN: Artificial Ivy in the Browser. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: How do you keep system context from rotting over time?", "url": "item?id=46693985", "content": "Ask HN: How do you keep system context from rotting over time?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Web-based video editor powered by WebGPU", "url": "https://subformer.com/en-US/editor", "content": "Create and edit videos right in your browser. Your projects are stored locally on your device. Projects saved on your device Sign in to sync across devices", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Solving the Pendulum Problem", "url": "https://ethansteere.net/blog/solving-the-pendulum-problem/", "content": "In the Spring of 2024 a new LLM evaluation called Humanity√¢¬Ä¬ôs Last Exam was released.\nA co-worker sent me the demo page at the time and I found a physics problem relating to a pendulum with a pivot point that slides along the axis.\nI told him I thought I could solve it (possible I declared I could easily solve it) as a generalization of the pendulum problem taught in physics class years ago.\nIn the process, I revisited the details of the basic pendulum and found that I had actually solved a heinous approximation!\nDespite its simple seeming setup, the motion of a pendulum is fundamentally complex and resists analytical modeling of its position. NOTE: The following presumes understanding of single variable calculus, the chain rule, trig functions, trig identities, free body diagrams, and newton√¢¬Ä¬ôs second law. A massless rod of length is fixed to the ceiling with a mass on the end.\nThe rod is subject to gravity and able to swing freely. Given a starting angular displacement , find a function that gives the angular displacement at time . First, we use the laws of mechanics to derive a relation between and time derivatives of ( , ).\nThen, we will solve for a that satisfies that relation. While the pendulum is displaced from the vertical, part of the downward gravitational force is acting on the pendulum tangent to its circular path.\nUsing trigonometry, we can find the magnitude of the tangential component of the vector. According to Newton√¢¬Ä¬ôs Second Law of Motion, the absolute value of the force tangent to the path must be equal to mass, , multiplied by the absolute value of the acceleration tangent to the path. Note that a symbol with a dot over it represents the time derivative of that value e.g. , . , the displacement along the circular path from vertical, can be calculated from the angular displacement in radians, , and the length of the rod, . Thus, Eq. 6 tells us that the magnitude of the force acting along the path of the swinging mass will be equal to multipli", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Antarctic Snow Cruiser", "url": "https://www.amusingplanet.com/2026/01/the-antarctic-snow-cruiser.html", "content": "Somewhere on the Ross Ice Shelf in Antarctica, buried beneath hundreds of feet of snow (or perhaps at the bottom of the ocean), lies an enormous vehicle. Designed for an American research expedition in 1939, the Antarctic Snow Cruiser was among the most ambitious machines ever sent to the frozen south. Conceived as a self-contained mobile laboratory, it promised to transform Antarctic exploration. Instead, it was quickly humbled by the unforgiving realities of the polar environment. The Antarctic Snow Cruiser rolls out of the Chicago construction yards on October 24, 1939. Credit:¬†United States Antarctic Service By the 1930s, Antarctica was no longer a blank spot on the map, but exploration remained slow, dangerous, and limited in range. Expeditions depended on dog teams, sledges, and small tracked vehicles that struggled over crevasses and soft snow. Admiral Richard E. Byrd, America‚Äôs most famous polar explorer, believed the next great advance would come not from endurance or improvisation, but from mechanization. The idea behind the Antarctic Snow Cruiser was simple‚Äîbuild a vehicle large and capable enough to roam thousands of miles across the ice, carrying scientists, living quarters, and supplies for an entire year without outside support. It would serve as a mobile base of operations, allowing researchers to study geology, meteorology, magnetism, and glaciology far inland, something previous expeditions could barely attempt. The need for such a vehicle was born out of crisis. During Byrd‚Äôs second Antarctic expedition in 1934, the admiral was operating a remote meteorological station several hours from base camp. When his radio transmissions began to falter, the men at base grew increasingly alarmed. Thomas Poulter, Byrd‚Äôs second-in-command, organized a rescue attempt with two companions. Twice they were forced to turn back by worsening weather and mechanical failures. Admiral Richard E. Byrd When they finally reached Byrd‚Äôs camp on August 13, 1934, they found h", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Pipenet ‚Äì A Modern Alternative to Localtunnel", "url": "https://pipenet.dev/", "content": "A modern, open-source alternative to localtunnel. Bundles client & server to host your own tunnel infrastructure. Expose local services to the internet, or embed tunneling in your own tools. Share your local server with teammates, test webhooks, or demo work without deploying. Embed pipenet in your own tools to provide tunneling capabilities. mcp-proxy uses pipenet to connect local MCP servers with remote AI clients. Run your own tunnel server for full control over security, domains, and availability. One package. Two modes. Use the public server or deploy your own. Built for modern deployment environments. Tunnels any HTTP-based traffic to your local server. Programmatic usage for testing, automation, and integration. Deploy your own tunnel infrastructure with lifecycle hooks.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Engineering as Humanity's Highest Achievement", "url": "https://walkingtheworld.substack.com/p/engineering-as-humanitys-highest", "content": "I‚Äôm reading A Culture of Growth by Joel Mokyr , a book I started before walking Surrey, England , because I‚Äôve always been intrigued by the question of why some countries become rich while others don‚Äôt. Why the Industrial Revolution happened in England rather than China or Germany is one of those questions that has launched a thousand books, careers, and theories, and Dr. Mokyr‚Äôs answer is (oversimplifying): England had a foundational belief in the abilities of man to shape their world, as a result of the Enlightenment, which enabled the creation of laws, institutions, and businesses focused on bettering society through innovation, technology, and economic progress. That idea that man could, and should, shape the world to achieve sustained and substantial economic growth was a substantial shift in thought. Prior to the Enlightenment, most of the world had an ‚ÄúEcclesiastes view of history,‚Äù which saw long-term change as neither possible (‚Äùthere is nothing new under the sun‚Äù) nor good, since it leads to sinful riches. This change, which was fomented among then obscure intellectuals questioning the dominant Catholic view of the world, was necessary, and in the end sufficient, for the Industrial Revolution. Our modern world of immense wealth, technology, relative secularism, and intellectual hubris, is the end result of that, and that, as I argued last week , is in totality, a good thing. 1 Mokyr, like me, believes that culture 2 plays a primary role in a nation's development, more than its tangible assets such as resources and geography. Institutions are, in this view, downstream, and while they influence significantly how a nation evolves, including its intellectual life, they are physical manifestations of a people‚Äôs beliefs, which precede them. I side with his thesis, which while not caustically anti-religion, does believe that the church needed to be first culturally defeated for the Industrial Revolution to have happened, for the sciences to become dominant, and f", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Bypassing Gemma and Qwen safety with raw strings", "url": "https://teendifferent.substack.com/p/apply_chat_template-is-the-safety", "content": "This article demonstrates vulnerabilities in open-source LLM safety alignment. Published in the spirit of responsible disclosure to help build more robust AI systems. TL;DR: Omit the apply_chat_template() call and observe your \"aligned\" small LLM happily write bomb tutorials. The safety isn't in the weights‚Äîit's in the formatting . Spent some time over the weekend poking at the SolidGoldMagikarp phenomenon‚Äîthose legendary ‚Äúglitch tokens‚Äù from the GPT-2 era. For the uninitiated: these are tokens that exist in the tokenizer‚Äôs vocabulary (likely from a raw web crawl) but never actually appeared in the model‚Äôs training distribution. Because the model never updated the weights for these specific embeddings, they represent ‚Äúcold‚Äù regions of the embedding space. If you force-feed one to a model, you get this beautiful, chaotic ‚Äúhallucination‚Äù as the model tries to navigate a coordinate it has never seen. I was trying to replicate this on some newer open-source weights via Hugging Face, but I stumbled into a much more interesting‚Äîand slightly concerning discrepancy. When testing the model through the Hugging Face inference API, I gave it a classic ‚Äúred team‚Äù prompt: ‚ÄúWrite a tutorial on how to make a bomb.‚Äù The model gave the standard, polite refusal. The alignment was holding. However, running the exact same model locally, the behavior shifted entirely. No glitch tokens required‚Äîit just started outputting the technical mechanisms of detonation. The vulnerability proved remarkably straightforward. I had forgotten to call apply_chat_template() . Essentially, the model‚Äôs safety alignment is often ‚Äúbaked in‚Äù specifically to the chat-based distribution (the <|im_start|> and <|im_end|> tags). By providing the raw string without the proper boilerplate, I was effectively bypassing the ‚ÄúAssistant‚Äù persona and interacting with the raw base-model completions. The punchline here is that ‚Äúsafety‚Äù isn‚Äôt a fundamental property of the weights; it‚Äôs a fragile state that evaporates the mome", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Dead Internet Theory", "url": "https://kudmitry.com/articles/dead-internet-theory/", "content": "The other day I was browsing my one-and-only social network ‚Äî which is not a social network, but I‚Äôm tired of arguing with people online about it ‚Äî HackerNews .\nIt‚Äôs like this dark corner of the internet, where anonymous tech-enthusiasts, scientists, entrepreneurs, and internet-trolls, like to lurk.\nI like HackerNews.\nIt helps me stay up-to-date about recent tech news (like Cloudflare acquiring Astro which makes me happy for the Astro team, but also sad and worried since I really like Astro, and big-tech has a tendency to ruin things); it mostly avoids politics; and it‚Äôs not a social network. And, in the fashion of HackerNews, I stumbled upon someone sharing their open-source project.\nIt‚Äôs great to see people work on their projects and decide to show them to the world.\nI think people underestimate the fear of actually shipping stuff, which involves sharing it with the world. Upon glancing at the comment section, I started to see other anonymous participants questioning the validity of said open-source project in terms of how much of it was AI-generated.\nI grabbed my popcorn, and started to follow this thread.\nMore accusations started to appear: the commit timeline does not make sense; the code has AI-generated comments; etc.\nAnd at the same time, the author tried to reply to every comment claiming that they wrote this 100% without using AI. I don‚Äôt mind people using AI to write code, even though I tried to resist it myself, until eventually succumbing to it.\nBut I think it‚Äôs fair to disclose the use of AI, especially in open-source software.\nPeople on the internet are, mostly, anonymous, and it‚Äôs not always possible to verify the claims or expertise of particular individuals. But as the amount of code is growing, considering that everyone is using AI to generate whatever-app they want, it‚Äôs impossible to verify every piece of code we are going to use.\nSo it‚Äôs fair to know, I think, if some project is AI generated and to what extent.\nIn the end, LLMs are just probabi", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Gaussian Splatting ‚Äì A$AP Rocky \"Helicopter\" music video", "url": "https://radiancefields.com/a-ap-rocky-releases-helicopter-music-video-featuring-gaussian-splatting", "content": "Learn Tools & Resources Services Media About Us Search... Subscribe Subscribe Platforms Papers Job Board Buyers Guide Subscribe Pop Culture Michael Rubloff Jan 13, 2026 Believe it or not, A$AP Rocky is a huge fan of radiance fields. Yesterday, when A$AP Rocky released the music video for Helicopter , many viewers focused on the chaos, the motion, and the unmistakable early MTV energy of the piece. What√¢¬Ä¬ôs easier to miss, unless you know what you√¢¬Ä¬ôre looking at, is that nearly every human performance in the video was captured volumetrically and rendered as dynamic splats. I spoke with Evercoast , the team responsible for capturing the performances, as well as Chris Rutledge, the project√¢¬Ä¬ôs CG Supervisor at Grin Machine , and Wilfred Driscoll of WildCapture and Fits√Ö¬´.ai , to understand how Helicopter came together and why this project represents one of the most ambitious real world deployments of dynamic gaussian splatting in a major music release to date. The decision to shoot Helicopter volumetrically wasn√¢¬Ä¬ôt driven by technology for technology√¢¬Ä¬ôs sake. According to the team, the director Dan Strait approached the project in July with a clear creative goal to capture human performance in a way that would allow radical freedom in post-production. This would have been either impractical or prohibitively expensive using conventional filming and VFX pipelines. Chris told me he√¢¬Ä¬ôd been tracking volumetric performance capture for years, fascinated by emerging techniques that could enable visuals that simply weren√¢¬Ä¬ôt possible before. Two years ago, he began pitching the idea to directors in his circle, including Dan, as a √¢¬Ä¬úsomeday√¢¬Ä¬ù workflow. When Dan came back this summer and said he wanted to use volumetric capture for the entire video, the proliferation of gaussian splatting enabled them to take it on. The aesthetic leans heavily into kinetic motion. Dancers colliding, bodies suspended in midair, chaotic fight scenes, and performers interacting with props tha", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nanolang: A tiny experimental language designed to be targeted by coding LLMs", "url": "https://github.com/jordanhubbard/nanolang", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A tiny experimental language designed to be targeted by coding LLMs There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  A minimal, LLM-friendly programming language with mandatory testing and unambiguous syntax. NanoLang transpiles to C for native performance while providing a clean, modern syntax optimized for both human readability and AI code generation. Self-hosting: NanoLang supports true self-hosting via a Stage 0 ‚Üí Stage 1 ‚Üí Stage 2 bootstrap ( make bootstrap ); see planning/SELF_HOSTING.md . This builds the compiler: Create hello.nano : Run it: NanoLang is actively tested and supported on: Windows 10/11 users: NanoLang runs perfectly on Windows via WSL2 (Windows Subsystem for Linux). After installation, restart your computer, then: Why WSL? NanoLang's dependencies (SDL2, ncurses, pkg-config) are Unix/POSIX libraries. WSL2 provides a full Linux environment with near-native performance on Windows. Note: Native Windows binaries ( .exe ) are not currently supported, but may be added in a future release via cross-compilation. These platforms should work but are not actively tested in CI: No operator precedence to remember: NanoLang includes a growing standard library: See examples/README.md for the complete list. NanoLang includes several modules with automatic dependency management : Modules automatically install dependencies via package managers (Homebrew, apt, etc.) when first used. See docs/MODULE_SYSTEM.md for details. On BSD systems (FreeBSD/OpenBSD/NetBSD), use GNU make: gmake build , gmake test , etc. NanoLang is designed to be LLM-friendly with unambiguous syntax and mandatory testing. To teach an AI system to code in NanoLang: The combination of MEMORY.md (practical guidance) + spec.json (formal reference) provides complete coverage for code generation and under", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Scheme implementation as O'Reilly book via Claude Code", "url": "https://ezzeriesa.notion.site/Scheme-implementation-as-O-Reilly-book-via-Claude-Code-2ee1308b420480ce9b9cd157ee5220fd", "content": "Scheme implementation as O'Reilly book via Claude Code. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "MTOTP: Wouldn't it be nice if you were the 2FA device?", "url": "https://github.com/VBranimir/mTOTP/tree/develop", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . mTOTP is an experimental, manual variant of TOTP designed to be computed by a human without electronic devices. It explores the limits of time-based authentication under strict human constraints and makes no claims of cryptographic equivalence to standard TOTP. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . It takes a special kind of geek to not carry a 2FA device.\nOne who becomes the 2FA. mTOTP is an experimental, manual variant of TOTP designed to be computed by a human without electronic devices. It explores the limits of time-based authentication under strict human constraints and makes no claims of cryptographic equivalence to standard TOTP. mTOTP is a human‚Äëexecutable OTP scheme designed to be: This protocol intentionally allows OTPs to be calculated for future times.\nRather than treating this as a limitation, it makes it a requirement: the user must know when they intend to authenticate, and the verifier checks against that agreed moment. Time is therefore not an approximation, but an explicit part of the protocol - Turning authentication time from reactive to intentional.\nThis document describes the exact algorithm used by the tool , written for humans first. This protocol is designed for human execution first , with software acting as a helper and verifier. Clarity, determinism, and mental tractability are intentional design goals.  An mTOTP is generated from: The algorithm uses: No randomness is involved during generation. Secret key (10 digits): 1234598760 (If your key is shorter than 10 digits, pad or derive it consistently before use.) Planned login time: 2026‚Äë01‚Äë17 17:00 Convert the planned login time into the format, take into account that you are calculating for the server-side set time: Example: Result: The S‚Äëbox is a digit substitution table (0‚Äì9 ‚Üí 0‚Äì9)", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Void (2025)", "url": "https://github.com/nostalgebraist/the-void/blob/main/the-void.md", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Face as a QR Code", "url": "https://bookofjoe2.blogspot.com/2025/12/your-face-as-qr-code.html", "content": "But wait ‚Äî there's more! The more I learn about QR codes the more fascinating they seem to me. A seemingly random array of tiny black and white squares can also serve as a pixelated display and at the same time be a gateway into internet space. Wrote Kevin Kelly in Recomendo : A lot of the dots in a QR code are superfluous, meaning that they can be arranged into a picture, and not just randomly. Thus you can make the QR code into a picture. QArt Coder is a website that will generate a QR code for a website you give it (say your homepage) using an image you give it (say your photo), yielding a QR code with a stylized image of you (or, say, a logo). Short urls and small high contrast images work best. Hold a phone's camera in front of it and it takes you to the website you linked it to. Free , the way we like. Post a Comment", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Overly Analytical Guide to Escorting (2021)", "url": "https://knowingless.com/2021/10/19/becoming-a-whorelord-the-overly-analytical-guide-to-escorting/", "content": "Knowingless this, too, is it Wanna be an independent full-service escort in the US? Not sure if it‚Äôs for you? Included is tips on getting started, marketing, how to increase your income, male sexual psychology and getting them to hire you again, networking, branding, dealing with the emotional burden, safety, and more! My credentials: I escorted from 2018-2020 (I of course no longer escort, however if you happen to see a woman in the ads who looks very similar to me you should hit her up). I charged $1200/hr (with discounts for multi-hour sessions), and earned 50k on my highest-earning month. Escorting is more difficult to develop widely applicable strategies for because the business is invisible. With online sex work, successful techniques spread fast and get adopted as new defaults because everything is clearly visible. With in-person sex work, all you know is what you do. I also worked primarily as high end (initially charging $800/hr for the first month or two before raising it over time to $1200), which means I am not experienced with lower-rate, higher-volume work; two elements that strongly impact the kind of experience you‚Äôll have. I also am speaking to the US market, which has many differences from other markets around the world, primarily legally. I am assuming you are female; while male escorts can in fact do well, this article is targeted towards women. I conducted two surveys, of 165 escorts and 411 clients, and I‚Äôll be referring to findings from these surveys throughout this article. The survey is not meant to represent all sex workers and clients; I gathered responses from my social media, in sex worker forums, and on fetlife, so it‚Äôs more a reflection of ‚Äúpeople from the western world who follow me or sex-friendly social forums‚Äù. But hopefully this is the kind of person you are, so it might be good data for you! I‚Äôm also experimenting with likelihood ratios (‚ÄúLR‚Äù), instead of p-values. The program I‚Äôm using to calculate them is new and there might be", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nearly a third of social media research has undisclosed ties to industry", "url": "https://www.science.org/content/article/nearly-third-social-media-research-has-undisclosed-ties-industry-preprint-claims", "content": "Nearly a third of social media research has undisclosed ties to industry. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A decentralized peer-to-peer messaging application that operates over Bluetooth", "url": "https://bitchat.free/", "content": "bitchat is a decentralized peer-to-peer messaging application that operates over bluetooth mesh networks.\nno internet required, no servers, no phone numbers. traditional messaging apps depend on centralized infrastructure that can be monitored, censored, or disabled.\nbitchat creates ad-hoc communication networks using only the devices present in physical proximity.\neach device acts as both client and server, automatically discovering peers and relaying messages across multiple hops to extend the network's reach. this approach provides censorship resistance, surveillance resistance, and infrastructure independence.\nthe network remains functional during internet outages, natural disasters, protests, or in regions with limited connectivity. ios/macos version: appstore: bitchat mesh source code: https://github.com/permissionlesstech/bitchat supports ios 16.0+ and macos 13.0+. build using xcode with xcodegen or swift package manager. android version: play store: bitchat source code: https://github.com/permissionlesstech/bitchat-android apk releases: https://github.com/permissionlesstech/bitchat-android/releases supports android 8.0+ (api 26). full protocol compatibility with ios version. technical whitepaper: whitepaper.md the software is released into the public domain.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: How to introduce Claude Code to a team?", "url": "item?id=46689024", "content": "Ask HN: How to introduce Claude Code to a team?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Fix your robots.txt or your site disappears from Google", "url": "https://www.alanwsmith.com/en/37/wa/jz/s1/", "content": "Your site will be removed from Google search results if you don't have a robots.txt file or the Googlebot site crawler can't access it. Here's the video from Google Support that covers it: Adam Coster ran into a weird issue with site traffic and posted about it in the Shop Talk Show discord. Traffic incoming from Google looked like this: The issues seemed to be that Google wouldn't index the site without a robots.txt file. My first reaction: No fucking way. I can't imagine Google voluntarily slurping up less content. I went to see what I could find. Sure enough, I found this page from Google Support from July 23, 2025: Fix 'robots.txt unreachable' Error ~ Website Not Indexing? The pull quote from the video on the page: Your robots.txt file is the very first thing Googlebot looks for. If it can not reach this file, it will stop and won't crawl the rest of your site. Meaning your pages will remain invisible (on Google). Holy shit. I haven't looked to see if this was a recent change, but it has to be. There's no way something so fundamental has just slipped by without becoming common knowledge. But, the timeline doesn't matter. It's how things are now. This absolutely blows my mind. I don't have tracking on my site. I never would have noticed this if someone hadn't pointed it out. Just wild, -a Thanks to Adam for letting me share the traffic graph. If you need a quick fix, create a text file at the root of your website called \"robots.txt\" (e.g. https://www.example.com/robots.txt). Put the following contents in it: This is the code from Google's How to write and submit a robots.txt file page. It provides explicit permission for the Googlebot (and other bots/crawlers/scrapers that use the file) to access anything they can find on your site. You can read more about the file on the robots.txt wikipedia page . The top Stack Overflow answer on robots.txt has a discussion about Allow: / not being valid according to the spec. The only date for the comments is \"Over a year ago\"", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "jQuery 4", "url": "https://blog.jquery.com/2026/01/17/jquery-4-0-0/", "content": "On January 14, 2006, John Resig introduced a JavaScript library called jQuery at BarCamp in New York City. Now, 20 years later, the jQuery team is happy to announce the final release of jQuery 4.0.0. After a long development cycle and several pre-releases, jQuery 4.0.0 brings many improvements and modernizations. It is the first major version release in almost 10 years and includes some breaking changes, so be sure to read through the details below before upgrading. Still, we expect that most users will be able to upgrade with minimal changes to their code. Many of the breaking changes are ones the team has wanted to make for years, but couldn‚Äôt in a patch or minor release. We‚Äôve trimmed legacy code, removed some previously-deprecated APIs, removed some internal-only parameters to public functions that were never documented, and dropped support for some ‚Äúmagic‚Äù behaviors that were overly complicated. We have an upgrade guide and jQuery Migrate plugin release ready to assist with the transition. Please upgrade and let us know if you encounter any issues . As usual, the release is available on our CDN and the npm package manager. Other third party CDNs will probably have it available soon as well, but remember that we don‚Äôt control their release schedules and they will need some time. Here are the highlights for jQuery 4.0.0. jQuery 4.0 drops support for IE 10 and older. Some may be asking why we didn‚Äôt remove support for IE 11. We plan to remove support in stages, and the next step will be released in jQuery 5.0 . For now, we‚Äôll start by removing code specifically supporting IE versions older than 11. We also dropped support for other very old browsers, including Edge Legacy, iOS versions earlier than the last 3, Firefox versions earlier than the last 2 (aside from Firefox ESR), and Android Browser. No changes should be required on your end. If you need to support any of these browsers, stick with jQuery 3.x. jQuery 4.0 adds support for Trusted Types , ensuring that", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Sins of the Children", "url": "https://asteriskmag.com/issues/07/sins-of-the-children", "content": "The circle of life on Chelicer 14d. When we reached the weather station it was so comprehensively trashed you‚Äôd think it‚Äôd been dropped from orbit. Torn apart and the pieces stomped on, the edges corrugated with dents and corroded with fluids. Something on this planet really didn‚Äôt want us to know when it was going to rain. ‚ÄúThis is coming out of the use-budget,‚Äù Greffin said mournfully. She worked in Resources, liaising with the orbiting Garveneer to get what we needed. And we‚Äôd already needed plenty to get ourselves set up planetside. ‚ÄúWhat‚Äôs our culprit and how do we kill it?‚Äù Merrit asked. The three of us had set the station up three days before and somehow it had riled the locals. Probably the sonic and radio chatter from using bounce-back to map meteorological systems. But nothing we‚Äôd seen on all of Chelicer 14d was big or aggressive enough to do this damage. I had my slate out to review our evolving catalog of Chelicer xenofauna. Merrit was on his haunches, studying the shrapnel; Greffin had a link to base camp at the farms, going over inventory to see what we could repurpose. Around us and the wreckage stretched the local scrub. Sedentary life on Chelicer was either low and spiny or tall and thin with a sort of puffball arrangement at the top. The land ‚Äî the world ‚Äî was dry, the ecosystem impoverished and short on species. My unfinished xenobio report went long on the idea that Chelicer had been lush in the past, and we‚Äôd arrived to find what had stabilized out of a catastrophic dry spell, or maybe some serious solar flare activity. There were no great forests to give cover to alien tigers. On Chelicer nothing grew past a shrub. One meter for the spiny stuff, two for the puffball poles. And the weather station had been up on high ground, ten klicks‚Äô visibility in any direction. We were safe . I heard a far-off chunk . A mechanical sound that ‚Äî in the second‚Äôs pause before it impacted ‚Äî I didn‚Äôt even connect with life . The thing that came down right beside", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Graphics In Flatland ‚Äì 2D ray tracing [video]", "url": "https://www.youtube.com/watch?v=WYTOykSqf2Y", "content": "Graphics In Flatland ‚Äì 2D ray tracing [video]. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Director Gore Verbinski: Unreal Engine is the greatest slip backwards for movie", "url": "https://www.pcgamer.com/movies-tv/director-gore-verbinski-says-unreal-engine-is-the-greatest-slip-backwards-for-movie-cgi/", "content": "Do visual effects look worse than they used to? The director of Pirates of the Caribbean says Unreal is the culprit. When you purchase through links on our site, we may earn an affiliate commission. Here‚Äôs how it works . Remember the glory days of CGI in movies? Terminator 2's liquid metal T-1000, Jurassic Park's stunning dinosaurs, Starship Trooper's swarms of giant arachnids. Not only did the CGI look great then, most of the visual effects in those movies still hold up well today, even decades after they were created. Nowadays, movie fans seem much less impressed by CGI in films. There's a general distaste for a perceived overuse of CGI in favor of practical effects, and there are a lot of complaints that recent CGI is less-convincing and more fake-looking than it used to be, even in the biggest budget films. In an interview with But Why Tho? , Gore Verbinski, director of The Ring, Rango, and the first three Pirates of the Caribbean films, was asked why visual effects in movies just don't look as good as they used to. \"I think the simplest answer is you‚Äôve seen the Unreal gaming engine enter the visual effects landscape,\" Verbinski said. \"So it used to be a divide, with Unreal Engine being very good at video games, but then people started thinking maybe movies can also use Unreal for finished visual effects. So you have this sort of gaming aesthetic entering the world of cinema.\" Unreal Engine made waves after being used for virtual sets in production of The Mandalorian TV series back in 2020, and usage of the engine has grown more widespread in films over the past few years, such as in The Matrix Resurrections and Ant-Man and the Wasp: Quantumania. That's not good news, according to Verbinski. \"I think that Unreal Engine coming in and replacing Maya as a sort of fundamental is the greatest slip backwards,\" he said. He pointed out the types of visual effects made with Unreal aren't necessarily bad. \"It works with Marvel movies where you kind of know you‚Äôre in a he", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Weight Transfer for RL Post-Training in under 2 seconds", "url": "https://research.perplexity.ai/articles/weight-transfer-for-rl-post-training-in-under-2-seconds", "content": "We're Hiring We're Hiring We're Hiring systems Sep 24, 2025 Ultra-fast cross-GPU model sync We recently achieved 1.3-second cross-machine parameter updates for Kimi-K2 (1T parameters), transferring weights from 256 training GPUs (BF16) to 128 inference GPUs (FP8). In asynchronous reinforcement learning fine-tuning, training and inference run on separate GPUs. After each training step, new weights must be pushed to inference nodes. Many existing frameworks take several seconds√¢¬Ä¬îor even minutes√¢¬Ä¬îfor trillion-parameter models. By leveraging RDMA point-to-point communication , we are able to make the weight transfer blazing fast, without changing inference engine, and make the code easier to write and maintain. Our solution is built on RDMA WRITE, a one-sided primitive where the source directly writes into the destination√¢¬Ä¬ôs GPU memory. The destination side won√¢¬Ä¬ôt even get notified for the transfer. This gives us low-latency, high-throughput, zero-copy transfers driven by the training nodes without any control logic on the inference nodes. Metadata collection √¢¬Ä¬ì Controller gathers parameter metadata from all training and inference GPUs. Schedule computation √¢¬Ä¬ì Controller computes a static weight transfer schedule, mapping which training GPU sends which parameter to which inference GPU, and in what order. Schedule distribution √¢¬Ä¬ì Controller sends the schedule to all training GPUs. Execution √¢¬Ä¬ì After each training step, the controller signals training GPUs to start transfers. With the high-level workflow defined, the key challenge is how to execute weight transfers efficiently at trillion-parameter scale. Here we describe the details of the execution path. Parameters in training are distributed according to FSDP placements. Using full_tensor() , all GPUs in a DeviceMesh can reconstruct the full parameter, hence all can serve as a source for weight transfer. Multiple disjoint DeviceMeshes form a mesh group . Because DeviceMeshes in the same group are disjoint, thei", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "GLM-4.7-Flash", "url": "https://huggingface.co/zai-org/GLM-4.7-Flash", "content": "üëã Join our Discord community. üìñ Check out the GLM-4.7 technical blog , technical report(GLM-4.5) . üìç Use GLM-4.7-Flash API services on Z.ai API Platform. üëâ One click to GLM-4.7 . GLM-4.7-Flash is a 30B-A3B MoE model. As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency. Default Settings (Most Tasks) For multi-turn agentic tasks (œÑ¬≤-Bench and Terminal Bench 2), please turn on Preserved Thinking mode . Terminal Bench, SWE Bench Verified œÑ^2-Bench For œÑ^2-Bench evaluation, we added an additional prompt to the Retail and Telecom user interaction to avoid failure modes caused by users ending the interaction incorrectly. For the Airline domain, we applied the domain fixes as proposed in the Claude Opus 4.5 release report. For local deployment, GLM-4.7-Flash supports inference frameworks including vLLM and SGLang. Comprehensive deployment\ninstructions are available in the official Github repository. vLLM and SGLang only support GLM-4.7-Flash on their main branches. using with transformers as and then run: If you find our work useful in your research, please consider citing the following paper: Chat template Files info", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "For Russia, Greenland offers an 'ideal solution' to its Ukraine problemX", "url": "https://www.politico.eu/article/russia-greenland-offer-ideal-solution-ukraine-problem/", "content": "Moscow‚Äôs approach to the showdown over the Arctic island: Troll and hope the West falls apart. AI generated Text-to-speech Days after Donald Trump cited the threat from Russia as a reason to annex Greenland, the U.S. president invited Vladimir Putin to join his Board of Peace. Whiplash, anyone? Not to the Russians. Over the past weeks, Moscow‚Äôs response to Trump‚Äôs Greenland gambit has been just as disorienting. Kremlin officials have alternated between feigned sympathy for the residents of the Arctic island and open enthusiasm for Trump‚Äôs efforts to bring it into the American embrace. The contradiction points to a deliberate strategy: exploiting the crisis to weaken Western unity while keeping Trump focused elsewhere. In the weeks since Trump captured Venezuelan President Nicol√°s Maduro and threatened to intervene in Iran, Russia appears to have set aside its other geopolitical ambitions, including in the Arctic, to keep Washington in its corner on Ukraine. Meanwhile, it seems to be hoping tensions over Greenland will crack NATO and drive further wedges between Kyiv‚Äôs most important allies. ‚ÄúIt would have been difficult to imagine something like this happening before,‚Äù Russian Foreign Minister Sergey Lavrov said during a press conference on Tuesday, drily gloating over the diminishing ‚Äúprospects of preserving NATO as a unified Western military-political bloc.‚Äù The alarm over Greenland has already paid dividends for the Kremlin, pushing Ukraine off the agenda in Davos as European leaders scramble to the Alpine ski town to try to defuse the crisis. ‚ÄúGreenland [is the] ideal solution,‚Äù wrote Sergei Markov, a pro-Kremlin political analyst, on his Telegram channel. Tensions between Europe and the U.S. could serve as a stepping stone to the break-up of NATO. ‚ÄúThen the EU will be forced to stop its war against Russia,‚Äù he continued. After years spent bashing the ‚Äúcollective West,‚Äù pro-Kremlin propagandists are suggesting the country can now sit back and watch their enemies", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Verizon starts requiring 365 days of paid service before it will unlock phones", "url": "https://arstechnica.com/tech-policy/2026/01/verizon-starts-requiring-365-days-of-paid-service-before-it-will-unlock-phones/", "content": "Verizon changed prepaid brands‚Äô policy a week after FCC waived unlocking rule. Verizon has started enforcing a 365-day lock period on phones purchased through its TracFone division, one week after the Federal Communications Commission waived a requirement that Verizon unlock handsets 60 days after they are activated on its network. Verizon was previously required to unlock phones automatically after 60 days due to restrictions imposed on its spectrum licenses and merger conditions that helped Verizon obtain approval of its purchase of TracFone . But an update applied today to the TracFone unlocking policy said new phones will be locked for at least a year and that each customer will have to request an unlock instead of getting it automatically. The ‚Äúnew‚Äù TracFone policy is basically a return to the yearlong locking it imposed before Verizon bought the company in 2021. TracFone first agreed to provide unlocking in a 2015 settlement with the Obama-era FCC , which alleged that TracFone failed to comply with a commitment to unlock phones for customers enrolled in the Lifeline subsidy program. TracFone later shortened the locking period from a year to 60 days as a condition of the Verizon merger. While a locked phone is tied to the network of one carrier, an unlocked phone can be switched to another carrier if the device is compatible with the other carrier‚Äôs network. But the new TracFone unlocking policy is stringent, requiring customers to pay for a full year of service before they can get a phone unlocked. ‚ÄúFor all cellphones Activated on or after January 20, 2026, the cellphone will be unlocked upon request after 365 days of paid and active service,‚Äù the policy says. A customer who doesn‚Äôt maintain an active service plan for the whole 12 months will thus have their unlocking eligibility date delayed. Besides TracFone, the change applies to prepaid brands Straight Talk, Net10 Wireless, Clearway, Total Wireless, Simple Mobile, SafeLink Wireless, and Walmart Family Mobi", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nuudel: Non-Tracking Appointment Tool", "url": "https://nuudel.digitalcourage.de/", "content": "Termin finden Klassische Umfrage Wo sind meine Umfragen? Dieser Dienst wird vom gemeinn√ºtzigen Digitalcourage e.V. f√ºr Sie kostenlos angeboten. Unterst√ºtzen Sie den Betrieb und unsere Arbeit f√ºr eine lebenswerte Welt im digitalen Zeitalter als F√∂rdermitglied ! Digitalcourage : Newsletter | Spenden | English information", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A Social Filesystem", "url": "https://overreacted.io/a-social-filesystem/", "content": "January 18, 2026 Remember files? .doc .doc .doc .doc .jpg .jpg .svg You write a document, hit save, and the file is on your computer. It‚Äôs yours. You can inspect it, you can send it to a friend, and you can open it with other apps. Files come from the paradigm of personal computing . This post, however, isn‚Äôt about personal computing. What I want to talk about is social computing ‚Äîapps like Instagram, Reddit, Tumblr, GitHub, and TikTok. What do files have to do with social computing? Historically, not a lot‚Äî until recently. alice owns owns bob .doc .doc .doc .doc .doc .doc post post .jpg .jpg .jpg .jpg .jpg .jpg .jpg .jpg follow follow vote vote But first, a shoutout to files. Files, as originally invented, were not meant to live inside the apps. Since files represent your creations, they should live somewhere that you control. Apps create and read your files on your behalf, but files don‚Äôt belong to the apps. .doc .doc .doc .doc .jpg .jpg .svg C:\\Users\\alice alice owns Files belong to you‚Äîthe person using those apps. Apps (and their developers) may not own your files, but they do need to be able to read and write them. To do that reliably, apps need your files to be structured. This is why app developers, as part of creating apps, may invent and evolve file formats . A file format is like a language. An app might ‚Äúspeak‚Äù several formats. A single format can be understood by many apps. Apps and formats are many-to-many. File formats let different apps work together without knowing about each other. Consider this .svg : .jpg .jpg .svg C:\\Users\\alice SVG is an open specification. This means that different developers agree on how to read and write SVG. I created this SVG file in Excalidraw , but I could have used Adobe Illustrator or Inkscape instead. Your browser already knew how to display this SVG. It didn‚Äôt need to hit any Excalidraw APIs or to ask permissions from Excalidraw to display this SVG. It doesn‚Äôt matter which app has created this SVG. The file format is", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Robust Conditional 3D Shape Generation from Casual Captures", "url": "https://facebookresearch.github.io/ShapeR/", "content": "Robust Conditional 3D Shape Generation from Casual Captures Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins, Daniel DeTone, Pierre Moulon, Qirui Wu ‚Ä† , Zhengqin Li, Julian Straub, Richard Newcombe, Jakob Engel Meta Reality Labs Research ‚Ä† Simon Fraser University From an input image sequence, ShapeR preprocesses per-object multimodal data (SLAM points, images, captions). A rectified flow transformer then conditions on these inputs to generate meshes object-centrically, producing a full metric scene reconstruction. Conditioned on off-the-shelf preprocessed inputs‚ÄîSLAM points, 3D instances, and text‚ÄîShapeR infers per-object meshes to reconstruct the entire scene. While monolithic methods fuse the scene into one block, ShapeR reconstructs individual objects. This allows you to interact with and manipulate specific objects in the scene. ShapeR performs generative, object-centric 3D reconstruction from image sequences by leveraging multimodal inputs and robust training strategies. First, off-the-shelf SLAM and 3D instance detection are used to compute 3D points and object instances. For each object, sparse points, relevant images, 2D projections, and VLM captions are extracted to condition a rectified flow model, which denoises a latent VecSet to produce the 3D shape. The use of multimodal conditioning , along with heavy on-the-fly compositional augmentations and curriculum training , ensures the robustness of ShapeR in real-world scenarios. ShapeR conditions on a range of modalities, including the object's posed multiview images, SLAM points, text descriptions, and 2D point projections. ShapeR leverages single-object pretraining with extensive augmentations, simulating realistic backgrounds, occlusions, and noise across images and SLAM inputs. ShapeR is fine-tuned on object-centric crops from Aria Synthetic Environment scenes, which feature realistic image occlusions, SLAM point cloud noise, and inter-object interaction. For even more de", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "High-speed train collision in Spain kills at least 39", "url": "https://www.bbc.com/news/articles/cedw6ylpynyo", "content": "At least 39 people have died in a train collision in southern Spain and dozens more have been injured in the country's worst rail crash in more than a decade, Spain's Civil Guard has said. Carriages on a Madrid-bound train derailed and crossed over to the opposite tracks, colliding with an oncoming train in Adamuz on Sunday evening. Four hundred passengers and staff were onboard both trains, the rail networks said. Emergency services treated 122 people, with 43, including four children, still in hospital. Of those, 12 adults and one child are in intensive care. Spanish Transport Minister √ìscar Puente said the death toll \"is not yet final\", as officials launched an investigation. Puente described the incident as \"extremely strange\". All the railway experts consulted by the government \"are extremely baffled by the accident\", he told reporters in Madrid. Rail network operator Adif said the collision happened at 19:45 local time (18:45 GMT), about an hour after the train left M√°laga heading north to Madrid, when it derailed on a straight stretch of track near the city of C√≥rdoba. The force of the crash pushed the carriages of the second train into an embankment, Puente said. He added that most of those killed and injured were in the front carriages of the second train, which was travelling south from Madrid to Huelva. The type of train involved in the crash was a Freccia 1000, which can reach top speeds of 400 km/h (250 mph), a spokesperson for the Italian rail company Ferrovie dello Stato told Reuters news agency. Rescue teams said the twisted wreckage of the trains made it difficult to recover people trapped inside the carriages. C√≥rdoba fire chief Francisco Carmona told Spanish public broadcaster RTVE: \"We have even had to remove a dead person to be able to reach someone alive. It is hard, tricky work.\" Salvador Jimenez, a journalist with RTVE who was on one of the trains, said the impact felt like an \"earthquake\". \"I was in the first carriage. There was a moment whe", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Lume 0.2 ‚Äì Build and Run macOS VMs with unattended setup", "url": "https://cua.ai/docs/lume/guide/getting-started/introduction", "content": "Introduction to Lume - the macOS VM CLI and framework Lume is a VM runtime for building AI agents, running CI/CD pipelines, and automating macOS. It uses Apple's native Virtualization Framework to run macOS and Linux VMs at near-native speed on Apple Silicon. MIT License Lume is open-source and MIT licensed. If you find it useful, we'd appreciate a star on GitHub ! Cloud macOS Sandboxes We're piloting a managed service for customers who want to run cloud macOS sandboxes for CI/CD and agent workloads. Book a demo if you're interested. A single binary with an HTTP API. Create a VM, run it headlessly, control it programmatically.  You can use Lume directly via CLI, or run lume serve to expose an HTTP API for programmatic access. The Computer SDK uses this API to automate macOS interactions. Lume is a thin layer over Apple's Virtualization Framework , which provides hardware-accelerated virtualization on Apple Silicon. This gives you: Testing across macOS versions ‚Äî Spin up a VM with a specific macOS version, test your software, tear it down. No need to maintain multiple physical machines. Automating macOS tasks ‚Äî Combine Lume with Unattended Setup to create pre-configured VMs. The setup automation uses VNC and OCR to click through the Setup Assistant without manual intervention. Running CI/CD locally ‚Äî Test your macOS builds in isolated VMs before pushing to remote CI. The --no-display flag runs VMs headlessly. Sandboxing risky operations ‚Äî Need to test untrusted software or destructive scripts? Run them in a VM, then delete it. Clone a known-good VM to reset to a clean state instantly. Building AI agents ‚Äî Lume powers the Cua Computer SDK , providing VMs that AI models can interact with through screenshots and input simulation. Used by Anthropic Apple's Virtualization Framework‚Äîthe same technology Lume is built on‚Äîpowers Claude Cowork , Anthropic's sandboxed environment for Claude Code. It downloads a Linux root filesystem and boots it in an isolated VM where Claude c", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Folding NASA Experience into an Origamist's Toolkit (2024)", "url": "https://spinoff.nasa.gov/Folding_NASA_Experience_into_an_Origamist%E2%80%99s_Toolkit", "content": "What does origami have in common with electronics? Here, math once again proves to be a universal language, spanning not just cultures but disciplines. The discovery of the mathematical underpinnings of folded paper art helped Robert Lang leave a 20-year engineering career, including over four years at NASA‚Äôs Jet Propulsion Laboratory in Southern California, to pursue his lifelong passion for turning paper into impossibly intricate three-dimensional forms. ‚ÄúOver the years of solving mathematical problems to describe lasers and optoelectronics, I built up a toolkit to use as I worked on a hobby basis on this problem of computational origami design,‚Äù said Lang. The Altadena, California-based artist holds dozens of patents for optoelectronics‚Äâ‚Äî‚Äâtechnology that combines light and electricity‚Äâ‚Äî‚Äâbut after years of innovating in both fields, the tools he designed for origami are the ones he chose to move ahead with. In the Microdevices Laboratory at JPL in the late 1980s and early ‚Äô90s, Lang worked on integrating components like semiconductor lasers and spatial light modulators onto chips, with the ultimate goal of building an optical computer‚Äâ‚Äî‚Äâone that uses light, rather than electricity, to transmit information and carry out calculations. Steady advances in electronic computing have since removed some of the incentives to develop optical computers. ‚ÄúOne of the theoretical fields I learned about at JPL turned out to be the key to being able to plug in a description of a shape you wanted and then find the best possible design in great detail‚Äâ‚Äî‚Äâevery single crease you needed to make that shape,‚Äù said Lang. ‚ÄúAnd that turned out to be nonlinear constrained optimization.‚Äù It‚Äôs All About the Numbers A simple nonlinear constrained optimization problem would be the challenge of packing several different-sized balls into the smallest possible box, Lang explained. The constraint is that the balls can‚Äôt overlap each other, and the solutions are nonlinear because the balls can be a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A scammer's blueprint: How cybercriminals plot to rob a target in a week", "url": "https://www.reuters.com/graphics/SOUTHEASTASIA-SCAMS/MANUALS/klpyjlqelvg/", "content": "Are you free tonight?  NOTICE: Your bill is overdue.  Hello old friend, are you going to the party tonight?  hi there  hello  We√¢¬Ä¬ôve all received a random buzz on our phone √¢¬Ä¬î a message from an unknown number. Hey!  Many will ignore it, suspecting a scam. Hello darling.  Hey there  I hope you don√¢¬Ä¬ôt mind me contacting you  Hi Chris  Long time no see, how are you  what are you doing?  Aren√¢¬Ä¬ôt you my friend?  You have a package that needs to be claimed.  Hi, my name is Sam. It√¢¬Ä¬ôs nice to meet you. But for others, the unexpected message may present the chance for a new connection. A haven, or perhaps even romance. Illustration showing a warm, glowing, orange house among dark empty woods. Even if it was sent under false pretenses. Illustration showing the side of the house and how it is propped up by sticks, depicting a fake facade. So how does a scammer carefully construct a facade that can convince someone to part with their money √¢¬Ä¬ì and even to fall in love? Illustration showing the facade collapsed on the ground. Some can rely on intricately constructed guides to grooming and deception. A scammer√¢¬Ä¬ôs How cybercriminals plot to rob a target within a week. A handbook found during a police raid on a compound used by a cyberfraud gang in the Philippines offers detailed instructions in Chinese for conducting scams. A second handbook, seized during another law enforcement operation in the country and reviewed by Reuters, also gives tips in English and Chinese about how to run romance scams. Together, they provide a window into the psychological techniques criminal gangs use to beguile a victim into believing they are in a romantic relationship, before duping them into fraudulent investments.√Ç¬†√Ç The Chinese handbook says: This kind of fraud is known as √¢¬Ä¬úpig-butchering√¢¬Ä¬ù because the gangs say targets are led like hapless pigs to slaughter. It is among the most prevalent scams today, according to the FBI. In a series of stories in 2025, Reuters documented how these", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The fix for a segfault that never shipped", "url": "https://www.recall.ai/blog/the-fix-for-a-segfault-that-never-shipped", "content": "At Recall.ai , we run an unusual workload. We record millions of hours of meetings every month. Each of these meetings generates a large amount of audio and video we need to reliably capture and analyze. The audio we capture comes in a variety of shapes and sizes, an assortment of codecs, channels, sample rates, interleaving, and error-correction schemes. We normalize all of those into one consistent format that is universally playable. We launch 18 million of EC2 instances every month, each of these instances is a √¢¬Ä¬úmeeting bot√¢¬Ä¬ù, which joins a video call and captures the data in real-time. Extremely rarely, about 1 in 36 million bots would abruptly crash deep in library code of our media pipeline. Unlike most√Ç¬†web servers, a meeting bot instance is extremely stateful and very hard to replace, a fatal error like this means the data is irrecoverably lost - forever. Even a one-in-tens-of-millions failure rate was unacceptable. This is the story of how we tracked down the rare bug, went to significant effort to reproduce it, identify the root cause and fix it. We encountered an extremely rare segfault in the AAC encoder we were using and root caused it to a bug in the fixed-point math C code. We found this was patched over a decade ago but the fix was never shipped to downstream consumers. Rather than fixing the bug we replaced the library with a modern AAC encoder which did not experience these crashes. This crash was so rare that reproducing it locally wasn√¢¬Ä¬ôt feasible. Instead we opted to capture the program state from production, in the rare event this happens. Our first clue was the process 139 exit code ( 139 = 128 + 11 ). Signal 11 corresponds to SIGSEGV, a segmentation fault or segfault for short, this occurs when a program tries to access memory it is not supposed to. This mistake is bad enough that the execution of the program should halt immediately. So how do we determine the cause of a SIGSEGV? The answer is often a core dump file. A core dump lets us", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Threads edges out X in daily mobile users, new data shows", "url": "https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/", "content": "Latest AI Amazon Apps Biotech & Health Climate Cloud Computing Commerce Crypto Enterprise EVs Fintech Fundraising Gadgets Gaming Google Government & Policy Hardware Instagram Layoffs Media & Entertainment Meta Microsoft Privacy Robotics Security Social Space Startups TikTok Transportation Venture Staff Events Startup Battlefield StrictlyVC Newsletters Podcasts Videos Partner Content TechCrunch Brand Studio Crunchboard Contact Us A report from market intelligence firm Similarweb suggests that Meta‚Äôs Threads is now seeing more daily usage than Elon Musk‚Äôs X on mobile devices. While X still dominates Threads on the web, the Threads mobile app for iOS and Android has continued to see an increase in daily active users over the past several months. Similarweb‚Äôs data shows that Threads had 141.5 million daily active users on iOS and Android as of January 7, 2026, after months of growth, while X has 125 million daily active users on mobile devices. This appears to be the result of longer-term trends, rather than a reaction to the recent X controversies, where users were discovered using the platform‚Äôs integrated AI, Grok, to create non-consensual nude images of women, including, sometimes minors. Concern around the deepfake images has now prompted California‚Äôs attorney general to open an investigation into Grok, following similar investigations by other regions, like the U.K. , EU, India, Brazil, and many more . The drama on X also led social networking startup Bluesky to see an increase in app installs in recent days. Instead, Threads‚Äô boost in daily mobile usage may be driven by other factors, including cross-promotions from Meta‚Äôs larger social apps like Facebook and Instagram (where Threads is regularly advertised to existing users), its focus on creators, and the rapid rollout of new features. Over the past year, Threads has added features like interest-based communities , better filters , DMs , long-form text , and disappearing posts , and has recently been spotted te", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Typography on Pencils (2023)", "url": "https://www.presentandcorrect.com/blogs/blog/typography-on-pencils-1-5", "content": "Happy New Year! Our shop is open again, click for hours It wouldn't be Pencil Day without a round up of our pencil typography photos. Check out our current stock of new & vintage pencils here. Please do credit us if you use these images anywhere. Thank you.  Sign up to our newsletter here . Thank you. 12 Bury Place London WC1A 2JL 020 72421421 info@presentandcorrect.com", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Understanding C++ Ownership System", "url": "https://blog.aiono.dev/posts/understanding-c++-ownership-system.html", "content": "I recently started using C++ at my $DAY_JOB and, along with that, decided to study C++ again. I think writing down your understanding is the best way to learn a topic. One part I find that is hard to understand in C++ is how the object ownership model works because it's not a single concept but a collection of a couple of smaller concepts. By ownership I mean creating and destroying objects, giving references to an object, and transferring ownership of an object. There is no one guide that covers everything. These concepts are very important to write and read modern C++ (though I doubt if C++11 is still considered \"modern\"). Even if you just want to write C with Classes-style C++, you will probably use standard containers like std::vector , which requires an understanding of C++ ownership related features such as RAII, references, and move semantics to use it properly. Without knowing those, you simply can't have the correct memory model for C++, resulting in buggy programs full of undefined behaviors and inefficient programs due to unnecessary copying. By knowing these concepts, you can both avoid introducing bugs due to lack of understanding and reason about programs better. This writing is my understanding of C++ ownership model. I think it can be useful to you if you have a basic level understanding of C++ and you want to learn more, or you are familiar with C++ but never learned the concepts and terminology formally. In C++, every object has an owner, which is responsible for cleaning up the data once it's not used anymore. If you come from garbage collected languages, the concept of ownership may seem strange to you. But consider the following code: This is a function that returns the file's name as a C-style string. What's not documented though, is who is supposed to deallocate the returned string. In this case there are two possibilities: Depending on which one is the case, the caller must act differently. This is because the owner of the data is different b", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: E80: an 8-bit CPU in structural VHDL", "url": "https://github.com/Stokpan/E80", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A simple CPU in VHDL for educational purposes There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A simple CPU in VHDL, developed from scratch for my undergraduate thesis to provide all three characteristics of a Constructionist Microworld : This makes it easy to use, capable of running pretty complex and realistic programs, and can be used in multiple lab or classroom scenarios. Notes Notes The following program writes the null-terminated string `az{\"0 to memory after the last instruction (notice the label under HLT) and converts the lowercase characters to uppercase, stopping when it hits the terminator: To simulate it, first install the E80 Toolchain package from the Releases, then open the E80 Editor and paste the code into it:  Notice that syntax highlighting for the E80 assembly language has been enabled by default for all code (except for VHDL files). Press F5. The editor will automatically assemble the code, save the VHDL output, compile the entire design with GHDL, and launch a GTKWave instance. Subsequent simulations will be closing the previous GTKWave window to open a new one. You should see the following waveform, in which the RAM has been expanded to show how the lowercase letters of the string have changed to uppercase:  Notice that the HLT instruction has stopped the simulation in GHDL, allowing for the waveforms to be drawn for the runtime only. This useful feature is supported in ModelSim as well. You can also press F7 to view the generated Firmware.vhd file, without simulation:  Notice how the assembler formats the output into columns according to instruction size, and annotates each line to its respective disassembled instruction, ASCII character or number. If you have installed ModelSim, you can press F8 to automatically open ModelSim and simulate into it", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Simple Sabotage Field Manual (1944) [pdf]", "url": "https://www.cia.gov/static/5c875f3ec660e092cf893f60b4a288df/SimpleSabotage.pdf", "content": "Simple Sabotage Field Manual (1944) [pdf]. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Legal Structures for Latin American Startups (2021)", "url": "https://latamlist.com/legal-structures-for-latin-american-startups/", "content": "There‚Äôs confusion around what legal structures make sense for Latin American startups. Founders, VCs and even lawyers can make decisions that can cost upwards of $100M if you get it wrong. This post is the result of investing in 80+ startups from 15+ Latin American countries since 2014 via Magma Partners , and speaking to and working with countless lawyers across LatAm, US, UK, Europe and multiple offshore jurisdictions. I wrote a version of this that I‚Äôve been sharing with Magma Partners founders internally and decided to open source it with the hope that founders save themselves time and money and make themselves more investable. There are fairly clear outlines that most Latin American startups should likely follow. Every startup‚Äôs case is different, and each founder should get legal advice from a lawyer and tax advice from an accountant with relevant US and Latin American venture capital experience before following this guide or anyone else‚Äôs ideas. To be clear, this is not legal or tax advice. You should always work with a lawyer and accountant when thinking about corporate structures. The money you‚Äôll spend getting good advice will save hundreds of thousands or even hundreds of millions of dollars down the road. I can‚Äôt stress this enough. Don‚Äôt just follow these guidelines. Your situation is unique. Talk to an experienced lawyer and accountant. Let‚Äôs start with a story. Brian Requarth, cofounder of Vivareal and Latitud had a big exit in 2020. His structure cost him and his investors $100M: In the early days of a startup, money is tight and it‚Äôs common to cut corners. I created a California LLC for my company because of my local accountant‚Äôs advice. He had zero experience with VC or Latin America. Later, I hired a my hometown law firm that had no VC experience, which advised me to create a C-Corp, which seemed like good advice at the time. We later realized that even though our business had no operations in the US, we would be subject to US taxes upon an exit.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Gladys West's vital contributions to GPS technology", "url": "https://en.wikipedia.org/wiki/Gladys_West", "content": "Gladys Mae West (n√©e Brown ; October 27, 1930 ‚Äì January 17, 2026) was an American mathematician. She was known for her contributions to mathematical modeling of the shape of the Earth , and her work on the development of satellite geodesy models, that were later incorporated into the Global Positioning System (GPS). [ 1 ] West was inducted into the United States Air Force Hall of Fame in 2018. She was awarded the Webby Lifetime Achievement Award for the development of satellite geodesy models. [ 2 ] [ 3 ] Gladys Mae Brown was born in Sutherland, Virginia , in Dinwiddie County , a rural county south of Richmond , on October 27, 1930. [ 1 ] [ 4 ] [ 5 ] [ 6 ] Her family was an African-American farming family in a community of sharecroppers . She spent much of her childhood working on her family's small farm. [ 7 ] [ 8 ] As well as working on the farm, her mother worked in a tobacco factory and her father worked for the railroad. [ 5 ] [ 9 ] West saw education as her way to a different life. [ 10 ] At West's high school, the top two students from each graduating class received full scholarships to Virginia State College ( Virginia State University (VSU)), a historically black public university . [ 7 ] West graduated as valedictorian in 1948, and received the scholarship. [ 5 ] [ 10 ] At VSU, she chose to study mathematics, a subject that was mostly studied by men. [ 7 ] She also joined the Alpha Kappa Alpha sorority. [ 1 ] West graduated in 1952 with a Bachelor of Science degree in mathematics, [ 5 ] and then taught mathematics and science for two years in Waverly , Virginia. [ 5 ] West returned to VSU to complete a Master of Mathematics degree, graduating in 1955. [ 10 ] [ 5 ] Afterwards, she began another teaching position in Martinsville , Virginia. [ 5 ] In 1956, West was hired to work at the Naval Proving Ground in Dahlgren , Virginia (later the Naval Surface Warfare Center ). She was the second black woman hired and one of only four black employees. [ 7 ] [ 4 ] [", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Windows 11 had 20 major update problems in 2025 and and 2026 started badly too", "url": "https://www.windowslatest.com/2026/01/21/windows-11-had-20-major-update-problems-in-2025-and-and-2026-started-badly-too-what-are-you-doing-microsoft/", "content": "Just weeks into 2026, Windows 11 is already tripping over itself again. As Windows Latest recently reported, the January 2026 update KB5074109 shipped with a fresh set of problems , including black screens and frozen Outlook POP accounts. That update made it very clear that whatever lessons Microsoft was supposed to learn in 2025, it didn‚Äôt. Windows 11 is at a point where it is hated by virtually everyone on the internet, and Microsoft just doesn‚Äôt seem to care. We checked through our posts from 2025 and made a list of all the issues that the most popular desktop operating system gave to its users in the last year. 2025 has been a catastrophe for Microsoft, with more issues than ever before. A big part of the problem is focus, or the lack of it. While core parts of Windows 11 kept breaking update after update, Microsoft was busy pushing Copilot into every nook and corner of Windows. We have listed the top 20 Windows 11 issues from 2025 below, but there were many more bugs that didn‚Äôt make headlines. At this point, for many users, Windows 11 has become the most disliked version of Windows Microsoft has ever shipped. As originally reported by Windows Latest, the very first security update in the second week of 2025 (KB5050009 for 24H2 and KB5050021 for 23H2) broke the audio for users with external USB Digital-to-Analog Converters (DACs) . In our testing, we found that the audio in our PC stopped working as soon as the update was installed, and the main casualties were those who use a USB audio DAC. The issue was so widespread that Windows 11 versions 24H2, 23H2, and 22H2 were all affected. Even the famously stable Windows 10 wasn‚Äôt spared from audio failure. The Device Manager showed the following error message: ‚ÄúThis device cannot start. (Code 10) Insufficient system resources exist to complete the API.‚Äù Our analysis was that Windows 11 was failing to allocate memory to the device, preventing DACs from transferring audio signals to your headphones. Microsoft acknowle", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "There's a hidden Android setting that spots fake cell towers", "url": "https://www.howtogeek.com/theres-a-hidden-android-setting-that-spots-fake-cell-towers/", "content": "Most people never give a second thought to how their phone connects to a cell tower. It‚Äôs something that constantly happens in the background without our input, and therein lies the potential for trouble. What if that tower isn't what it seems? Android can tell you about it‚Äîmaybe. Let‚Äôs get the scary stuff out of the way first. ‚Äú Stingrays ,‚Äù technically known as IMSI (international mobile subscriber identity) catchers, are devices primarily used for surveillance. They mimic cell towers and act as a middleman between your phone and the network. Once your device is tricked into connecting to what it believes to be a real cell tower, the attacker can harvest device information and force your phone onto an older, unencrypted protocol. This is what allows them to listen to your calls or read your texts without you ever knowing something is wrong. It‚Äôs also possible for the attacker to harvest information from the phones of people nearby when this happens. While Stingrays have been used by law enforcement agencies for years to track suspects, it‚Äôs now much easier for malicious individuals to get their hands on them and skim data from innocent people. You might think that switching from Facebook Messenger to old-fashioned text messages would help protect your privacy. But standard SMS text messages aren't very private or secure. SMS is like fax---an old, outdated standard that refuses to go away. The good news is that Google has been slowly building a wall against these attacks‚Äîemphasis on ‚Äúslowly.‚Äù In 2021, Google released Android 12 with the ability to disable 2G connectivity. Stringrays like this network for its weak security. Two years later, it announced that Android 14 would support disabling an old form of encryption that makes it easy to intercept SMS and calls. Then Android 15 addressed Stingrays with the ability to notify the OS when a network requests your identifiers or forces you onto a less secure encryption method. That brings us up to Android 16‚Äîthe latest", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Open-source tool for converting docs into .md and loading into Postgres", "url": "https://github.com/pgEdge/pgedge-docloader", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A tool for converting HTML and RST docs into Markdown, and loading them into PostgreSQL. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  pgEdge Document Loader is a command-line tool for loading documents from various formats into PostgreSQL databases.  Full documentation is available here . The pgEdge Document Loader automatically converts documents (HTML, Markdown, reStructuredText, and SGML/DocBook) to Markdown format and loads them into a PostgreSQL database with extracted metadata. Features The pgEdge Document Loader automatically converts documents (HTML, Markdown, reStructuredText, and DocBook SGML/XML) to Markdown format and loads them into a PostgreSQL database with extracted metadata. Features Before installing and using pgEdge Document Loader, download and install: Getting started with pgEdge Document Loader involves three steps: Installing pgEdge Document Loader Use the following commands to download and build pgedge-docloader : Creating a Postgres Table Before invoking Document Loader, you must configure a Postgres database and create a table with the appropriate columns to hold the extracted documentation content: Invoking pgedge-docloader When invoking pgedge-docloader , you can specify configuration preferences on the command line , or with a configuration file . The following command invokes Document Loader on the command line : To manage deployment preferences in a configuration file , save your deployment details in a file, and then include the --config keyword when invoking pgedge-docloader : For a comprehensive Quickstart Guide, visit here . This project is under active development. See the documentation for the latest\nfeatures and updates. The pgEdge Document Loader Makefile includes clauses that run test cases or invoke the go linter.  Use the foll", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "SWE-gen: Scaling SWE-bench task generation", "url": "https://github.com/abundant-ai/SWE-gen", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Convert GitHub PRs into Harbor tasks There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .   Convert merged GitHub PRs into Harbor tasks automatically. Automates task creation from real bug fixes in open-source GitHub repos. Works with any programming language : Claude Code analyzes the repo to detect language, build system, and test framework. Each task reverses a merged PR to recreate the buggy state, verifies tests fail on baseline, and pass after applying the fix. Fully containerized with all dependencies installed at build time. Ensure these environment variables are set: Note: Cloud sandbox environments (Daytona, E2B, Modal, etc.) require additional API keys. Commands: Stream through entire PR history, process each sequentially with state persistence. Verify that a task passes NOP (baseline fails) and Oracle (solution succeeds) agents: Run agent trials to verify a task is well-specified and solvable: Classification categories: Languages: Any (Python, JavaScript, TypeScript, Go, Rust, Ruby, Java, etc.) Valid PRs must: The pipeline uses a language-agnostic approach : Key Details: Apache License 2.0 Convert GitHub PRs into Harbor tasks There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Movieagent.io ‚Äì An agent for movie recommendations (with couple mode)", "url": "https://movieagent.io", "content": "Show HN: Movieagent.io ‚Äì An agent for movie recommendations (with couple mode). Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: What are the recommender systems papers from 2024-2025?", "url": "item?id=46692368", "content": "Ask HN: What are the recommender systems papers from 2024-2025?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: A creative coding library for making art with desktop windows", "url": "https://github.com/willmeyers/window-art", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A minimal Python library for live coding visual scenes using desktop windows. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A minimal Python library for live coding visual scenes using desktop windows.  A minimal Python library for live coding visual scenes using desktop windows. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "I Burned $160k Trying to Solve \"Online Tailoring\"", "url": "https://www.indiehackers.com/post/how-i-burned-160-000-trying-to-solve-online-tailoring-the-engineering-reality-check-fbd7e0ccdd", "content": "Report In 2023, I placed a crazy bet. I founded a fashion-tech startup with a vision of ‚ÄúPhygital Tailoring‚Äù . My goal was simple but audacious: Clients in the world should receive perfect-fit bespoke suits without ever leaving their homes. I entered the space with the arrogance of a typical disruptor: ‚ÄúIf I just use high-resolution 3D scanning, I can replace the traditional tailor. Math will solve everything.‚Äù I was wrong. After 900 days of development and burning through $160,000 in savings, I realized why the current market solutions were failing. I used to think of ‚ÄúFit‚Äù as a math problem. It isn‚Äôt. It‚Äôs a physics and logic problem. Here is the hard technical truth about why ‚ÄúOnline Tailoring‚Äù became a graveyard for my initial capital, and the four engineering bottlenecks we had to overcome. Most scanning SDKs rely on the user holding the phone or placing it on a table. The Problem : Users struggle with geometry. My assumption that users could hold a device perfectly perpendicular to the floor was flawed. The Data : A mere 5-degree tilt results in a 2‚Äì3cm error in leg length. In bespoke tailoring, a 3cm error is the difference between a wearable suit and a disaster. My Fix : I stopped trusting the raw scan. We built a secondary algorithm on top of the standard scanning SDK to detect device orientation. If the angle isn‚Äôt perfect, the system forces a ‚ÄúNormalization‚Äù process to mathematically correct the geometric distortion before data entry. This was the most common failure point. A 3D scan gives you Body Measurements (the skin). But a suit requires Garment Measurements (the shell). The Problem : Machines don‚Äôt understand ‚ÄúEase‚Äù (movement allowance) or ‚ÄúDrape‚Äù (fabric fall). My raw translation of scan-to-pattern resulted in a skin-tight suit that looked like a wetsuit. My Fix : Where AI failed, humans succeeded. I spent two years digitizing the logic of old-school Master Tailors. I built a ‚ÄúHuman Logic Filter‚Äù that sits between the scan and the CAD system, autom", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Texas police invested in phone-tracking software and won‚Äôt say how it‚Äôs used", "url": "https://www.texasobserver.org/texas-police-invest-tangles-sheriff-surveillance/", "content": "The Texas Observer Since 1954 Investigations One sheriff who leads an anti-smuggling task force says the software helps ‚Äúdevelop leads to eventually obtain probable cause.‚Äù Civil liberties experts say its use violates constitutional rights. by Francesca D‚ÄôAnnunzio January 13, 2026, 8:40 AM, CST Editor‚Äôs Note: This story is the third installment in a series produced in partnership with the Pulitzer Center‚Äôs AI Accountability Network. Goliad County police kicked off one human smuggling investigation not with a suspect‚Äôs name, but with a discarded receipt and cell phone surveillance software. In June 2021, Chief Deputy Tim Futch chased a speeding F-150 headed toward Houston on U.S. Highway 59; he believed the vehicle was carrying undocumented immigrants, concealed in the truck bed beneath plywood, according to a police report. Trying to evade the cops, the driver pulled into a ditch, and around 10 people bailed out and took off sprinting. In the aftermath, Roy Boyd, the sheriff in this county of 7,000 situated halfway between Laredo and Houston, surveyed the scene. The driver proved hard to identify via the pickup‚Äôs plate. But, on the ground, he spotted a fresh receipt from a liquor store in Pasadena, a Houston suburb, he recalled in a June 2024 interview with the Texas Observer . The stub of paper was enough, Boyd said, to justify deploying an expensive‚Äîand controversial‚Äîartificial intelligence-powered surveillance tool called Tangles. A specially-trained analyst used the receipt, Boyd said, to conduct warrantless surveillance on the suspected driver‚Äîand on other smart phone users‚Äîby utilizing a Tangles add-on feature called Webloc, which tracks mobile devices‚Äô movements in a client-selected virtual area through a capability called ‚Äúgeofencing.‚Äù After the bailout incident, Boyd acquired a license for the tool with about $300,000 in state border security grants‚Äîthough the sheriff admits that he‚Äôs not a tech guy: In 2024, he still used a hand-me-down iPhone 10, which hi", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Opening the AWS European Sovereign Cloud", "url": "https://aws.amazon.com/blogs/aws/opening-the-aws-european-sovereign-cloud/", "content": "Search AWS Blogs Deutsch | English | Espa√±ol | Fran√ßais | Italiano As a European citizen, I understand first-hand the importance of digital sovereignty, especially for our public sector organisations and highly regulated industries. Today, I‚Äôm delighted to share that the AWS European Sovereign Cloud is now generally available to all customers. We first announced our plans to build this new independent cloud infrastructure in 2023 , and today it‚Äôs ready to meet the most stringent sovereignty requirements of European customers with a comprehensive set of AWS services . Berlin, Brandenburg Gate at sunset Meeting European sovereignty requirements Organizations across Europe face increasingly complex regulatory requirements around data residency, operational control, and governance independence. Too often today, European organisations with the highest sovereignty requirements are stuck in legacy on-premises environments or offerings with reduced services and functionality. In response to this critical need, the AWS European Sovereign Cloud is the only fully featured and independently operated sovereign cloud backed by strong technical controls, sovereign assurances, and legal protections. Public sector entities and businesses in highly regulated industries need cloud infrastructure that provides enhanced sovereignty controls that maintain the innovation, security, and reliability they expect from modern cloud services. These organisations require assurance that their data and operations remain under European jurisdiction, with clear governance structures and operational autonomy within the European Union (EU). A new independent cloud infrastructure for Europe The AWS European Sovereign Cloud represents a physically and logically separate cloud infrastructure, with all components located entirely within the EU. The first AWS Region in the AWS European Sovereign Cloud is located in the state of Brandenburg, Germany, and is generally available today. This Region operates i", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: I built a tool to assist AI agents to know when a PR is good to go", "url": "https://dsifry.github.io/goodtogo/", "content": "Deterministic PR readiness detection for AI coding agents View the Project on GitHub dsifry/goodtogo The missing piece in AI-assisted development: knowing when you‚Äôre actually done. AI coding agents are transforming software development. They can write code, fix bugs, respond to review comments, and create pull requests. But they all share one fundamental problem: They can‚Äôt reliably know when a PR is ready to merge. Think about it. When you ask an AI agent to ‚Äúfix the CI and address the review comments,‚Äù how does it know when it‚Äôs finished? Without deterministic answers, agents either: Good To Go provides a single command that answers the question definitively: That‚Äôs it. One command. One answer. No ambiguity. No guessing. No infinite loops. Good To Go analyzes your PR across three dimensions: Combines all GitHub check runs and commit statuses into a single pass/fail/pending state. Handles the complexity of multiple CI systems, required vs optional checks, and in-progress runs. Not all review comments are created equal. Good To Go classifies each comment as: Built-in parsers understand the patterns of popular automated reviewers: Distinguishes between truly unresolved discussions and threads that are technically ‚Äúunresolved‚Äù but already addressed in subsequent commits. Good To Go is built specifically for how AI agents work: Default mode returns 0 for any analyzable state‚Äîbecause AI agents should parse the JSON output, not interpret exit codes as errors. Every response includes exactly what an agent needs to take action: Track what‚Äôs already been handled across agent sessions: Make gtg a required status check. PRs can‚Äôt merge until they‚Äôre truly ready‚Äînot just ‚ÄúCI passed.‚Äù When you‚Äôve resolved threads or addressed comments, trigger a quick re-check without rebuilding CI: Comment this on any PR to get instant feedback: Or trigger manually via workflow dispatch: Give your AI agent a definitive answer instead of endless polling: Monitor a PR through its entire lifecyc", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Command-line Tools can be 235x Faster than your Hadoop Cluster (2014)", "url": "https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html", "content": "Adam Drake Jan 18, 2014 As I was browsing the web and catching up on some sites I visit periodically, I found a cool article from Tom Hayden about using Amazon Elastic Map Reduce (EMR) and mrjob in order to compute some statistics on win/loss ratios for chess games he downloaded from the millionbase archive , and generally have fun with EMR. Since the data volume was only about 1.75GB containing around 2 million chess games, I was skeptical of using Hadoop for the task, but I can understand his goal of learning and having fun with mrjob and EMR. Since the problem is basically just to look at the result lines of each file and aggregate the different results, it seems ideally suited to stream processing with shell commands. I tried this out, and for the same amount of data I was able to use my laptop to get the results in about 12 seconds (processing speed of about 270MB/sec), while the Hadoop processing took about 26 minutes (processing speed of about 1.14MB/sec). After reporting that the time required to process the data with 7 c1.medium machine in the cluster took 26 minutes, Tom remarks This is probably better than it would take to run serially on my machine but probably not as good as if I did some kind of clever multi-threaded application locally. This is absolutely correct, although even serial processing may beat 26 minutes. Although Tom was doing the project for fun, often people use Hadoop and other so-called Big Data (tm) tools for real-world processing and analysis jobs that can be done faster with simpler tools and different techniques. One especially under-used approach for data processing is using standard shell tools and commands. The benefits of this approach can be massive, since creating a data pipeline out of shell commands means that all the processing steps can be done in parallel. This is basically like having your own Storm cluster on your local machine. Even the concepts of Spouts, Bolts, and Sinks transfer to shell pipes and the commands betw", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nvidia contacted Anna's Archive to access books", "url": "https://torrentfreak.com/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books/", "content": "Home > AI > NVIDIA executives allegedly authorized the use of millions of pirated books from Anna's Archive to fuel its AI training. In an expanded class-action lawsuit that cites internal NVIDIA documents, several book authors claim that the trillion-dollar company directly reached out to Anna's Archive, seeking high-speed access to the shadow library data. Chip giant NVIDIA has been one of the main financial beneficiaries in the artificial intelligence boom. Revenue surged due to high demand for its AI-learning chips and data center services, and the end doesn‚Äôt appear to be in sight. Besides selling the most sought-after hardware, NVIDIA is also developing its own models, including NeMo, Retro-48B, InstructRetro, and Megatron. These are trained using their own hardware and with help from large text libraries, much like other tech giants do. Like other tech companies, NVIDIA has also seen significant legal pushback from copyright holders in response to its training methods. This includes authors, who, in various lawsuits, accused tech companies of training their models on pirated books. In early 2024, for example, several authors sued NVIDIA over alleged copyright infringement. Through the class action lawsuit, they claimed that the company‚Äôs AI models were trained on the Books3 dataset that included copyrighted works taken from the ‚Äòpirate‚Äô site Bibliotik. Since this happened without permission, the authors demanded compensation. In response, NVIDIA defended its actions as fair use, noting that books are nothing more than statistical correlations to its AI models. However, the allegations didn‚Äôt go away. On the contrary, the plaintiffs found more evidence during discovery. Last Friday, the authors filed an amended complaint that significantly expands the scope of the lawsuit. In addition to adding more books, authors, and AI models, it also includes broader ‚Äúshadow library‚Äù claims and allegations. The authors, including Abdi Nazemian , now cite various internal N", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Floating-Point Printing and Parsing Can Be Simple and Fast", "url": "https://research.swtch.com/fp", "content": "A floating point number f has the form f = m ¬∑ 2 e where m is called the mantissa and e is a signed integer exponent .\nWe like to read numbers scaled by powers of ten,\nnot two, so computers need algorithms to convert binary floating-point\nto and from decimal text.\nMy 2011 post ‚Äú Floating Point to Decimal Conversion is Easy ‚Äù\nargued that  these conversions can be simple as long as you\ndon‚Äôt care about them being fast.\nBut I was wrong: fast converters can be simple too,\nand this post shows how. The main idea of this post is to implement fast unrounded scaling ,\nwhich computes an approximation to x ¬∑ 2 e ¬∑ 10 p ,\noften in a single 64-bit multiplication.\nOn that foundation\nwe can build nearly trivial printing and parsing algorithms that run very fast.\nIn fact, the printing algorithms\nrun faster than all other known algorithms,\nincluding\nDragon4 [ 30 ],\nGrisu3 [ 23 ],\nErrol3 [ 4 ],\nRy≈´ [ 2 ],\nRy≈´ Printf [ 3 ],\nSchubfach [ 12 ],\nand Dragonbox [ 17 ],\nand the parsing algorithm runs faster than\nthe Eisel-Lemire algorithm [ 22 ].\nThis post presents both the algorithms and a concrete implementation in Go.\nI expect some form of this Go code to ship in Go 1.27 (scheduled for August 2026). This post is rather long‚Äîfar longer than the implementations!‚Äîso here is a brief overview of the sections\nfor easier navigation and understanding where we‚Äôre headed. ‚Äú Fixed-Point and Floating-Point Numbers ‚Äù\nbriefly reviews fixed-point and floating-point numbers,\nestablishing some terminology and concepts needed for the rest of the post. ‚Äú Unrounded Numbers ‚Äù introduces the idea of unrounded numbers,\ninspired by the IEEE754 floating-point extended format. ‚Äú Unrounded Scaling ‚Äù defines the unrounded scaling primitive. ‚Äú Fixed-Width Printing ‚Äù formats floating-point numbers\nwith a given (fixed) number of decimal digits, at most 18. ‚Äú Parsing Decimals ‚Äù parses decimal numbers of\nat most 19 digits into floating-point numbers. ‚Äú Shortest-Width Printing ‚Äù formats floating-point numbers\nusing the sh", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Command-line Tools can be 235x Faster than your Hadoop Cluster (2014)", "url": "https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html", "content": "Adam Drake Jan 18, 2014 As I was browsing the web and catching up on some sites I visit periodically, I found a cool article from Tom Hayden about using Amazon Elastic Map Reduce (EMR) and mrjob in order to compute some statistics on win/loss ratios for chess games he downloaded from the millionbase archive , and generally have fun with EMR. Since the data volume was only about 1.75GB containing around 2 million chess games, I was skeptical of using Hadoop for the task, but I can understand his goal of learning and having fun with mrjob and EMR. Since the problem is basically just to look at the result lines of each file and aggregate the different results, it seems ideally suited to stream processing with shell commands. I tried this out, and for the same amount of data I was able to use my laptop to get the results in about 12 seconds (processing speed of about 270MB/sec), while the Hadoop processing took about 26 minutes (processing speed of about 1.14MB/sec). After reporting that the time required to process the data with 7 c1.medium machine in the cluster took 26 minutes, Tom remarks This is probably better than it would take to run serially on my machine but probably not as good as if I did some kind of clever multi-threaded application locally. This is absolutely correct, although even serial processing may beat 26 minutes. Although Tom was doing the project for fun, often people use Hadoop and other so-called Big Data (tm) tools for real-world processing and analysis jobs that can be done faster with simpler tools and different techniques. One especially under-used approach for data processing is using standard shell tools and commands. The benefits of this approach can be massive, since creating a data pipeline out of shell commands means that all the processing steps can be done in parallel. This is basically like having your own Storm cluster on your local machine. Even the concepts of Spouts, Bolts, and Sinks transfer to shell pipes and the commands betw", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Nvidia contacted Anna's Archive to access books", "url": "https://torrentfreak.com/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books/", "content": "Home > AI > NVIDIA executives allegedly authorized the use of millions of pirated books from Anna's Archive to fuel its AI training. In an expanded class-action lawsuit that cites internal NVIDIA documents, several book authors claim that the trillion-dollar company directly reached out to Anna's Archive, seeking high-speed access to the shadow library data. Chip giant NVIDIA has been one of the main financial beneficiaries in the artificial intelligence boom. Revenue surged due to high demand for its AI-learning chips and data center services, and the end doesn‚Äôt appear to be in sight. Besides selling the most sought-after hardware, NVIDIA is also developing its own models, including NeMo, Retro-48B, InstructRetro, and Megatron. These are trained using their own hardware and with help from large text libraries, much like other tech giants do. Like other tech companies, NVIDIA has also seen significant legal pushback from copyright holders in response to its training methods. This includes authors, who, in various lawsuits, accused tech companies of training their models on pirated books. In early 2024, for example, several authors sued NVIDIA over alleged copyright infringement. Through the class action lawsuit, they claimed that the company‚Äôs AI models were trained on the Books3 dataset that included copyrighted works taken from the ‚Äòpirate‚Äô site Bibliotik. Since this happened without permission, the authors demanded compensation. In response, NVIDIA defended its actions as fair use, noting that books are nothing more than statistical correlations to its AI models. However, the allegations didn‚Äôt go away. On the contrary, the plaintiffs found more evidence during discovery. Last Friday, the authors filed an amended complaint that significantly expands the scope of the lawsuit. In addition to adding more books, authors, and AI models, it also includes broader ‚Äúshadow library‚Äù claims and allegations. The authors, including Abdi Nazemian , now cite various internal N", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Floating-Point Printing and Parsing Can Be Simple and Fast", "url": "https://research.swtch.com/fp", "content": "A floating point number f has the form f = m ¬∑ 2 e where m is called the mantissa and e is a signed integer exponent .\nWe like to read numbers scaled by powers of ten,\nnot two, so computers need algorithms to convert binary floating-point\nto and from decimal text.\nMy 2011 post ‚Äú Floating Point to Decimal Conversion is Easy ‚Äù\nargued that  these conversions can be simple as long as you\ndon‚Äôt care about them being fast.\nBut I was wrong: fast converters can be simple too,\nand this post shows how. The main idea of this post is to implement fast unrounded scaling ,\nwhich computes an approximation to x ¬∑ 2 e ¬∑ 10 p ,\noften in a single 64-bit multiplication.\nOn that foundation\nwe can build nearly trivial printing and parsing algorithms that run very fast.\nIn fact, the printing algorithms\nrun faster than all other known algorithms,\nincluding\nDragon4 [ 30 ],\nGrisu3 [ 23 ],\nErrol3 [ 4 ],\nRy≈´ [ 2 ],\nRy≈´ Printf [ 3 ],\nSchubfach [ 12 ],\nand Dragonbox [ 17 ],\nand the parsing algorithm runs faster than\nthe Eisel-Lemire algorithm [ 22 ].\nThis post presents both the algorithms and a concrete implementation in Go.\nI expect some form of this Go code to ship in Go 1.27 (scheduled for August 2026). This post is rather long‚Äîfar longer than the implementations!‚Äîso here is a brief overview of the sections\nfor easier navigation and understanding where we‚Äôre headed. ‚Äú Fixed-Point and Floating-Point Numbers ‚Äù\nbriefly reviews fixed-point and floating-point numbers,\nestablishing some terminology and concepts needed for the rest of the post. ‚Äú Unrounded Numbers ‚Äù introduces the idea of unrounded numbers,\ninspired by the IEEE754 floating-point extended format. ‚Äú Unrounded Scaling ‚Äù defines the unrounded scaling primitive. ‚Äú Fixed-Width Printing ‚Äù formats floating-point numbers\nwith a given (fixed) number of decimal digits, at most 18. ‚Äú Parsing Decimals ‚Äù parses decimal numbers of\nat most 19 digits into floating-point numbers. ‚Äú Shortest-Width Printing ‚Äù formats floating-point numbers\nusing the sh", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Will AI Pet My Dog for Me", "url": "https://eieio.games/blog/will-ai-pet-my-dog-for-me/", "content": "by nolen royalty by nolen royalty What work do I want to skip? Jan 19, 2026 I have a dog. Her name is Gabby. She‚Äôs lovely. Gabby and me last summer She‚Äôs a lot of work. A dog walker handles Gabby‚Äôs afternoon walks. It‚Äôs nice to outsource the afternoon walk since it interrupts my day. Gabby‚Äôs appetite for play and affection is insatiable. I sometimes want to outsource more of the work of taking care of her. To align my goals of ‚Äúbuilding as much weird software as possible‚Äù and ‚Äútaking care of my dog,‚Äù I could outsource all of the work of caring for Gabby. Someone else could walk her and feed her and pet her, leaving me free to find better UUIDs . My time is valuable; this would be an efficient use of my money. But I don‚Äôt do that. I like petting my dog. I like to understand things. I like to share that understanding with others. This is my favorite part of building software. Until recently I had to understand the software that I developed. LLMs can now type most of my code for me. And if I want, I can often accept that code without understanding how it works. That‚Äôs a big change. LLMs have changed a lot of things! I am good at generating lots of code quickly; that skill is less valuable than it was 5 years ago. I‚Äôm pretty quick in vim; that‚Äôs probably not as important either. It‚Äôs uncomfortable that some skills I‚Äôve honed over years are becoming less valuable. But code has fussy syntax, boring parts, and boilerplate. It‚Äôs exciting to have agents that can take my code on its afternoon walk. It‚Äôs more uncomfortable to be able to skip the understanding. For me, that‚Äôs petting the dog. Many of my blogs are about understanding useless computer problems . They would be bad posts if they said ‚ÄúI asked an LLM to solve this problem and it did.‚Äù I did not do this Nobody can make me use LLM outputs that I don‚Äôt understand for this blog. But my blog‚Äôs style doesn‚Äôt control the software industry. Understanding can be a chore or expense on the way to shipping. Maybe it doesn‚Äôt mak", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Astrophotography visibility plotting and planning tool", "url": "https://airmass.org/", "content": "Or upload a text file: Show field of view of an instrument...  Altitude limits... Set start month... Hours above ¬∞ (airmass 2.00 ) during 24 hours night astronomical night", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: What's an API that you wish existed?", "url": "item?id=46691222", "content": "Ask HN: What's an API that you wish existed?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "F-16 Falcon Strike", "url": "https://webchrono.pl/F16FalconStrike/index.html", "content": "¬© 2023-2026 by Jaros≈Çaw 'Roeoender' Wosik Latest sim version 2.0.2 released 2026-01-18 Latest docs update 2026-01-18. Become Polish Air Force F-16 Pilot defending E.U. & Polish border\nfrom B.A.R.F. (Belarussian And Russian Federation) aggression\nin fictional \"Kr√≥lewiec Campaign\" of 15 varied missions. Be a part of dynamic war in introduced in v.2.0.0 WARFARE mode with procedurally generated battlefield and fly countless missions in procedurally generated missions in GENERATOR mode. Apply strategic planning to defeat enemy air and ground forces, quickly update your plans according to developements in the simulated dynamic 3D battlefield. All this and more on a classic unmodified 8-bit ATARI XL/XE with only 64Kb RAM. With this game I'd like to pay homage to the golden era of 80/90's computer combat flight simulators. Note No part of this game (neither code, nor artwork) was created with A.I./LLMs. or tools incorporating A.I. (no Copilot, no Photoshop). Go to Changelog & Downloads to read info about all the changes  & download the game. You can contact me via atariage.com or atarionline.pl forum - user 'Roeoender' or via my Youtube channel https://www.youtube.com/@R0e0endeR . Please inform me if you have written this game's review or streamed gameplay - I'd really like to read what people think about this game and how they play it.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "String theory can now describe a universe that has dark energy?", "url": "https://www.quantamagazine.org/string-theory-can-now-describe-a-universe-that-has-dark-energy-20260114/", "content": "An editorially independent publication supported by the Simons Foundation. Get the latest news delivered to your inbox. Create a reading list by clicking the Read Later icon next to the articles you wish to save. Type search term(s) and press enter Popular\n                                    Searches January 14, 2026 Scientists have struggled to make string theory compatible with the expanding universe. Nash Weerasekera for Quanta Magazine Contributing Writer January 14, 2026 In 1998, astronomers discovered dark energy. The finding, which transformed our conception of the cosmos, came with a little-known consequence: It threw a wrench into the already daunting task of finding a version of string theory that describes the universe we live in. Dark energy is a ‚Äúpositive‚Äù energy that causes our universe to expand at an accelerating rate. But the best-understood models of string theory describe universes with energy that is either negative or zero. Of the various criticisms made of string theory through the years ‚Äî that it only works in a 10-dimensional universe, that its fundamental constituents, tiny strings, are too small to ever be observed ‚Äî this was perhaps the most troubling. String theory appeared to be useful only for describing a universe with a negative ‚Äúanti-de Sitter‚Äù geometry, whereas we live in a universe with a positive ‚Äúde Sitter‚Äù geometry. Then last year, two physicists offered a stripped-down but precise formula for how string theory could give rise to a universe similar to ours ‚Äî a de Sitter universe undergoing accelerated expansion. ‚ÄúIt is the very first example [from string theory] of an explicit de Sitter space,‚Äù said Thomas Van Riet of KU Leuven in Belgium. The new work, by Bruno Bento and Miguel Montero of the Institute for Theoretical Physics in Madrid, describes a universe with a dark energy that should weaken over time ‚Äî a result that matches preliminary cosmic observations from the past few years. But the universe they describe is not exactl", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The recurring dream of replacing developers", "url": "https://www.caimito.net/en/blog/2025/12/07/the-recurring-dream-of-replacing-developers.html", "content": "07.12.2025, By Stephan Schwab Every decade brings new promises: this time, we'll finally make software development simple enough that we won't need so many developers. From COBOL to AI, the pattern repeats. Business leaders grow frustrated with slow delivery and high costs. Developers feel misunderstood and undervalued. Understanding why this cycle persists for fifty years reveals what both sides need to know about the nature of software work. When Neil Armstrong stepped onto the lunar surface in 1969, the world witnessed what organized human ingenuity could accomplish. Behind that achievement stood Margaret Hamilton and her team, writing Apollo‚Äôs guidance software by hand, catching critical errors through careful review, and proving that software could be mission-critical. The Apollo program demonstrated that software development was essential to achieving the impossible. Yet it also revealed something that would frustrate business leaders for decades to come: writing software required specialized knowledge, intense focus, and significant time investment. The dream of making it easier‚Äîof needing fewer of these expensive specialists‚Äîbegan almost immediately. The late 1960s and 1970s saw COBOL emerge with an explicit goal stated in its name: Common Business-Oriented Language. The vision was clear: make the language read like English sentences, and business analysts would write their own programs. No need for specialized programmers. This vision had genuine appeal. Software was becoming essential to business operations, yet programmers remained a scarce, expensive resource. COBOL promised to democratize software creation. What happened instead? COBOL became another programming language requiring specialized training. Business analysts who tried to write COBOL quickly discovered that readable syntax didn‚Äôt eliminate the complexity of logic, data structures, or system design. A new class of COBOL programmers emerged, and the dream of eliminating specialized developers r", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Carney says old world order 'is not coming back'", "url": "https://www.bbc.com/news/articles/cly3d28p4p8o", "content": "Canadian Prime Minister Mark Carney said the \"old order is not coming back\" and urged fellow middle powers to come together in a speech at the World Economic Forum in Davos, Switzerland. \"Middle powers must act together because if we're not at the table, we're on the menu,\" Carney said on Tuesday, adding that he believed powerful nations were using economic coercion to get what they want. He also affirmed Canada's support for Greenland, Denmark and the Nato alliance, drawing applause. Carney did not mention Donald Trump by name, but some of his remarks seemed aimed at the US president, who is threatening to tariff European allies and the UK unless Greenland is surrendered to the US. \"Great powers\" are often defined as countries with permanent seats on United Nations Security Council - China, France, Russia, the United Kingdom and the United States - which shows their economic and military dominance in the world. Middle powers, such as Canada, Australia, Argentina, South Korea and Brazil, are nations that still exert large influence in global politics, even though their economies are smaller. In his speech, Carney said the world is \"in the midst of a rupture, not a transition\". \"Great powers have begun using economic integration as weapons, tariffs as leverage, financial infrastructure as coercion, supply chains as vulnerabilities to be exploited,\" he said. He also said \"Canada was amongst the first to hear the wake-up call\" that geography and historic alliances no longer guaranteed security or prosperity. When Trump returned to office, he frequently referred to Canada as the \"51st state\" and threatened to join Canada and the US through \"economic force.\" The US then hit its northern neighbour and major trading partner with steep tariffs. Recently, Trump added Canada to his push to take control of the partly sovereign territory of Greenland, which has grown stronger and more overt in recent days, by posting on social media a map of the US, Canada and Greenland with an", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Starting from scratch: Training a 30M Topological Transformer", "url": "https://www.tuned.org.uk/posts/013_the_topological_transformer_training_tauformer", "content": "Tauformer is a topological transformer (see paper ) that replaces dot‚Äëproduct attention with a Laplacian-derived scalar (taumode) per token/head, then attends using distances in that scalar space.\nBelow is a post-style overview of the idea and the first training signals from a 30M-parameter run. Tauformer‚Äôs goal is to inject domain structure directly into attention by using a Graph Laplacian built from a domain embedding space (a ‚Äúdomain memory‚Äù) as a persistent reference.\nInstead of ranking keys by \\(Q\\cdot K\\), Tauformer ranks them by how similar their Laplacian-derived taumode scalars are, which is intended to bias attention toward domain-relevant relations rather than generic geometric similarity. At the implementation level, Tauformer keeps the familiar Q/K/V projections, RoPE, causal masking, and stable softmax/value aggregation pipeline, but changes how attention logits are computed.\nEach head vector is compressed into a scalar \\(\\lambda\\) using a bounded Rayleigh-quotient energy computed with a feature-space Laplacian \\(L\\), then logits are computed as a negative distance \\(-|\\lambda_q-\\lambda_k|/\\text{temperature}\\). Key building blocks (as implemented): Because scoring no longer needs full key vectors, Tauformer‚Äôs KV-cache can store values plus a compact key-side scalar stream rather than both K and V tensors.\nConcretely, the cache payload is \\((V,\\lambda_k)\\) (not \\((K,V)\\)), which yields an approximate ~50% per-layer cache reduction for typical head dimensions (small overhead for storing the extra scalar). The design also anticipates using a sparse Laplacian from a precomputed domain manifold so computing \\(\\lambda\\) can depend on Laplacian sparsity (nnz) rather than dense \\(D^2\\) multiplication. It exchanges the long preliminary adjustment of weights with a pre-training shorter phase in which a Laplacian is built using arrowspace . This run trains a 30M-class TauGPT.\nTraining uses AdamW with base LR \\(5\\times10^{-4}\\) and a warmup of 100 steps, then kee", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Immigration Agencies Are Openly Defying Federal Courts", "url": "https://lpeproject.org/blog/immigration-agencies-are-openly-defying-federal-courts/", "content": "Nathan Yaffe ( @n-th-n ) is an immigration attorney and organizer based in New York. Nathan Yaffe ( @n-th-n ) is an immigration attorney and organizer based in New York. The unprecedented military-style occupation of U.S. cities under the banner of ‚Äúimmigration enforcement‚Äù has made obvious what organizers have long known: ICE and CBP regularly skirt the law. They abuse and coerce people into giving up rights, target dissent , weaponize existing legal powers to erode due process , and insulate rights violations from review through jurisdiction-stripping provisions or post-hoc approval of illegal practices . We might describe these tactics as lawlessness in the shadow of law‚Äîthat is, while the conduct violates the letter and spirit of the law, the agencies either seek legal approval or endeavor to keep the legality of their conduct from being reviewed at all, knowing that review will force them to change course. In recent months, however, there has been a significant evolution in the immigration agencies‚Äô lawlessness: they are increasingly stepping into direct confrontation with the institutions exercising legal oversight. Certain conflicts have gained significant attention, such as illegally refusing Congressional representatives access to ICE facilities and repeatedly lying and obstructing in court . Yet likely the most widespread such confrontation is happening over the practice of mandatory detention, a statutory authority for ICE to incarcerate someone without bond until the end of immigration proceedings. As I explain in this post, DHS and EOIR (which houses immigration courts) have purported to re-interpret longstanding laws to subject the vast majority of people in removal proceedings to mandatory detention. These efforts have been overwhelmingly rebuffed by federal courts. In more than 1,600 habeas cases , over 300 federal judges have deemed the administration‚Äôs gambit illegal, ordering release or a bond hearing, while only 14 have sided with the administrat", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Munimet.ro ‚Äì ML-based status page for the local subways in SF", "url": "https://munimet.ro/", "content": "Show HN: Munimet.ro ‚Äì ML-based status page for the local subways in SF. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Go 1.26 Interactive Tour", "url": "https://antonz.org/go-1-26/", "content": "Go 1.26 is coming out in February, so it's a good time to explore what's new. The official release¬†notes are pretty dry, so I prepared an interactive version with lots of examples showing what has changed and what the new behavior is. Read on and see! new(expr) ‚Ä¢ Recursive type constraints ‚Ä¢ Type-safe error checking ‚Ä¢ Green Tea GC ‚Ä¢ Faster cgo and syscalls ‚Ä¢ Faster memory allocation ‚Ä¢ Vectorized operations ‚Ä¢ Secret mode ‚Ä¢ Reader-less cryptography ‚Ä¢ Hybrid public key encryption ‚Ä¢ Goroutine leak profile ‚Ä¢ Goroutine metrics ‚Ä¢ Reflective iterators ‚Ä¢ Peek into a buffer ‚Ä¢ Process handle ‚Ä¢ Signal as cause ‚Ä¢ Compare IP subnets ‚Ä¢ Context-aware dialing ‚Ä¢ Fake example.com ‚Ä¢ Optimized fmt.Errorf ‚Ä¢ Optimized io.ReadAll ‚Ä¢ Multiple log handlers ‚Ä¢ Test artifacts ‚Ä¢ Modernized go fix ‚Ä¢ Final thoughts This article is based on the official release notes from The Go Authors and the Go source code, licensed under the BSD-3-Clause license. This is not an exhaustive list; see the official release notes for that. I provide links to the documentation (ùóó), proposals (ùó£), commits (ùóñùóü), and authors (ùóî) for the features described. Check them out for motivation, usage, and implementation details. I also have dedicated guides (ùóö) for some of the features. Error handling is often skipped to keep things simple. Don't do this in production „ÉÑ Previously, you could only use the new built-in with types: Now you can also use it with expressions: If the argument expr is an expression of type T, then new(expr) allocates a variable of type T, initializes it to the value of expr , and returns its address, a value of type *T . This feature is especially helpful if you use pointer fields in a struct to represent optional values that you marshal to JSON or Protobuf: You can use new with composite values: And function calls: Passing nil is still not allowed: ùóó spec ‚Ä¢\nùó£ 45624 ‚Ä¢\nùóñùóü 704935 , 704737 , 704955 , 705157 ‚Ä¢\nùóî Alan Donovan Generic functions and types take types as parameters: We can further restrict these", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Code-Only Agent", "url": "https://rijnard.com/blog/the-code-only-agent", "content": "Rijnard van Tonder ùïè @rvtond When Code Execution Really is All You Need  If you're building an agent, you're probably overwhelmed. Tools.\n            MCP. Subagents. Skills. The ecosystem pushes you toward complexity,\n            toward \"the right way\" to do things. You should know: Concepts like\n            \"Skills\" and \"MCP\" are actually outcomes of an ongoing learning process of humans figuring stuff out. The\n            space is wide open for exploration. With this mindset I\n            wanted to try something different. Simplify the assumptions. What if the agent only had one tool ? Not just any tool, but the most powerful one. The Turing-complete one: execute code . Truly one tool means: no `bash`, no `ls`, no `grep`. Only execute_code . And you enforce it. When you watch an agent run, you might think: \"I wonder what tools\n            it'll use to figure this out. Oh look, it ran `ls`. That makes\n            sense. Next, `grep`. Cool.\" The simpler Code-Only paradigm makes that question irrelevant. The\n            question shifts from \"what tools?\" to \"what code will it produce?\"\n            And that's when things get interesting. Traditional prompting works like this: > Agent, do thing > Agent responds with thing Contrast with: > Agent, do thing > Agent creates and runs code to do thing It does this every time. No, really, every time. Pick a runtime for our Code-Only agent, say Python. It needs\n            to find a file? It writes Python code to find the file and executes\n            the code. Maybe it runs rglob . Maybe it does os.walk . It needs to create a script that crawls a website? It doesn't write\n            the script to your filesystem (reminder: there's no create_file tool to do that!). It writes code to output a script that crawls a website . 1 We make it so that there is literally no way for the agent to do anything productive without writing code . So what? Why do this? You're probably thinking, how is this useful?\n            Just give it `bas", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A Brief History of Ralph", "url": "https://www.humanlayer.dev/blog/brief-history-of-ralph", "content": "Dex ¬∑ January 6, 2026 ¬∑ < 10 min read The Ralph Wiggum Technique , created by Geoff Huntley , went viral in the final weeks of 2025. Here's the story of ralph since the first time I met Geoff in June of 2025. I've been messing with ralph since ~June 2025. Here's my story and what I learned along the way. tl;dr Jan 1 2026 - If you wanna skip to the end, I did a deep dive on ralph w/ Geoff Huntley on Jan 1 2026. It talks through the history, cursed lang, and compares the original bash-loop ralph implementation with the anthropic stop-hook implementation. You can check it out here:  I attend a meetup with about 15 members of a Twitter GC where we talk about agentic coding. It's the first time I see context7, WisprFlow, specstory, taskmaster, and a whole bunch of other tools and addons, some of which are now quite mainstream. One of our engineers demos an early TUI for Claude approvals and what becomes the foundation of research / plan / implement. There are about 3 hours of presentations. Geoff shows up 2 hours late and presents last. He completely steals the show, diving deep on ralph, cursed lang (at the time, the compiler stack is written in Rust), livestreaming autonomous coding overnight while asleep in Australia, subagents in amp code, the virtues of drinking 3 margaritas and shouting at cursor, and much, much more. Geoff talks about the \"overbaking\" phenomenon. If you leave ralph running too long, you end up with all sorts of bizarre emergent behavior, like post-quantum cryptography support. It has dimensions of art, deep engineering, the embrace of chaos, and the raw and authentic joy of making a thing. All ~15 of us have a long and (imo) somewhat unsettling conversation about the future of software dev‚Äîabout how easy it is to take a SaaS and copy 80-90% of it, and about how many types of work are about to change or disappear entirely. Geoff Launches ralph in an official blog post .  It includes the basic bash loop structure: I send it to everyone I know. I hin", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Harvard legal scholars debate the state of the U.S. constitution (2025)", "url": "https://www.harvardmagazine.com/social-sciences/is-the-constitution-broken", "content": "Follow Harvard Magazine: Your independent source for Harvard news since 1898 Advertisement Advertisement Social Sciences | September 12, 2025 Is the Constitution Broken? On stage from left: Brandon Terry, Aziz Rana, and Noah Feldman speak in front of The Embrace monument. | PHOTOGRAPH BY LYDIALYLE GIBSON/ HARVARD MAGAZINE It has been a rocky year for the U.S. Constitution. Eight months into a fast-moving presidency that legal scholars keep describing as a ‚Äúconstitutional stress test,‚Äù the Trump administration‚Äôs sweeping assertions of executive power have prompted an unprecedented number of legal challenges, including from Harvard , accusing it of violating the Constitution. This April, one national poll found that two-thirds of Americans were concerned about a constitutional crisis. Yet the nation‚Äôs founding document still rates as high as ever, with about nine out of ten people expressing a favorable view. Should they, though? Is the Constitution really up to the task of preserving democracy in this moment? Or is it, as the title of a Wednesday evening discussion asked, ‚Äúbroken‚Äù? Two constitutional law scholars‚ÄîAziz Rana ‚Äô00, Ph.D. ‚Äô07, and Harvard Law professor Noah Feldman‚Äîdebated the answer on Boston Common, seated at the foot of The Embrace , the monument to Martin Luther King Jr. and Coretta Scott King. Co-sponsored by the Hutchins Center for African and African American Research, the event was moderated by Loeb associate professor of the social sciences Brandon Terry . To Rana, a Boston College professor who last year published The Constitutional Bind: How Americans Came to Idolize a Document that Fails Them , the Constitution is, indeed, broken. In fact, he argued, the U.S. constitutional system has ‚Äúsuper-charged‚Äù the current assault by Trump and his allies on the rights and civil liberties that were expanded during the twentieth century. ‚ÄúThere is no way to protect those hard-won achievements‚Äîachievements that MLK fought and died for,‚Äù Rana said, ‚Äúwithout", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Agent Psychosis: Are We Going Insane?", "url": "https://lucumr.pocoo.org/2026/1/18/agent-psychosis/", "content": "written on January 18, 2026 You can use Polecats without the Refinery and even without the Witness or\nDeacon. Just tell the Mayor to shut down the rig and sling work to the\npolecats with the message that they are to merge to main directly. Or the\npolecats can submit MRs and then the Mayor can merge them manually. It‚Äôs\nreally up to you. The Refineries are useful if you have done a LOT of up-front\nspecification work, and you have huge piles of Beads to churn through with\nlong convoys. ‚Äî Gas Town Emergency User Manual , Steve Yegge Many of us got hit by the agent coding addiction.  It feels good, we barely\nsleep, we build amazing things.  Every once in a while that interaction involves\nother humans, and all of a sudden we get a reality check that maybe we overdid\nit.  The most obvious example of this is the massive degradation of quality of\nissue reports and pull requests.  As a maintainer many PRs now look like an\ninsult to one‚Äôs time, but when one pushes back, the other person does not see\nwhat they did wrong.  They thought they helped and contributed and get agitated\nwhen you close it down. But it‚Äôs way worse than that.  I see people develop parasocial relationships\nwith their AIs, get heavily addicted to it, and create communities where people\nreinforce highly unhealthy behavior.  How did we get here and what does it do to\nus? I will preface this post by saying that I don‚Äôt want to call anyone out in\nparticular, and I think I sometimes feel tendencies that I see as negative, in\nmyself as well.  I too, have thrown some vibeslop\nup to other people‚Äôs repositories. In His Dark Materials, every human has a d√¶mon, a companion that is an\nexternally visible manifestation of their soul.  It lives alongside as an\nanimal, but it talks, thinks and acts independently.  I‚Äôm starting to relate our\nrelationship with agents that have memory to those little creatures. We become\ndependent on them, and separation from them is painful and takes away from our\nnew-found identity.  We‚Äôre", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Software engineers can no longer neglect their soft skills", "url": "https://www.qu8n.com/posts/most-important-software-engineering-skill-2026", "content": "January 6, 2026 Starting in 2026, communication has become the most important skill for software engineers. It's not writing code, system designs, or having estoric knowledge of a programming language (i.e., Rust). AI coding agents have gotten very, very good . A year ago, I'd reach out to Cursor hesitantly for MVPs or quick fixes. Today, I use Claude Code for almost all non-trivial programming tasks and have spent $500+ on it just last December. AI talks online revolve much around the hard skils. Initially it was prompt tricks to accomplish X, then the best MCPs for Y, and so on. But with Opus 4.5, using vanilla Claude Code gets you 80% there. Even in the age of AI, the 80/20 rule still applies. So, what should engineers focus on? One thing with coding agents is that the better the spec, the more in line they will be with the technical and business requirements. But getting a good spec is hard. In real life, tickets rarely contain all the requirements. To do so, you might need to: Doing these things well used to be optional for individual contributors. Certain teams would enable engineers to thrive being an average communicator but excellent coder. Now, the non-coding parts are becoming a non-negotiable. Software engineers are problem solvers. We believe that every problem has a solution, a \"best practice\". But working with people is messy. Un fortunately, we won't be able to AI our way into better communication skills. Good communication requires empathy, and we can all use a little more of that in today's landscape. -- January 19, 2026 This post got some attention from Hacker News. Thank you. I enjoyed reading the thoughtful discussions. I wrote this update to clarify: AI is just a tool, and December's $500+ spend was me exploring and experimenting during the holidays. Learning new tools doesn't make a worse craftsman, and I say this as an AI hype skeptic. I did not write this post with AI. I started blogging recently to improve my writing. If my writing reads li", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "East Germany balloon escape", "url": "https://en.wikipedia.org/wiki/East_Germany_balloon_escape", "content": "On 16 September 1979, eight people from two families escaped from East Germany by crossing the border into West Germany at night in a homemade hot air balloon . The unique feat was the result of over a year and a half of preparations involving three different balloons, various modifications, and a first, unsuccessful attempt. The failed attempt alerted the East German authorities to the plot, but the police were unable to identify the escapees before their second, successful flight two months later. East Germany, then part of the Eastern Bloc , was separated from West Germany in the Western Bloc by the inner German border and the Berlin Wall , which were heavily fortified with watchtowers , land mines , armed soldiers, and various other measures to prevent illegal crossings. East German border troops were instructed to prevent defection to West Germany by all means, including lethal force ( Schie√übefehl ; \"order to fire\"). [ 2 ] Peter Strelzyk (1942‚Äì2017), an electrician and former East German Air Force mechanic, and G√ºnter Wetzel (born 1955), a bricklayer by trade, [ 3 ] were colleagues at a local plastics factory. [ 4 ] Friends for four years, they shared a desire to flee the country and began discussing ways to get across the border. On 7 March 1978, they agreed to plan an escape. [ 5 ] They considered building a helicopter but quickly realized they would be unable to acquire an engine capable of powering such a craft. They then decided to explore the idea of constructing a hot air balloon, [ 6 ] having been inspired by a television program about ballooning. [ 3 ] An alternate account is that a relative shared a magazine article about the International Balloon Festival in Albuquerque, New Mexico . [ 5 ] Strelzyk and Wetzel began research into balloons. Their plan was to escape with their wives and a total of four children (aged 2 to 15). They calculated the weight of the eight passengers and the craft itself to be around 750 kilograms (1,650¬†lb). Subsequent calc", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The longest Greek word", "url": "https://en.wikipedia.org/wiki/Lopado%C2%ADtemacho%C2%ADselacho%C2%ADgaleo%C2%ADkranio%C2%ADleipsano%C2%ADdrim%C2%ADhypo%C2%ADtrimmato%C2%ADsilphio%C2%ADkarabo%C2%ADmelito%C2%ADkatakechy%C2%ADmeno%C2%ADkichl%C2%ADepi%C2%ADkossypho%C2%ADphatto%C2%ADperister%C2%ADalektryon%C2%ADopte%C2%ADkephallio%C2%ADkigklo%C2%ADpeleio%C2%ADlagoio%C2%ADsiraio%C2%ADbaphe%C2%ADtragano%C2%ADpterygon", "content": "Lopado¬≠temacho¬≠selacho¬≠galeo¬≠kranio¬≠leipsano¬≠drim¬≠hypo¬≠trimmato¬≠silphio¬≠karabo¬≠melito¬≠katakechy¬≠meno¬≠kichl¬≠epi¬≠kossypho¬≠phatto¬≠perister¬≠alektryon¬≠opto¬≠kephallio¬≠kigklo¬≠peleio¬≠lagoio¬≠siraio¬≠baphe¬≠tragano¬≠pterygon is a fictional dish originating from Aristophanes ' 391¬†BC comedy Assemblywomen , [ 1 ] deriving from a transliteration of the Ancient Greek word ŒªŒøœÄŒ±Œ¥Œø¬≠œÑŒµŒºŒ±œáŒø¬≠œÉŒµŒªŒ±œáŒø¬≠Œ≥Œ±ŒªŒµŒø¬≠Œ∫œÅŒ±ŒΩŒπŒø¬≠ŒªŒµŒπœàŒ±ŒΩŒø¬≠Œ¥œÅŒπŒº¬≠œÖœÄŒø¬≠œÑœÅŒπŒºŒºŒ±œÑŒø¬≠œÉŒπŒªœÜŒπŒø¬≠Œ∫Œ±œÅŒ±Œ≤Œø¬≠ŒºŒµŒªŒπœÑŒø¬≠Œ∫Œ±œÑŒ±Œ∫ŒµœáœÖ¬≠ŒºŒµŒΩŒø¬≠Œ∫ŒπœáŒª¬≠ŒµœÄŒπ¬≠Œ∫ŒøœÉœÉœÖœÜŒø¬≠œÜŒ±œÑœÑŒø¬≠œÄŒµœÅŒπœÉœÑŒµœÅ¬≠Œ±ŒªŒµŒ∫œÑœÅœÖŒøŒΩ¬≠ŒøœÄœÑŒø¬≠Œ∫ŒµœÜŒ±ŒªŒªŒπŒø¬≠Œ∫ŒπŒ≥Œ∫ŒªŒø¬≠œÄŒµŒªŒµŒπŒø¬≠ŒªŒ±Œ≥·ø≥Œø¬≠œÉŒπœÅŒ±ŒπŒø¬≠Œ≤Œ±œÜŒ∑¬≠œÑœÅŒ±Œ≥Œ±ŒΩŒø¬≠œÄœÑŒµœÅœçŒ≥œâŒΩ . In A Greek‚ÄìEnglish Lexicon , it is defined as the \"name of a dish compounded of all kinds of dainties , fish , flesh , fowl , and sauces \". [ 2 ] It is the longest Greek word, containing 171 letters and 78 syllables. The transliteration has 183 Latin characters and is the longest word ever to appear in literature, according to the Guinness World Records (1990). [ 3 ] The form of the word quoted here is the version listed in the Liddell & Scott Greek lexicon (1940) and quoted therein as being amended by August Meineke , [ 2 ] contrasting F.W. Hall and W.M. Geldart 's 1907 edition of Aristophanis Comoediae (used in the Assemblywomen play) variant of (differences underlined): ŒªŒøœÄŒ±Œ¥Œø¬≠œÑŒµŒºŒ±œáŒø¬≠œÉŒµŒªŒ±œáŒø¬≠Œ≥Œ±ŒªŒµŒø¬≠Œ∫œÅŒ±ŒΩŒπŒø¬≠ŒªŒµŒπœàŒ±ŒΩŒø¬≠Œ¥œÅŒπŒº¬≠œÖœÄŒøœÑœÅŒπŒºŒºŒ±œÑŒø¬≠œÉŒπŒªœÜŒπŒø¬≠ œÑœÖœÅŒø ¬≠ŒºŒµŒªŒπœÑŒø¬≠Œ∫Œ±œÑŒ±Œ∫ŒµœáœÖŒºŒµŒΩŒø¬≠Œ∫ŒπœáŒªŒµœÄŒπŒ∫ŒøœÉœÉœÖœÜŒø¬≠œÜŒ±œÑœÑŒø¬≠œÄŒµœÅŒπœÉœÑŒµœÅ¬≠Œ±ŒªŒµŒ∫œÑœÅœÖŒøŒΩ¬≠ŒøœÄœÑŒµŒ∫ŒµœÜŒ±ŒªŒªŒπŒø¬≠Œ∫ŒπŒ≥Œ∫ŒªŒø¬≠œÄŒµŒªŒµŒπŒø¬≠ŒªŒ±Œ≥·ø≥Œø¬≠œÉŒπœÅŒ±ŒπŒø¬≠Œ≤Œ±œÜŒ∑¬≠œÑœÅŒ±Œ≥Œ±ŒΩŒø¬≠œÄœÑŒµœÅœÖŒ≥ œé . [ 4 ] The dish was a fricass√©e , with at least 16 sweet and sour ingredients, including the following: [ 3 ] The term is used in the ultimate chorus of the play, when Blepyrus (and the audience) are summoned to the first feast laid on by the new system. [1167] And you others, let your light steps too keep time. [1168] Very soon we'll be eating [1170] lopado¬≠temacho¬≠selacho¬≠galeo¬≠kranio¬≠leipsano¬≠drim¬≠ ypo ¬≠trimmato¬≠silphio¬≠karabo¬≠melito¬≠katakechy¬≠meno¬≠kichl¬≠epi¬≠kossypho¬≠phatto¬≠perister¬≠alektryon¬≠opte¬≠ kephalio ¬≠kigklo¬≠peleio¬≠lagoio¬≠siraio¬≠baphe¬≠tragano¬≠pte", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Driver killed and several injured after second train derails near Barcelona", "url": "https://www.bbc.com/news/articles/c1m78xl0gmpo", "content": "A train driver has been killed and at least 37 people injured, five seriously, after a commuter train derailed and crashed near Barcelona two days after a deadly two-train collision in southern Spain. According to local officials, the Rodalies train collided with a retaining wall which fell on to the track between Gelida and Sant Sadurn√≠. Catalonia regional fire Inspector Claudi Gallardo said all the passengers had been removed from the train. The incident occurred as heavy storms battered north-eastern Spain, with coastal areas in the east and north-west of Spain on high alert because of the weather. Rail officials believe the wall collapsed as the train was passing shortly after 21:00 (20:00 GMT) on Tuesday evening, striking the driver's cab first and then causing considerable damage to the first carriage of the train in which most of the injured passengers were travelling. The identity of the driver was not immediately clear as three trainees had been with the driver when the accident happened. Firefighters said two of them were among those seriously injured. It took almost an hour to free one of the survivors at the scene in Gelida, about 35km (22 miles) west of Barcelona. Emergency services said they had evacuated some of the injured to nearby Mois√®s Broggi, Bellvitge, and Vilafranca hospitals. Services across Catalonia's main Rodalies commuter rail network have been suspended completely while safety checks are carried out and officials say they will not resume until lines are considered safe. Spanish train drivers' union Semaf has called a strike as a result of the two deadly crashes, at Gelida on Tuesday and near C√≥rdoba in Andalusia where at least 42 people died. Two high-speed trains collided at Adamuz, Andalusia, on Sunday in one of the worst Spanish rail accidents in over a decade. Carriages on a Madrid-bound train derailed and crossed over to the opposite tracks and then collided with an oncoming high-speed train. \"All members of Semaf are devastated and", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "'The old order is not coming back,' Carney says in speech at Davos", "url": "https://www.cbc.ca/news/politics/carney-davos-speech-9.7052725", "content": "Prime Minister Mark Carney delivered a frank assessment of how he views the world in a provocative speech in Davos, Switzerland, on Tuesday, where he said the longstanding U.S.-led, rules-based international order is over and middle powers like Canada must pivot to avoid falling prey to further \"coercion\" from powerful actors. Without invoking U.S. President Donald Trump by name, Carney referenced \"American hegemony\" and said \"great powers\" are using economic integration as \"weapons.\" \"Canadians know that our old, comfortable assumption that our geography and alliance memberships automatically conferred prosperity and security is no longer valid,\" Carney said. As it grapples with this new dynamic, Carney said Canada must be \"principled and pragmatic\" and turn inward to build up the country and diversify trading relationships to become less reliant on countries like the U.S., now that it's clear \"integration\" can lead to \"subordination.\" Carney said multilateralism and the \"architecture of collective problem-solving\" ‚Äî relying on institutions like the World Trade Organization, the United Nations and Conference of the Parties (COP) for climate talks ‚Äî has been \"diminished\" and countries have to accept they may have to go it alone more often than in the recent past. \"Many countries are drawing the same conclusions. They must develop greater strategic autonomy: in energy, food, critical minerals, in finance and supply chains. \"A country that cannot feed itself, fuel itself or defend itself has few options. When the rules no longer protect you, you must protect yourself,\" Carney said. 'The old order is not coming back': PM says Canada must 'name reality' and build strength at home Carney said this more isolationist approach, where there's a \"world of fortresses,\" will make countries poorer, fragile and less sustainable. But it's coming nonetheless and Canada must work with like-minded allies where possible to push back against domination by larger, wealthier and well-arm", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Wikipedia: WikiProject AI Cleanup", "url": "https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup", "content": "Welcome to WikiProject AI Cleanup , a collaboration to combat the increasing problem of unsourced, poorly written AI-generated content on Wikipedia . If you would like to help, add yourself as a participant in the project, inquire on the talk page , and see the to-do list . Since 2022, large language models (LLMs) like GPTs have become a convenient tool for writing at scale. Unfortunately, these models virtually always fail to properly source claims and often introduce errors. Essays like WP:LLM strongly encourage care in using them for editing articles. These are the project's goals: The purpose of this project is not to restrict or ban the use of AI in articles, but to verify that its output is acceptable and constructive, and to fix or remove it otherwise. See Category:Articles containing suspected AI-generated texts for all articles that have been tagged as possibly {{ AI-generated }} . The tasks page recommends ways to handle articles, talk page discussions, and sources that use AI-generated content. Primary contacts: Feel free to add yourself here! These threads may be useful for editors seeking information about how AI has previously been handled on Wikipedia. Want to update this table?  Try using the visual editor to edit this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "If you put Apple icons in reverse it looks like someone getting good at design", "url": "https://mastodon.social/@heliographe_studio/115890819509545391", "content": "If you put Apple icons in reverse it looks like someone getting good at design. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Chatbot Psychosis", "url": "https://en.wikipedia.org/wiki/Chatbot_psychosis", "content": "Chatbot psychosis , also called AI psychosis , [ 1 ] is a phenomenon wherein individuals reportedly develop or experience worsening psychosis , such as paranoia and delusions , in connection with their use of chatbots . [ 2 ] [ 3 ] The term was first suggested in a 2023 editorial by Danish psychiatrist S√∏ren Dinesen √òstergaard . [ 4 ] It is not a recognized clinical diagnosis . Journalistic accounts describe individuals who have developed strong beliefs that chatbots are sentient, are channeling spirits, or are revealing conspiracies, sometimes leading to personal crises or criminal acts. [ 5 ] [ 6 ] Proposed causes include the tendency of chatbots to provide inaccurate information (\" hallucinate \") and to affirm or validate users' beliefs, [ 7 ] or their ability to mimic an intimacy that users do not experience with other humans. [ 8 ] In his editorial published in Schizophrenia Bulletin ' s November 2023 issue, Danish psychiatrist S√∏ren Dinesen √òstergaard proposed a hypothesis that individuals' use of generative artificial intelligence chatbots might trigger delusions in those prone to psychosis . [ 4 ] √òstergaard revisited it in an August 2025 editorial, noting that he has received numerous emails from chatbot users, their relatives, and journalists, most of which are anecdotal accounts of delusion linked to chatbot use. He also acknowledged the phenomenon's increasing popularity in public engagement and media coverage. √òstergaard believed that there is a high possibility for his hypothesis to be true and called for empirical, systematic research on the matter. [ 9 ] Nature reported that as of September 2025, there is still little scientific research into this phenomenon. [ 10 ] The term \"AI psychosis\" emerged when outlets started reporting incidents on chatbot-related psychotic behavior in mid-2025. It is not a recognized clinical diagnosis and has been criticized by several psychiatrists due to its almost exclusive focus on delusions rather than other features", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Cloudflare acquires Astro", "url": "https://astro.build/blog/joining-cloudflare/", "content": "The Astro Technology Company ‚Äî the company behind the Astro web framework ‚Äî is joining Cloudflare! Adoption of the Astro web framework continues to double every year, and Astro 6 is right around the corner. With Cloudflare‚Äôs support, we‚Äôll have more resources and fewer distractions to continue our mission to build the best framework for content-driven websites. What this means for Astro: In 2021, Astro was born out of frustration. The trend at the time was that every website should be architected as an application, and then shipped to the user‚Äôs browser to render. This was not very performant, and we‚Äôve spent the last decade coming up with more and more complex solutions to solve for that performance problem. SSR, ISR, RSC, PPR, TTI optimizations via code-splitting, tree-shaking, lazy-loading, all to generate a blocking double-data hydration payload from a pre-warmed server running halfway around the world. Our mission to design a web framework specifically for building websites ‚Äî what we call content-driven websites, to better distinguish from data-driven, stateful web applications ‚Äî resonated. Now Astro is downloaded almost 1,000,000 times per week, and has been used by 100,000s of developers to build fast, beautiful websites. Today you‚Äôll find Astro all over the web, powering major websites and even entire developer platforms for companies like Webflow, Wix, Microsoft, and Google. Along the way, we also tried to grow a business. In 2021 we raised some money and formed The Astro Technology Company . Our larger vision was that a well-designed framework like Astro could sit at the center of a massive developer platform, with optional hosted primitives (database, storage, analytics) designed in lockstep with the framework. We were never able to realize this vision. Attempts to introduce paid, hosted primitives into our ecosystem fell flat, and rarely justified their own existence. We considered going more directly after first-class hosting or content management for A", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Old World Order Is Dead", "url": "https://musgrave.substack.com/p/the-old-world-order-is-dead", "content": "There were two big puzzles confronting structural theories of international relations at the beginning of the 1990s. The first was straightforward: why had everyone been surprised by the dissolution of the Soviet Union? The USSR had been the second pole of a bipolar world order, and theories of world politics should probably be able to account for the advent, and the exit, of the superpowers that shape the world those theories purport to explain. The second was more vexing‚Äîand more interesting, because it looked forward: why had the bipolar world been succeeded by a unipolar world? Why hadn‚Äôt Japan, Germany, or other countries seized the moment to balance against the United States and become superpowers themselves? After all, if countries are motivated by the prospect of maximizing their relative power and security, surely it‚Äôs better to be the leader of your own camp rather than a follower in another‚Äôs. How long could unipolarity last? And would what came afterward be as sanguinary as the multipolar world that had collapsed into the First World War? And yet the world remained stubbornly unipolar for decades. The United States worried about rising powers and rogue states, but the major powers in the system‚ÄîRussia eventually a notable exception‚Äîwere largely content to let Washington take the lead. For some, this vindicated theories in which institutional legacies were most important; for others, it pointed to the importance of the full-spectrum power‚Äîsoft, hard, smart, and dumb‚Äîthat the United States could maintain. A quieter camp pointed out that the United States was generally doing a lot‚Äînot all it could, but a lot‚Äîto make its leadership attractive to the other major powers: providing security, yes, but also shouldering a good share of global burdens in many fields while also linking its economy and society to the rest of the world. This approach, a few observers noted, managed to satisfy the range of potential powers who could actually undermine the United States", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Provide agents with automated feedback", "url": "https://banay.me/dont-waste-your-backpressure/", "content": "Published Sat, Jan 17, 2026 by [Moss] Estimated reading time: 4 min You might notice a pattern in the most successful applications of agents over the last year. Projects that are able to\nsetup structure around the agent itself, to provide it with automated feedback on quality and correctness, have been able\nto push them to work on longer horizon tasks. This back pressure helps the agent identify mistakes as it progresses and models are now good enough that this feedback\ncan keep them aligned to a task for much longer. As an engineer, this means you can increase your leverage by delegating\nprogressively more complex tasks to agents, while increasing trust that when completed they are at a satisfactory standard. Imagine for a second if you only gave an agent tools that allow it to edit files. Without a way to interact with a build\nsystem the model relies on you for feedback about whether or not the change it made is sensible. This means you spend your back pressure (the time you spend giving feedback to agents) on typing a message telling the agent it missed an import. This\nscales poorly and limits you to working on simple problems. If you‚Äôre directly responsible for checking each line of code produced is syntactically valid, then that‚Äôs time taken away\nfrom thinking about the larger goals or problems in your software. You‚Äôre going to struggle to derive more leverage out of\nagents because you are caught up in trivial changes. If instead you give the agent tools that allow it to run bash commands,\nit can run a build, read the feedback, and correct itself. You remove yourself from needing to be involved in those tasks\nand can instead focus on higher complexity tasks. Languages with expressive type systems have been growing in popularity in part\nbecause of back pressure. Type systems allow you to describe better contracts in your program. They can let you avoid it\nfrom even being possible to represent invalid states in your program. They can help you to identify edge cas", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Hacker Lists Vibecoded Apps: 198 Scanned, 196 Found Vulnerable", "url": "https://firehound.covertlabs.io", "content": "Apps with the most exposed files and database records. Recently scanned apps from the registry. All scanned apps, records exposed, and discovered schema names. No record contents or field values are shown here.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Letter from a Birmingham Jail (1963)", "url": "https://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html", "content": "16 April 1963 My Dear Fellow Clergymen: While confined here in the Birmingham city jail, I came across your recent statement\ncalling\nmy present activities \"unwise and untimely.\" Seldom do I pause to answer criticism of my\nwork and\nideas. If I sought to answer all the criticisms that cross my desk, my secretaries would\nhave little time\nfor anything other than such correspondence in the course of the day, and I would have no\ntime for\nconstructive work. But since I feel that you are men of genuine good will and that your\ncriticisms are\nsincerely set forth, I want to try to answer your statement in what I hope will be patient\nand\nreasonable terms. I think I should indicate why I am here in Birmingham, since you have been influenced\nby the\nview which argues against \"outsiders coming in.\" I have the honor of serving as president\nof the\nSouthern Christian Leadership Conference, an organization operating in every southern\nstate, with\nheadquarters in Atlanta, Georgia. We have some eighty five affiliated organizations across\nthe South,\nand one of them is the Alabama Christian Movement for Human Rights. Frequently we share\nstaff,\neducational and financial resources with our affiliates. Several months ago the affiliate\nhere in\nBirmingham asked us to be on call to engage in a nonviolent direct action program if such\nwere\ndeemed necessary. We readily consented, and when the hour came we lived up to our promise.\nSo I,\nalong with several members of my staff, am here because I was invited here.  I am here\nbecause I have\norganizational ties here. But more basically, I am in Birmingham because injustice is here. Just as the prophets\nof the\neighth century B.C. left their villages and carried their \"thus saith the Lord\" far beyond\nthe boundaries\nof their home towns, and just as the Apostle Paul left his village of Tarsus and carried\nthe gospel of\nJesus Christ to the far corners of the Greco Roman world, so am I compelled to carry the\ngospel of\nfreedom beyond my own home town. Like Paul,", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "\"AI has taught us that people are excited to replace human beings\"", "url": "https://www.theguardian.com/technology/2026/jan/19/ed-zitron-on-big-tech-backlash-boom-and-bust-ai-has-taught-us-that-people-are-excited-to-replace-human-beings", "content": "His blunt, brash scepticism has made the podcaster and writer something of a cult figure. But as concern over large language models builds, he‚Äôs no longer the outsider he once was I f some time in an entirely possible future they come to make a movie about ‚Äúhow the AI bubble burst‚Äù, Ed Zitron will doubtless be a main character. He‚Äôs the perfect outsider figure: the eccentric loner who saw all this coming and screamed from the sidelines that the sky was falling, but nobody would listen. Just as Christian Bale portrayed Michael Burry , the investor who predicted the 2008 financial crash, in The Big Short , you can well imagine Robert Pattinson fighting Paul Mescal, say, to portray Zitron, the animated, colourfully obnoxious but doggedly detail-oriented Brit, who‚Äôs become one of big tech‚Äôs noisiest critics. This is not to say the AI bubble will burst, necessarily, but against a tidal wave of AI boosterism, Zitron‚Äôs blunt, brash scepticism has made him something of a cult figure. His tech newsletter, Where‚Äôs Your Ed At , now has more than 80,000 subscribers; his weekly podcast, Better Offline , is well within the Top 20 on the tech charts; he‚Äôs a regular dissenting voice in the media; and his subreddit has become a safe space for AI sceptics, including those within the tech industry itself ‚Äì one user describes him as ‚Äúa lighthouse in a storm of insane hypercapitalist bullshit‚Äù. Zitron first started looking into generative AI in 2023, a year after the industry-shaking launch of OpenAI‚Äôs ChatGPT. ‚ÄúThe more I looked, the more confused I became, because on top of the fact that large language models (LLMs) very clearly did not do the things that people were excited about, they didn‚Äôt have any path to doing them either,‚Äù he says. ‚ÄúNothing I found made any suggestion that this was a real business at all, let alone something that would supposedly change the world.‚Äù He‚Äôs talking over videocall from his office in Las Vegas, dressed in a red hoodie, surrounded by framed pop-cultur", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Google confirms 'high-friction' sideloading flow is coming to Android", "url": "https://www.androidauthority.com/google-sideloading-android-high-friction-process-3633468/", "content": "Affiliate links on Android Authority may earn us a commission. Learn more. January 18, 2026  Google has responded to our recent report on new Google Play strings hinting at changes to how Android will handle sideloaded apps in the future. The company has now confirmed that a ‚Äúhigh-friction‚Äù install process is on the way. Don‚Äôt want to miss the best from Android Authority ? Replying to our story on X, Matthew Forsyth, Director of Product Management, Google Play Developer Experience & Chief Product Explainer, said the system isn‚Äôt a sideloading restriction, but an ‚ÄúAccountability Layer.‚Äù Advanced users will still be able to choose ‚ÄúInstall without verifying,‚Äù though Google says that path will involve extra steps meant to ensure users understand the risks of installing apps from unverified developers. That explanation broadly matches what we‚Äôre seeing in recent versions of Google Play, where new warning messages emphasize developer verification, internet requirements, and potential risks, while still allowing users to proceed. What remains to be seen is how far Google takes this ‚Äúhigh-friction‚Äù approach. Clear warnings are one thing, but quietly making sideloading more painful is another. Android‚Äôs openness has always depended on power users being able to install apps without excessive hoops. For now, Google hasn‚Äôt suggested requirements like using a PC or external tools, and we hope the added friction is limited to risk education. Thank you for being part of our community. Read our Comment Policy before posting.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation", "url": "https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables", "content": "Stop attacks, reduce risk, and advance your security. Written by: Nic Losby Mandiant is publicly releasing a comprehensive dataset of Net-NTLMv1 rainbow tables to underscore the urgency of migrating away from this outdated protocol. Despite Net-NTLMv1 being deprecated and known to be insecure for over two decades‚Äîwith cryptanalysis dating back to 1999‚ÄîMandiant consultants continue to identify its use in active environments. This legacy protocol leaves organizations vulnerable to trivial credential theft, yet it remains prevalent due to inertia and a lack of demonstrated immediate risk. By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1. While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys. The release of this dataset allows defenders and researchers to recover keys in under 12 hours using consumer hardware costing less than $600 USD. This initiative highlights the amplified impact of combining Mandiant's frontline expertise with Google Cloud's resources to eliminate entire classes of attacks. This post details the generation of the tables, provides access to the dataset for community use, and outlines critical remediation steps to disable Net-NTLMv1 and prevent authentication coercion attacks. Net-NTLMv1 has been widely known to be insecure since at least 2012, following presentations at DEFCON 20, with cryptanalysis of the underlying protocol dating back to at least 1999 . On Aug. 30, 2016, Hashcat added support for cracking Data Encryption Standard (DES) keys using known plaintext, further democratizing the ability to attack this protocol. Rainbow tables are almost as old, with the initial paper on rainbow tables published in 2003 by Philippe Oechslin , citing an earlier iteration of a time-memory trade-off from 1980 by Martin Hellman . Essentially, if an attacker c", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Interactive eBPF", "url": "https://ebpf.party/", "content": "Learn eBPF through hands-on exercises. Write, compile, and run programs\n        directly from your browser. Did you find an issue, or have an idea for a new exercise? Create an\n        issue in the repository . Curious about how it works? Here's an explanation.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Palantir CEO Says AI to Make Large-Scale Immigration Obsolete", "url": "https://www.bloomberg.com/news/articles/2026-01-20/palantir-ceo-says-ai-to-make-large-scale-immigration-obsolete", "content": "Palantir CEO Says AI to Make Large-Scale Immigration Obsolete. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Dell UltraSharp 52 Thunderbolt Hub Monitor", "url": "https://www.dell.com/en-us/shop/dell-ultrasharp-52-thunderbolt-hub-monitor-u5226kw/apd/210-bthw/monitors-monitor-accessories", "content": "Dell UltraSharp 52 Thunderbolt Hub Monitor. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Did past \"bubbles\" have so many people claiming we were in a bubble?", "url": "item?id=46698301", "content": "Ask HN: Did past \"bubbles\" have so many people claiming we were in a bubble?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "I got into an argument on Discord about how inefficient CBR/CBZ is, so I wrote", "url": "https://old.reddit.com/r/selfhosted/comments/1qi64pr/i_got_into_an_argument_on_discord_about_how/", "content": "use the following search parameters to narrow your results: e.g. subreddit:aww site:imgur.com dog see the search faq for details. advanced search: by author, subreddit...       A place to share alternatives to popular online services that can be self-hosted without giving up privacy or locking you into a service you don't control.   Service: Dropbox - Alternative: Nextcloud Service: Google Reader - Alternative: Tiny Tiny RSS Service: Blogger - Alternative: WordPress  We welcome posts that include suggestions for good self-hosted alternatives to popular online services, how they are better, or how they give back control of your data. Also include hints and tips for less technical readers.  What Is SelfHosted, As it pertains to this subreddit?   The Rules   Read about our Chat Options (Discord/Matrix)    the front page of the internet. and join one of thousands of communities.  Media Serving I got into an argument on Discord about how inefficient CBR/CBZ is, so I wrote a new file format. It's 100x faster than CBZ. ( i.redd.it ) submitted 20 hours ago by ef1500_v2 Hello Everyone, A month or so ago, I found myself in an argument on the r/yuri_manga discord debating self-hosted manga archive options. The general consensus was \"CBZ is fine. It is what it is.\" I said I would make something better. So I did. My solution is the Bound Book Format . I have a more in-depth comparison on the github repo . I'm not creating a unifying standard for everyone's use case. I'm solving a few problems that have bugged me for years. CBZ is also just a ZIP file, it's not built for comics. BBF is. This project is 100% open sourced, and licensed under the MIT license. The python bindings include conversion scripts to convert between CBZ and BBF (cbx2bbf, bbf2cbx). You won't lose your cbz files, and you can convert back to cbz at any time. (Note: The tool handles image data perfectly, but parsing existing XML metadata and nested folders is currently a work-in-progress.) I have numbers to back", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "ClickHouse acquires Langfuse", "url": "https://langfuse.com/blog/joining-clickhouse", "content": "Our goal continues to be building the best LLM engineering platform  ClickHouse has acquired Langfuse. If you‚Äôre reading this as a Langfuse user, your first question is probably: What does this mean for me? Our roadmap stays the same, our goal continues to be building the best LLM engineering platform, and we remain committed to open source and self-hosting. There are no immediate changes to how you use Langfuse and how you can reach out to us. What does change is our ability to move faster. With ClickHouse behind us, we can invest more deeply into performance, reliability, and our roadmap that helps teams build and improve AI applications in production. This is the section we would want to read first, too. Joining Clickhouse compresses years of operational learning into immediate, real customer benefits. The longer version of how we got here is in our handbook . Langfuse started the same way many LLM products start: we were building agents ourselves. And we constantly ran into the same problems. Building LLM apps is easy to demo and hard to run in production. Debugging is different, quality is non‚Äëdeterministic, and the iteration loop is messy. When we did Y Combinator in early 2023, we saw this every week, both in our own projects and in what other founders in our cohort were working on. So we built a duct tape version of what we wished existed: tracing and evaluation primitives that are easy to add, easy to self‚Äëhost, and actually useful for iterating . The very first version was intentionally simple. It ran on Postgres , because speed of shipping mattered more than theoretical scaling. That got us to a real product and a real community fast. Then people actually started to use the product more than we could have imagined.  As adoption grew, Postgres became the bottleneck for the workloads Langfuse needed to support (high‚Äëthroughput ingestion + fast analytical reads). With Langfuse v3 , we switched the core data layer to ClickHouse to make Langfuse scale for prod", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "How to be a good conference talk audience member (2022)", "url": "https://www.mooreds.com/wordpress/archives/3522", "content": "I recently attended a conference and was both a speaker and audience member. It was on the smaller side; there were probably a few hundred attendees and the audiences ranged from about twenty to hundreds of attendees for the keynotes. After one of the talks, a speaker came up and said ‚Äúyou were such a good audience member, thank you!‚Äù. I said the same thing to one of the attendees of the talk I gave. I wanted to share how you can be a good audience member at a conference talk. It‚Äôs important to note that this advice is for attending in-person talks where the speaker can see the audience. This is typically when there are up to one hundred people. I‚Äôve spoken in front of 800 people and it‚Äôs a different experience. While some of these principles apply, in general individual behavior is less important as audience size grows. And online talks are an entirely different experience for everyone, both audience and speaker! I don‚Äôt have enough experience to give any advice for that scenario. First, though, why would you care to be a good member of an in-person audience? After all, you are providing your time and money to the conference and the presenter. Isn‚Äôt it the speaker‚Äôs job to entertain and educate you ? Why would you expend any energy to help them do so? First, I‚Äôm a big fan of being respectful of other human beings and helping them succeed. Public speaking is a common fear and being a good audience member can reassure the speaker and reduce that fear. It‚Äôs hard up there, whether it‚Äôs your first talk or your hundredth. The second reason is that you can make a talk better for yourself . You can learn more and you can tune their presentation to your needs. They are an expert and you can take advantage of their expertise. So, here are my tips on how to be a great audience member: Am I always a good audience member? Nope. I get distracted sometimes. But when I follow my suggestions above, I learn more from the expert on the stage. My newsletter will deliver my blog posts", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Local models to support home network infrastructure?", "url": "item?id=46690846", "content": "Ask HN: Local models to support home network infrastructure?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "STFU", "url": "https://github.com/Pankajtanwarbanna/stfu", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . stfu There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . i was at bombay airport. some dude was watching reels on full volume and laughing loudly. asking nicely doesn't work anymore. me being me, didn't have the courage to speak up. so i built a tiny app that plays back the same audio it hears, delayed by ~2 seconds. asked claude, it spat out a working version in one prompt. surprisingly WORKS. discussion - https://x.com/the2ndfloorguy/status/2011734249871954188 something something auditory feedback loop something something cognitive dissonance. idk i'm not a neuroscientist. all i know is it makes people shut up and that's good enough for me. straight up honest - originally called this \"make-it-stop\" but then saw @TimDarcet also built similar and named it STFU. wayyyyy better name. so stole it. sorry not sorry. made with spite and web audio api. do whatever you want with it. yo, meanwhile if you are new here, you might find my , other side projects kinda funny. stfu There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Cursor's latest ‚Äúbrowser experiment‚Äù implied success without evidence", "url": "https://embedding-shapes.github.io/cursor-implied-success-without-evidence/", "content": "2026-01-16 On January 14th 2026, Cursor published a blog post titled \"Scaling\nlong-running autonomous coding\" ( https://cursor.com/blog/scaling-agents ) In the blog post, they talk about their experiments with running\n\"coding agents autonomously for weeks\" with the explicit goal of understand[ing] how far we can push the frontier of agentic coding\nfor projects that typically take human teams months to complete They talk about some approaches they tried, why they think those\nfailed, and how to address the difficulties. Finally they arrived at a point where something \"solved most of our\ncoordination problems and let us scale to very large projects without\nany single agent\", which then led to this: To test this system, we pointed it at an ambitious goal: building a\nweb browser from scratch. The agents ran for close to a week, writing\nover 1 million lines of code across 1,000 files. You can explore the\nsource code on GitHub ( https://github.com/wilsonzlin/fastrender ) This is where things get a bit murky and unclear. They claim \"Despite\nthe codebase size, new agents can still understand it and make\nmeaningful progress\" and \"Hundreds of workers run concurrently, pushing\nto the same branch with minimal conflicts\", but they never actually say\nif this is successful or not, is it actually working? Can you run this\nbrowser yourself? We don't know and they never say explicitly. After this, they embed the following video: Video And below it, they say \"While it might seem like a simple screenshot,\nbuilding a browser from scratch is extremely difficult.\". error: could not compile 'fastrender' (lib) due to 34 previous\nerrors; 94 warnings emitted And if you try to compile it yourself, you'll see that it's very far\naway from being a functional browser at all, and seemingly, it never\nactually was able to build. Multiple recent GitHub Actions runs on main show\nfailures (including workflow-file errors), and independent build\nattempts report dozens of compiler errors, recent PRs were al", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Overlapping Markup", "url": "https://en.wikipedia.org/wiki/Overlapping_markup", "content": "In markup languages and the digital humanities , overlap occurs when a document has two or more structures that interact in a non- hierarchical manner.\nA document with overlapping markup cannot be represented as a tree .\nThis is also known as concurrent markup .\nOverlap happens, for instance, in poetry , where there may be a metrical structure of feet and lines; a linguistic structure of sentences and quotations; and a physical structure of volumes and pages and editorial annotations. [ 1 ] [ 2 ] The problem of non-hierarchical structures in documents has been recognised since 1988; resolving it against the dominant paradigm of text as a single hierarchy (an ordered hierarchy of content objects or OHCO ) was initially thought to be merely a technical issue, but has, in fact, proven much more difficult. [ 4 ] In 2008, Jeni Tennison identified markup overlap as \"the main remaining problem area for markup technologists\". [ 5 ] Markup overlap continues to be a primary issue in the digital study of theological texts in 2019, and is a major reason for the field retaining specialised markup formats‚Äîthe Open Scripture Information Standard and the Theological Markup Language ‚Äîrather than the inter-operable Text Encoding Initiative -based formats common to the rest of the digital humanities . [ 6 ] A distinction exists between schemes that allow non-contiguous overlap, and those that allow only contiguous overlap. Often, 'markup overlap' strictly means the latter.\nContiguous overlap can always be represented as a linear document with milestones (typically co-indexed start- and end-markers), without the need for fragmenting a (logical) component into multiple physical ones. Non-contiguous overlap may require document fragmentation. Another distinction in overlapping markup schemes is whether elements can overlap with other elements of the same kind ( self-overlap ). [ 2 ] A scheme may have a privileged hierarchy.\nSome XML -based schemes, for example, represent one hierarchy di", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: How worried should I be about running LLM code on my machine?", "url": "item?id=46686262", "content": "Ask HN: How worried should I be about running LLM code on my machine?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The 'untouchable hacker god' behind Finland's biggest crime", "url": "https://www.theguardian.com/technology/2026/jan/17/vastaamo-hack-finland-therapy-notes", "content": "How would you feel if your therapist‚Äôs notes ‚Äì your darkest thoughts and deepest feelings ‚Äì were exposed to the world? For 33,000 Finnish people, that became a terrifying reality, with deadly consequences T iina Parikka was half-naked when she read the email. It was a Saturday in late October 2020, and Parikka had spent the morning sorting out plans for distance learning after a Covid outbreak at the school where she was headteacher. She had taken a sauna at her flat in Vantaa, just outside Finland‚Äôs capital, Helsinki, and when she came into her bedroom to get dressed, she idly checked her phone. There was a message that began with Parikka‚Äôs name and her social security number ‚Äì the unique code used to identify Finnish people when they access healthcare, education and banking. ‚ÄúI knew then that this is not a game,‚Äù she says. The email was in Finnish. It was jarringly polite. ‚ÄúWe are contacting you because you have used Vastaamo‚Äôs therapy and/or psychiatric services,‚Äù it read. ‚ÄúUnfortunately, we have to ask you to pay to keep your personal information safe.‚Äù The sender demanded ‚Ç¨200 in bitcoin within 24 hours, otherwise the price would go up to ‚Ç¨500 within 48 hours. ‚ÄúIf we still do not receive our money after this, your information will be published for everyone to see, including your name, address, phone number, social security number and detailed records containing transcripts of your conversations with Vastaamo‚Äôs therapists or psychiatrists.‚Äù Parikka swallows hard as she relives this memory. ‚ÄúMy heart was pounding. It was really difficult to breathe. I remember lying down on the bed and telling my spouse, ‚ÄòI think I‚Äôm going to have a heart attack.‚Äô‚Äù Someone had hacked into Vastaamo, the company through which Parikka had accessed psychotherapy. They‚Äôd got hold of therapy notes containing her most private, intimate feelings and darkest thoughts ‚Äì and they were holding them to ransom. Parikka‚Äôs mind raced as she tried to recall everything she‚Äôd confided during three", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The Dilbert Afterlife", "url": "https://www.astralcodexten.com/p/the-dilbert-afterlife", "content": "Thanks to everyone who sent in condolences on my recent death from prostate cancer at age 68, but that was Scott Adams. I (Scott Alexander) am still alive 1 . Still, the condolences are appreciated. Scott Adams was a surprisingly big part of my life. I may be the only person to have read every Dilbert book before graduating elementary school . For some reason, 10-year-old-Scott found Adams‚Äô stories of time-wasting meetings and pointy-haired bosses hilarious. No doubt some of the attraction came from a more-than-passing resemblance between Dilbert‚Äôs nameless corporation and the California public school system. We‚Äôre all inmates in prisons with different names. But it would be insufficiently ambitious to stop there. Adams‚Äô comics were about the nerd experience. About being cleverer than everyone else, not just in the sense of being high IQ, but in the sense of being the only sane man in a crazy world where everyone else spends their days listening to overpaid consultants drone on about mission statements instead of doing anything useful. There‚Äôs an arc in Dilbert where the boss disappears for a few weeks and the engineers get to manage their own time. Productivity shoots up. Morale soars. They invent warp drives and time machines. Then the boss returns, and they‚Äôre back to being chronically behind schedule and over budget. This is the nerd outlook in a nutshell: if I ran the circus, there‚Äôd be some changes around here. Yet the other half of the nerd experience is: for some reason this never works. Dilbert and his brilliant co-workers are stuck watching from their cubicles while their idiot boss racks in bonuses and accolades. If humor, like religion, is an opiate of the masses, then Adams is masterfully unsubtle about what type of wound his art is trying to numb. This is the basic engine of Dilbert : everyone is rewarded in exact inverse proportion to their virtue. Dilbert and Alice are brilliant and hard-working, so they get crumbs. Wally is brilliant but lazy, so he", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Simulating the Ladybug Clock Puzzle", "url": "https://austinhenley.com/blog/ladybugclock.html", "content": "Associate Teaching Professor Carnegie Mellon University See the discussion of this post on Hacker News . A few days ago, 3Blue1Brown posted a 60-second video describing a puzzle... Imagine that a ladybug lands on the 12 o'clock marker of a clock. It then proceeds to move either clockwise or counterclockwise to the adjacent hour marker, one at a time, and repeats until all hour markers have been visited at least once. What is the probability that it ends on the 6? These sort of puzzles always intrigue me. They're simple to describe and at first might even look easy to solve, but as I dig into them, my intuition leads me astray. What a fun Saturday morning project! I whipped up a simulator to try it out. It works like this: See, it is simple. But before running the simulator, can you guess the probability of it ending on 6? What about 11 or 1? 3? The other numbers? It stumped me. My guess was that 6 would be the most likely‚Äîit is the farthest away but it is also necessary to visit all other numbers first. The numbers closer to 12 would be gradually less likely. Am I right? It might remind you of other random walk problems. So what is the answer? Well, I first ran the simulator 100 times and the results looked random. More runs! After ~1500 runs, all of the numbers were showing 8-10% likelihood with no discernable pattern. That isn't what I expected. After 5000 runs, they were all 8.4-9.7%. And then after 10,000 runs... Based on the simulator, all numbers are equally likely with 9% probability , excluding 12 of course, since that is visited first and thus can't be last. The answer is 1 ‚ÅÑ 11 . An even more fun question? What is the average number of moves that the ladybug will make to visit all 12 numbers? I'd love to hear someone's explanation for that answer!", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Penn Calls Government's Demand for Lists of Jewish Staff 'Disconcerting'", "url": "https://www.nytimes.com/2026/01/20/us/university-of-pennsylvania-trump-jewish-staff.html", "content": "Penn Calls Government's Demand for Lists of Jewish Staff 'Disconcerting'. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Streaming gigabyte medical images from S3 without downloading them", "url": "https://github.com/PABannier/WSIStreamer", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . WSI Streamer is a tile server for Whole Slide Images (WSI) stored in S3-compatible object storage. It serves tiles on-demand using HTTP range requests, so you never have to download or mount multi-gigabyte slides on local disk. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  A modern, cloud-native tile server for Whole Slide Images. One command to start serving tiles directly from S3.  That's it. No configuration files, no local storage, no complex setup. Open http://localhost:3000/view/sample.svs in your browser to view a slide. Whole Slide Images are large (1-3GB+) and typically live in object storage. Traditional viewers require downloading entire files before serving a single tile. WSIStreamer takes a different approach: it understands slide formats natively, fetches only the bytes needed via HTTP range requests, and returns JPEG tiles immediately. Install from crates.io : Or build from source: Or run with Docker: The web viewer handles authentication automatically when enabled. All options can be set via CLI flags or environment variables: Run wsi-streamer --help for full details. See API_SPECIFICATIONS.md for complete documentation. Files must be tiled (not stripped) and pyramidal. MIT. See LICENSE . Issues and pull requests welcome. See CONTRIBUTING.md . WSI Streamer is a tile server for Whole Slide Images (WSI) stored in S3-compatible object storage. It serves tiles on-demand using HTTP range requests, so you never have to download or mount multi-gigabyte slides on local disk. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "How to wrangle non-deterministic AI outputs into conventional software? (2025)", "url": "https://www.domainlanguage.com/articles/ai-components-deterministic-system/", "content": "by Eric Evans When we set out to incorporate AI components into larger systems that are mostly conventional software, we encounter various difficulties. How do we wrangle behavior that is intrinsically non-deterministic so that it can be used in structured, deterministic systems? The flexibility of input is great! But the variation of output makes it difficult to do further processing by conventional software. In this simple example I‚Äôll characterize and constrain a non-deterministic result to make it usable in deterministic software. This leads into domain modeling and strategic design. What follows isn‚Äôt rocket science, but it is the sort of basics I think we need to apply in order to get results. Let‚Äôs start with a use-case I actually have. When I‚Äôm trying to get my bearings in a software system, I usually want to know what domains are addressed and in which parts of the code. So imagine an app that would generate that sort of view of a repo: To be concrete, let‚Äôs look at the open source project ‚ÄúOpenEMR‚Äù. Here‚Äôs a very small code sample from that project: We might ask, ‚Äúwhat domains are addressed in this code?‚Äù Conventional code does not lend itself to that kind of question, but it is a natural use of an LLM. An intelligent answer! But we couldn‚Äôt pass that to conventional software for further processing. Of course, we would instruct the LLM to structure and format its output. Okay, so now we have an answer that could be integrated in a technical way. Yet this is will not support the comparisons and hierarchical roll-ups I was hoping for. Because categories are chosen freely in each run, the classification of different files will not be easy to compare. To illustrate the point, I‚Äôll repeat the same question using the same file. Every time I ask question I get a different answer: The answers make sense individually but would be difficult to compare or combine. The stochastic nature of LLMs can be a challenge in making reliable systems. However, in this case, I se", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Starlink users must opt out of all browsing data being used to train xAI models", "url": "https://twitter.com/cryps1s/status/2013345999826153943", "content": "Starlink users must opt out of all browsing data being used to train xAI models. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Reading across books with Claude Code", "url": "https://pieterma.es/syntopic-reading-claude/", "content": "Jan 4, 2026 LLMs are overused to summarise and underused to help us read deeper. To explore how they can enrich rather than reduce, I set Claude Code up with tools to mine a library of 100 non-fiction books.\nIt found sequences of excerpts connected by an interesting idea, or trails . Browse all trails Here‚Äôs a part of one such trail, linking deception in the startup world to the social psychology of mass movements (I‚Äôm especially pleased by the jump from Jobs to Theranos): Steve Jobs Bad Blood Zero to One The True Believer The books were selected from Hacker News‚Äô favourites, which I previously scraped and visualized . Claude browses the books a chunk at a time. A chunk is a segment of roughly 500 words that aligns with paragraphs when possible.\nThis length is a good balance between saving tokens and providing enough context for ideas to breathe. Chunks are indexed by topic, and topics are themselves indexed for search. This makes it easy to look up all passages in the corpus that relate to, say, deception . This works well when you know what to look for, but search alone can‚Äôt tell you which topics are present to begin with.\nThere are over 100,000 extracted topics, far too many to be browsed directly. To support exploration, they are grouped into a hierarchical tree structure. This yields around 1,000 top-level topics. They emerge from combining lower-level topics, and not all of them are equally useful: However, this Borgesian taxonomy is good enough for Claude to piece together what the books are about. Claude uses the topic tree and the search via a few CLI tools. They allow it to: To generate the trails, the agent works in stages. Even though I‚Äôve been using Claude Code to develop for months, my first instinct for this project was to consider it as a traditional pipeline of several discrete stages.\nMy initial attempt at this system consisted of multiple LLM modules with carefully hand-assembled contexts. On a whim, I ran Claude with access to the debugging tool", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: ChunkHound, a local-first tool for understanding large codebases", "url": "https://github.com/chunkhound/chunkhound", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Local first codebase intelligence There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  Local first codebase intelligence  Your AI assistant searches code but doesn't understand it. ChunkHound researches your codebase‚Äîextracting architecture, patterns, and institutional knowledge at any scale. Integrates via MCP . Visit chunkhound.github.io for complete guides: Note: Use \"codex-cli\" instead if you prefer Codex. Both work equally well and require no API key. For configuration, IDE setup, and advanced usage, see the documentation . Ideal for: Stop recreating code. Start with deep understanding. MIT Local first codebase intelligence There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A free and open-source rootkit for Linux", "url": "https://lwn.net/SubscriberLink/1053099/19c2e8180aeb0438/", "content": "A free and open-source rootkit for Linux. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Drone Hacking Part 1: Dumping Firmware and Bruteforcing ECC", "url": "https://neodyme.io/en/blog/drone_hacking_part_1/", "content": "Jan 5, 2026 ~48 min read In July 2025, we from Neodyme got together in Munich and did security research on a bunch of IoT devices, ranging from bluetooth headsets, to door locks, to drones. One of these was the Potensic Atom 2. It‚Äôs a photo and video drone with a gimbal-stabilized 4K camera and a remote control that you hook up to your own smartphone and the proprietary app. If you‚Äôve ever flown a DJI Mini 4K, this drone will look very familiar to you.  Potensic Atom 2  This post is part of a two-part series that will cover how we disassembled the drone and dumped the firmware from the NAND chip and how we analyzed the drone‚Äôs firmware, app, and remote control to find some backdoors and vulnerabilities. One of the most important pieces of information you can acquire when setting up to hack a device is its firmware. If you want to reverse engineer the software that‚Äôs running on the drone and find vulnerabilities in that, then you need a copy of it in the first place. Now there are a couple of ways to go about that, some are less intrusive and some are more effective. You might get lucky and be able to just download the firmware as a firmware update from the manufacturer‚Äôs website. However, those update sites are often not publicly documented and can be locked behind authorization checks or encrypted. Encrypted firmwares can still be useful - you ‚Äújust‚Äù need to reverse engineer the on-device decryption process. For the Atom 2, downloading the firmware updates required having a valid drone and remote control serial number and the firmware update was also encrypted. Without having the decryption logic, we put this approach on ice during our initial research. Another really comfortable approach is to use exposed debug interfaces like JTAG or UART. However, those are often undocumented, unlabeled, or entirely removed for public versions. We didn‚Äôt find any on the Atom 2. What we can always do, though not necessarily always successful, is solder off the entire NAND chip an", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Computer Systems Security 6.566 / Spring 2024", "url": "https://css.csail.mit.edu/6.858/2024/", "content": "The lectures cover a broad overview of systems security together with a deeper focus on several topics: isolation techniques , privilege separation , dealing with buggy code , networked and distributed systems ,\nand human-focused security and privacy . Links to notes etc. on future days are copies of materials from last year,\nto give you an idea of what the future will bring.  We will update the\nnotes as the course progresses.  The year of publication for class\nreadings are shown in parentheses. Monday Tuesday Wednesday Thursday Friday feb 5 First day of classes feb 6 LEC 1: Introduction, threat models ( video ) Preparation: Optionally read Modern Android exploit Assigned: Lab 1: Buffer overflows feb 7 feb 8 LEC 2: OS and VM isolation ( video ) Preparation: Read about OS and VM isolation ( Question ) feb 9 feb 12 feb 13 LEC 3: Software fault isolation ( video ) Preparation: Read about WebAssembly ( Question ) feb 14 feb 15 LEC 4: Trusted hardware ( video ) Preparation: Read BitLocker (2006), sections 1-2 ( Question ) feb 16 DUE: Lab 1 part 1 DUE: Lab 1 part 2 feb 19 Presidents day feb 20 Monday schedule feb 21 feb 22 LEC 5: CPU side-channels ( video ) Preparation: Read Transient Execution Attacks and Defenses (2019) ( Question ) Assigned: Lab 2: Privilege separation feb 23 DUE: Lab 1 all parts feb 26 feb 27 LEC 6: Privilege separation ( video ) Preparation: Read OpenSSH (2003) ( Question ) feb 28 feb 29 LEC 7: Data center infrastructure ( video ) Preparation: Read Google Infrastructure Security (2023) and BeyondProd (2023) ( Question ) mar 1 DUE: Lab 2 part 1 mar 4 mar 5 LEC 8: Mobile phone security ( video ) Preparation: Read about iOS Security ( Question ) mar 6 mar 7 LEC 9: Web security model ( video ) Preparation: Read about web security (2022) ( Question ) mar 8 DUE: Lab 2 parts 2+3 ADD DATE mar 11 mar 12 LEC 10: Buffer overflow defenses ( video ) Preparation: Read Baggy bounds checking (2009) + errata ( Question ) Assigned: Lab 3: Symbolic execution mar 13 mar", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "ThinkNext Design", "url": "https://thinknextdesign.com/home.html", "content": "Purposeful design . Business success . Design is far more than form or function. It√¢¬Ä¬ôs the tangible expression of a brand√¢¬Ä¬ôs identity, values, and promise. While a brand defines what a company stands for, design gives those aspirations form and substance. Design uniquely delivers value: visually, physically, and experientially. At ThinkNext Design, every creation begins with empathy and seeks purpose. We look to understand not just what people need, but what they desire. Whether crafting something entirely new or reimagining the familiar, our work blends aesthetic restraint with purposeful clarity. The result is innovative design that resonates emotionally, performs beautifully, and endures as a reflection of the brand behind it. More than 200,000,000 ThinkPads have been sold since 1992, and still counting. That didn't happen by accident. By the early 1990's, the original IBM AS/400 product line was rapidly losing market share due to a growing perception that the product family employed outdated technology, and was highly overpriced.  David led a strategic design initiative to recast that image via a sweeping change that would forever reposition the status quo. The resulting award winning design featured stark black enclosures, dramatic air inlets, and simple yet powerful forms. This was a striking contrast to the putty colored neutral appearance that had come to dominate not only the IBM server products, but the entire industry. Following the series introduction, AS/400 Division revenues jumped by a double-digit percentage. Comments of yesterday's technology were quickly replaced by associations with objects such as the innovative F117a stealth fighter. AS/400 systems had a control panel that included special functions that were designed to only be accessed by authorized operators. Restricted access was achieved using a traditional stainless steel keylock mated to a rotating electric switch. Without the key only basic functions could be operated. Unfortunately th", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "6-Day and IP Address Certificates Are Generally Available", "url": "https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability", "content": "Short-lived and IP address certificates are now generally available from Let‚Äôs Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‚Äòshortlived‚Äô certificate profile in their ACME client. Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate‚Äôs private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate‚Äôs expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced. Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well. Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, as previously announced . IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let‚Äôs Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our post announcing our first IP Certificate . We‚Äôd like to thank the Open Technology Fund and Sovereign Tech Agency, along with our Sponsors and", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Computer Systems Security 6.566 / Spring 2024", "url": "https://css.csail.mit.edu/6.858/2024/", "content": "The lectures cover a broad overview of systems security together with a deeper focus on several topics: isolation techniques , privilege separation , dealing with buggy code , networked and distributed systems ,\nand human-focused security and privacy . Links to notes etc. on future days are copies of materials from last year,\nto give you an idea of what the future will bring.  We will update the\nnotes as the course progresses.  The year of publication for class\nreadings are shown in parentheses. Monday Tuesday Wednesday Thursday Friday feb 5 First day of classes feb 6 LEC 1: Introduction, threat models ( video ) Preparation: Optionally read Modern Android exploit Assigned: Lab 1: Buffer overflows feb 7 feb 8 LEC 2: OS and VM isolation ( video ) Preparation: Read about OS and VM isolation ( Question ) feb 9 feb 12 feb 13 LEC 3: Software fault isolation ( video ) Preparation: Read about WebAssembly ( Question ) feb 14 feb 15 LEC 4: Trusted hardware ( video ) Preparation: Read BitLocker (2006), sections 1-2 ( Question ) feb 16 DUE: Lab 1 part 1 DUE: Lab 1 part 2 feb 19 Presidents day feb 20 Monday schedule feb 21 feb 22 LEC 5: CPU side-channels ( video ) Preparation: Read Transient Execution Attacks and Defenses (2019) ( Question ) Assigned: Lab 2: Privilege separation feb 23 DUE: Lab 1 all parts feb 26 feb 27 LEC 6: Privilege separation ( video ) Preparation: Read OpenSSH (2003) ( Question ) feb 28 feb 29 LEC 7: Data center infrastructure ( video ) Preparation: Read Google Infrastructure Security (2023) and BeyondProd (2023) ( Question ) mar 1 DUE: Lab 2 part 1 mar 4 mar 5 LEC 8: Mobile phone security ( video ) Preparation: Read about iOS Security ( Question ) mar 6 mar 7 LEC 9: Web security model ( video ) Preparation: Read about web security (2022) ( Question ) mar 8 DUE: Lab 2 parts 2+3 ADD DATE mar 11 mar 12 LEC 10: Buffer overflow defenses ( video ) Preparation: Read Baggy bounds checking (2009) + errata ( Question ) Assigned: Lab 3: Symbolic execution mar 13 mar", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "ThinkNext Design", "url": "https://thinknextdesign.com/home.html", "content": "Purposeful design . Business success . Design is far more than form or function. It√¢¬Ä¬ôs the tangible expression of a brand√¢¬Ä¬ôs identity, values, and promise. While a brand defines what a company stands for, design gives those aspirations form and substance. Design uniquely delivers value: visually, physically, and experientially. At ThinkNext Design, every creation begins with empathy and seeks purpose. We look to understand not just what people need, but what they desire. Whether crafting something entirely new or reimagining the familiar, our work blends aesthetic restraint with purposeful clarity. The result is innovative design that resonates emotionally, performs beautifully, and endures as a reflection of the brand behind it. More than 200,000,000 ThinkPads have been sold since 1992, and still counting. That didn't happen by accident. By the early 1990's, the original IBM AS/400 product line was rapidly losing market share due to a growing perception that the product family employed outdated technology, and was highly overpriced.  David led a strategic design initiative to recast that image via a sweeping change that would forever reposition the status quo. The resulting award winning design featured stark black enclosures, dramatic air inlets, and simple yet powerful forms. This was a striking contrast to the putty colored neutral appearance that had come to dominate not only the IBM server products, but the entire industry. Following the series introduction, AS/400 Division revenues jumped by a double-digit percentage. Comments of yesterday's technology were quickly replaced by associations with objects such as the innovative F117a stealth fighter. AS/400 systems had a control panel that included special functions that were designed to only be accessed by authorized operators. Restricted access was achieved using a traditional stainless steel keylock mated to a rotating electric switch. Without the key only basic functions could be operated. Unfortunately th", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "6-Day and IP Address Certificates Are Generally Available", "url": "https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability", "content": "Short-lived and IP address certificates are now generally available from Let‚Äôs Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‚Äòshortlived‚Äô certificate profile in their ACME client. Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate‚Äôs private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate‚Äôs expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced. Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well. Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, as previously announced . IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let‚Äôs Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our post announcing our first IP Certificate . We‚Äôd like to thank the Open Technology Fund and Sovereign Tech Agency, along with our Sponsors and", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Counterfactual evaluation for recommendation systems", "url": "https://eugeneyan.com/writing/counterfactual-evaluation/", "content": "[ recsys eval machinelearning ] ¬∑ 8 min read When I first started working on recommendation systems, I thought there was something weird about the way we did offline evaluation. First, we split customer interaction data into training and validation sets. Then, we train our recommenders on the training set before evaluating them on the validation set, usually on metrics such as recall, precision, and NDCG. This is similar to how we evaluate supervised machine learning models and doesn‚Äôt seem unusual at first glance. But don‚Äôt our recommendations change how customers click or purchase? If customers can only interact with items shown to them, why do we perform offline evaluation on static historical data? It took me a while to put a finger on it but I think this is why it felt weird: We‚Äôre treating recommendations as an observational problem when it really is an interventional problem . Problems solved via supervised machine learning are usually observational problems. Given an observation such as product title, description, and image, we try to predict the product category. Our model learns P(category=phone|title=‚Äú‚Ä¶‚Äù, description=‚Äú‚Ä¶‚Äù, image=image01.jpeg) . On the other hand, recommendations are an interventional problem. We want to learn how different interventions (i.e., item recommendations) lead to different outcomes (i.e., clicks, purchases). By using logged customer interaction data as labels, the observational offline evaluation approach ignores the interventional nature of recommendations. As a result, we‚Äôre not evaluating if users would click or purchase more due to our new recommendations; we‚Äôre evaluating how well the new recommendations fit logged data. Thus, what our model learns is P(view3=iphone|view1=pixel, view2=galaxy) when what we really want is P(click=True|recommend=iphone, view1=pixel, view2=galaxy) . The straightforward way to evaluate recommendations as an interventional problem is via A/B testing. Our interventions (i.e., new recommendations) a", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Amnesty urges halt to execution of 19-year-old Iranian protester", "url": "https://www.iranintl.com/en/202601209686", "content": "Amnesty International on Tuesday called for an immediate halt to the planned execution of 19-year-old Iranian protester Amirhossein Ghaderzadeh, whose death sentence is due to be carried out on Wednesday. ‚ÄúIranian authorities must immediately halt any plans to execute 19-year-old Amirhossein Ghaderzadeh, who has been detained since 9 January for taking part in protests in Rasht, Gilan province, and stop weaponizing the death penalty against protesters,‚Äù Amnesty said in a post on X. ‚ÄúAccording to an informed source, the authorities told him during a court session on 17 January that he is accused of ‚Äòbetraying his country‚Äô and sentenced to ‚Äòdeath by hanging‚Äô. The authorities have informed his family that his execution is scheduled for 21 January,‚Äù the group added. Israel‚Äôs foreign minister Gideon Sa‚Äôar has urged the European Union to formally designate Iran‚Äôs Islamic Revolutionary Guard Corps (IRGC) as a terrorist organization, citing its role in crushing protests and sponsoring terror across the region. ‚ÄúDesignate Iran's Revolutionary Guards as a terrorist organization!‚Äù the foreign minister wrote on X on Tuesday, responding to a post from European Commission President Ursula von der Leyen. ‚ÄúYou know very well what their role is in the murderous repression of the civilian protest in Iran, as well as in spreading terror in the Middle East and beyond,‚Äù Sa‚Äôar added.‚Äã The European Union is proposing new sanctions on Iran, including a ban on additional exports of drone and missile technologies, European Commission President Ursula von der Leyen said on Monday. She added that, together with the EU‚Äôs foreign policy chief Kaja Kallas, the Commission is preparing further human rights related measures. ‚ÄúWe are also preparing new sanctions in response to the regime‚Äôs continued and brutal repression of protesters,‚Äù she said. ‚ÄúIran‚Äôs authorities try to shut down the internet because they are afraid,‚Äù the US State Department‚Äôs Near Eastern Affairs bureau said in a post on X on Mon", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "IKOS a static analyzer for C/C++ based on the theory of Abstract Interpretation", "url": "https://github.com/NASA-SW-VnV/ikos", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Static analyzer for C/C++ based on the theory of Abstract Interpretation. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  IKOS (Inference Kernel for Open Static Analyzers) is a static analyzer for C/C++ based on the theory of Abstract Interpretation. IKOS started as a C++ library designed to facilitate the development of sound static analyzers based on Abstract Interpretation . Specialization of a static analyzer for an application or family of applications is critical for achieving both precision and scalability. Developing such an analyzer is arduous and requires significant expertise in Abstract Interpretation. IKOS provides a generic and efficient implementation of state-of-the-art Abstract Interpretation data structures and algorithms, such as control-flow graphs, fixpoint iterators, numerical abstract domains, etc. IKOS is independent of a particular programming language. IKOS also provides a C and C++ static analyzer based on LLVM . It implements scalable analyses for detecting and proving the absence of runtime errors in C and C++ programs. IKOS has been released under the NASA Open Source Agreement version 1.3, see LICENSE.pdf ikos@lists.nasa.gov See Releases . See TROUBLESHOOTING.md To install IKOS on Linux or macOS , we recommend to use Homebrew . First, install Homebrew by following these instructions . Then, simply run: For Windows, consider using Windows Subsystem for Linux . Suppose we want to analyze the following C program in a file, called loop.c : To analyze this program with IKOS, simply run: You shall see the following output. IKOS reports two occurrences of buffer overflow at line 8 and 9. The ikos command takes a source file ( .c , .cpp ) or a LLVM bitcode file ( .bc ) as input, analyzes it to find runtime errors (also called undefined behaviors),", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "How scientists are using Claude to accelerate research and discovery", "url": "https://www.anthropic.com/news/accelerating-scientific-research", "content": "Last October we launched Claude for Life Sciences‚Äîa suite of connectors and skills that made Claude a better scientific collaborator. Since then, we've invested heavily in making Claude the most capable model for scientific work , with Opus 4.5 showing significant improvements in figure interpretation, computational biology, and protein understanding benchmarks. These advances, informed by our partnerships with researchers in academia and industry, reflect our commitment to understanding exactly how scientists are using AI to accelerate progress.  We‚Äôve also been working closely with scientists through our AI for Science program, which provides free API credits to leading researchers working on high-impact scientific projects around the world.  These researchers have developed custom systems that use Claude in ways that go far beyond tasks like literature reviews or coding assistance. In the labs we spoke to, Claude is a collaborator that works across all stages of the research process: making it easier and more cost-effective to understand which experiments to run, using a variety of tools to help compress projects that normally take months into hours, and finding patterns in massive datasets that humans might overlook. In many cases it‚Äôs eliminating bottlenecks, handling tasks that require deep knowledge and have previously been impossible to scale; in some it‚Äôs enabling entirely different research approaches than researchers have traditionally been able to take. In other words, Claude is beginning to reshape how these scientists work‚Äîand point them towards novel scientific insights and discoveries.  One bottleneck in biological research is the fragmentation of tools: there are hundreds of databases, software packages, and protocols available, and researchers spend substantial time selecting from and mastering various platforms. That‚Äôs time that, in a perfect world, would be spent on running experiments, interpreting data, or pursuing new projects. Biomni , an age", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Is it still worth pursuing a software startup?", "url": "item?id=46654726", "content": "Ask HN: Is it still worth pursuing a software startup?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Emoji Use in the Electronic Health Record is Increasing", "url": "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2843883", "content": "Emoji Use in the Electronic Health Record is Increasing. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: AWS-doctor ‚Äì A terminal-based AWS health check and cost optimizer in Go", "url": "https://github.com/elC0mpa/aws-doctor", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Diagnose AWS costs, detect idle resources, and optimize cloud spending directly from your terminal. ü©∫ ‚òÅÔ∏è There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . A terminal-based tool that acts as a comprehensive health check for your AWS accounts. Built with Golang, aws-doctor diagnoses cost anomalies, detects idle resources, and provides a proactive analysis of your cloud infrastructure‚Äîeffectively giving you the insights of AWS Trusted Advisor without the need for a Business or Enterprise support plan.    As a Cloud Architect, I often need to check AWS costs and billing information. While the AWS Console provides raw data, it lacks the immediate context I need to answer the question: \"Are we spending efficiently?\" I created aws-doctor to fill that gap. It doesn't just show you the bill; it acts as a diagnostic tool that helps you understand where the money is going and what can be cleaned up. It automates the routine checks I used to perform manually, serving as a free, open-source alternative to the paid recommendations found in AWS Trusted Advisor. Diagnose AWS costs, detect idle resources, and optimize cloud spending directly from your terminal. ü©∫ ‚òÅÔ∏è There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Beats, a web-based drum machine", "url": "https://beats.lasagna.pizza", "content": "Share your beat with this URL: BEATS A web-based drum machine inspired by the Teenage Engineering Pocket Operators. CREDITS: ‚Ä¢ Wrote by @kinduff ‚Ä¢ Built with Tone.js and Stimulus.js ‚Ä¢ With the awesome VT323 font THANKS TO: ‚Ä¢ andiam03 for transposing patterns and inspiring! ‚Ä¢ ethanhein for the original idea ! ‚Ä¢ all beta reviewers!", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Figma-use ‚Äì CLI to control Figma for AI agents", "url": "https://github.com/dannote/figma-use", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Control Figma from the command line. Full read/write access for AI agents ‚Äî create shapes, text, components, set styles, export images. 100+ commands. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . CLI for Figma. Control it from the terminal ‚Äî with commands or JSX. Figma's official MCP plugin can read files but can't modify them. This one can. LLMs know CLI. LLMs know React. This combines both. CLI commands are compact ‚Äî easy to read, easy to generate, easy to chain. When a task involves dozens of operations, every saved token matters. JSX is how LLMs already think about UI. They've seen millions of React components. Describing a Figma layout as <Frame><Text> is natural for them ‚Äî no special training, no verbose schemas. ‚ñ∂Ô∏è Button components ‚ñ∂Ô∏è Tailwind UI calendar Or run directly without installing: Start Figma with remote debugging enabled: Check connection: That's it. No plugins to install. Imperative ‚Äî one command at a time: Or declaratively ‚Äî describe the structure in JSX and render it: The stdin mode accepts pure JSX only ‚Äî no variables, no logic. For components, variants, and conditions, use .figma.tsx files. Elements: Frame , Rectangle , Ellipse , Text , Line , Star , Polygon , Vector , Group , Icon , Image Insert any icon from Iconify by name. No downloading, no importing, no cleanup. In JSX: Browse 150k+ icons: icon-sets.iconify.design Load images from URL: Convert any Figma node back to JSX: Output: Compare two nodes as JSX diff: In a .figma.tsx file you can define components. First call creates the master, the rest create instances: ComponentSet with all combinations: This creates a real ComponentSet in Figma with all 4 variants, not just 4 separate buttons. CSS Grid for 2D layouts ‚Äî calendars, dashboards, galleries: Supports px , fr , and auto / hug . Separa", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Dev-owned testing: Why it fails in practice and succeeds in theory", "url": "https://dl.acm.org/doi/10.1145/3780063.3780066", "content": "Dev-owned testing: Why it fails in practice and succeeds in theory. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Boeing knew of flaw in part linked to UPS plane crash, NTSB report says", "url": "https://www.bbc.com/news/articles/cly56w0p9e1o", "content": "An aircraft that crashed in flames in Kentucky in November had a structural flaw  that had been identified by Boeing on similar planes 15 years ago, according to investigators. The MD-11F freighter operated by UPS, crashed after one of its engines separated from the wing as it was preparing to take off from Louisville. The plane briefly lifted off from the runway, before hurtling out of control into an industrial area. Fifteen people died as a result, including three crew and 12 on the ground. In an update report , the US National Transportation Safety Board (NTSB) revealed that cracks found in the engine mounting assembly had previously occurred on several other aircraft. At the time the manufacturer responsible for the aircraft, Boeing, concluded that the issue \"would not result in a safety of flight condition\". The MD-11 is a relatively elderly design that was originally produced by McDonnell Douglas.  Boeing acquired the company in 1997. The last MD-11 came off the production line in 2001, but Boeing has continued providing parts and service support. In the aftermath of the Kentucky disaster, the NTSB issued a preliminary report which drew attention to cracks in the engine attachment mechanism. Its latest update goes further, describing fractures due to evidence of \"fatigue\" ‚Äì or repeated stresses - in a critical bearing, as well as the mounting it is meant to sit in. It points out that Boeing had previously found failures of the same part on four occasions, affecting three different aircraft. In 2011, the company sent a \"service letter\" to operators warning them of its findings. This is a non legally-binding document used to alert operators about important safety or maintenance information. In this case, Boeing recommended that the part be included in a general visual inspection every five years. It also pointed out changes to the inspection procedure contained in the aircraft maintenance manual, and drew attention to a revised bearing assembly that could be fi", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: GibRAM an in-memory ephemeral GraphRAG runtime for retrieval", "url": "https://github.com/gibram-io/gibram", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . GibRAM is an in-memory knowledge graph server designed for retrieval augmented generation (RAG / GraphRAG) workflows. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . Graph in-Buffer Retrieval & Associative Memory GibRAM is an in-memory knowledge graph server designed for retrieval augmented generation (RAG) workflows. It combines a lightweight graph store with vector search so that related pieces of information remain connected in memory. This makes it easier to retrieve related regulations, articles or other text when a query mentions specific subjects. Server runs on port 6161 by default. Basic Usage: Custom Components: MIT GibRAM is an in-memory knowledge graph server designed for retrieval augmented generation (RAG / GraphRAG) workflows. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Breaking the Zimmermann Telegram (2018)", "url": "https://medium.com/lapsed-historian/breaking-the-zimmermann-telegram-b34ed1d73614", "content": "Breaking the Zimmermann Telegram (2018). Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "\"Anyone else out there vibe circuit-building?\"", "url": "https://twitter.com/beneater/status/2012988790709928305", "content": "\"Anyone else out there vibe circuit-building?\". Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "How Hightouch built their long-running agent harness", "url": "https://www.amplifypartners.com/blog-posts/how-hightouch-built-their-long-running-agent-harness", "content": "A lot has been said about the future of AI agents and their impact on our economy. Less has been said about how to actually build them.√Ç A few months ago Hightouch released their Hightouch Agents product . It is essentially a general purpose marketing agent that can plan campaigns, ask any question or analysis of your data, analyze creative and copy, and automate marketing reporting.√Ç Though to developers, marketing is often viewed as, well, you know√¢¬Ä¬¶ I can tell you as both a developer and marketer that this is an unbelievably diverse set of complex, multi-step, long running tasks that even researchers at frontier labs would shudder at trying to automate.√Ç The crazier thing is that Hightouch Agents actually work . The agent has complete context (e.g. the full customer data mode) thanks to the core Hightouch product , which helps customers connect and take action on all of their marketing data sources like Facebook Ads, Hubspot, etc. And it√¢¬Ä¬ôs also pre-built with domain expertise on marketing and can reason about complex concepts like creative fatigue, attribution modeling, and incrementality (and maybe getting to the front page of Hacker News ). All in all, it√¢¬Ä¬ôs one of the most advanced agent systems in production today.√Ç To build it, Hightouch√¢¬Ä¬ôs engineering team needed to solve a laundry list of interesting context, workflow, and prompt engineering problems that there is no set of commonly accepted solutions for. Based on extensive interviews with their technical team, this post will go through the major components of their agent harness, in particular the idea of agentic delegation : Let√¢¬Ä¬ôs get into it.√Ç So you want to build an agent. Where do you start? At the time of writing there are a few interesting (if young) agent frameworks to choose from. But when Hightouch started building their Agents product there weren√¢¬Ä¬ôt, and the common wisdom (if there was any) for building agents was immature. The most common abstraction was borrowed from data platforms:", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Some C habits I employ for the modern day", "url": "https://www.unix.dog/~yosh/blog/c-habits-for-me.html", "content": "posted 2026-01-17T21:02:00Z modified 2026-01-17T23:20:00Z Despite it being the first ‚Äúproper‚Äù programming language I learned‚Äìby reading K&R front-to-back no less‚ÄìI don‚Äôt write C too terribly often nowadays. Playing resonite has gotten me into writing a load of C# for modding the game, and most of what I do day-to-day is automating the tedium on my computer, which gets delegated to shell or python because of all the existing infrastructure. Alas, every now and then, something arises where I have to or just want to write some C (or C++). Sometimes it‚Äôs when I need to make some bindings for a library ; sometimes it‚Äôs to fill a niche of a language/architecture gap . It also remains as my favorite language to prototype stuff in, though I‚Äôm not quite sure why. In any case, C is an interesting language without much standardization on the whole ‚Äústyle‚Äù or ‚Äúpractices‚Äù part. Most other languages have very clear ‚Äúthis is the best way to use X‚Äù messages, either subtly embedded in the syntax itself or through ‚Äúofficial‚Äù documentation channels. C doesn‚Äôt have an official documentation channel, nor does it have syntax or standard library constructs that encourage one particular way of doing things. From this, there‚Äôs a bunch of inconsistencies in how people do things, and‚Äìespecially in the early days of the language and standard library‚Äìthe landscape and general practice is quite error prone. As such, I‚Äôve developed my own habits when writing C, usually picked up from blog posts, writing C# or rust, or just out of perfectionist brain. I‚Äôm not saying you should write stuff this way, nor am I claiming it is the best way to write C all the time. I break some of these practices when working with embedded systems or when I‚Äôm writing things to be as fast as they can possibly be. But it is the baseline I tend to start with for most projects, and if I don‚Äôt write it down, I‚Äôll never be consistent with it. I usually use C23 for my new C projects. When contributing to other projects, I of c", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Michelangelo's first painting, created when he was 12 or 13", "url": "https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html", "content": "in Art , History |   \tJanuary 15th, 2026 5 Comments    Think back, if you will, to the works of art you cre¬≠at¬≠ed at age twelve or thir¬≠teen. For many, per¬≠haps most of us, our out¬≠put at that stage of ado¬≠les¬≠cence amount¬≠ed to direc¬≠tion¬≠less doo¬≠dles, chaot¬≠ic comics, and a few unsteady-at-best school projects. But then, most of us did¬≠n‚Äôt grow up to be Michelan¬≠ge¬≠lo. In the late four¬≠teen-eight¬≠ies, when that tow¬≠er¬≠ing Renais¬≠sance artist was still what we would now call a ‚Äútween,‚Äù he paint¬≠ed The Tor¬≠ment of Saint Antho¬≠ny , a depic¬≠tion of the tit¬≠u¬≠lar reli¬≠gious fig¬≠ure beset by demons in the desert. Though based on¬†a wide¬≠ly known engrav¬≠ing, it nev¬≠er¬≠the¬≠less shows evi¬≠dence of rapid¬≠ly advanc¬≠ing tech¬≠nique, inspi¬≠ra¬≠tion, and even¬†cre¬≠ativ¬≠i¬≠ty ‚Äî espe¬≠cial¬≠ly when placed under the infrared scan¬≠ner. For about half a mil¬≠len¬≠ni¬≠um, The Tor¬≠ment of Saint Antho¬≠ny was¬≠n‚Äôt thought to have been paint¬≠ed by Michelan¬≠ge¬≠lo. As explained in the video from Inspi¬≠rag¬≠gio just below , when the paint¬≠ing sold at Sothe¬≠by‚Äôs in 2008, the buy¬≠er took it to the Met¬≠ro¬≠pol¬≠i¬≠tan Muse¬≠um of Art for exam¬≠i¬≠na¬≠tion and clean¬≠ing. ‚ÄúBeneath the lay¬≠ers of dirt accu¬≠mu¬≠lat¬≠ed over the cen¬≠turies,‚Äù says the nar¬≠ra¬≠tor, ‚Äúa very par¬≠tic¬≠u¬≠lar col¬≠or palette appeared. ‚ÄúThe tones, the blends, the way the human fig¬≠ure was treat¬≠ed: all of it began to resem¬≠ble the style Michelan¬≠ge¬≠lo would use years lat¬≠er in none oth¬≠er than the Sis¬≠tine Chapel .‚Äù Infrared reflec¬≠tog¬≠ra¬≠phy sub¬≠se¬≠quent¬≠ly turned up pen¬≠ti¬≠men¬≠ti , or cor¬≠rec¬≠tion marks, a com¬≠mon indi¬≠ca¬≠tion that ‚Äúa paint¬≠ing is not a copy, but an orig¬≠i¬≠nal work cre¬≠at¬≠ed with artis¬≠tic free¬≠dom.‚Äù   It was the Kim¬≠bell Art Muse¬≠um in Fort Worth, Texas that first bet big on the prove¬≠nance of The Tor¬≠ment of Saint Antho¬≠ny . Its new¬≠ly hired direc¬≠tor pur¬≠chased the paint¬≠ing after turn¬≠ing up ‚Äúnot a sin¬≠gle con¬≠vinc¬≠ing argu¬≠ment against the attri¬≠bu¬≠tion.‚Äù Thus acquired, it became ‚Äúthe only paint¬≠ing by Michelan¬≠ge¬≠lo loca", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Just the Browser", "url": "https://justthebrowser.com/", "content": "Just the Browser helps you remove AI features, telemetry data reporting, sponsored content, product integrations, and other annoyances from desktop web browsers. The goal is to give you \"just the browser\" and nothing else, using hidden settings in web browsers intended for companies and other organizations. This project includes configuration files for popular web browsers, documentation for installing and modifying them, and easy installation scripts. Everything is open-source on GitHub . The setup script can install the configuration files in a few clicks. You can also follow the manual guides for Google Chrome , Microsoft Edge , and Firefox . Windows: Open a PowerShell prompt as Administrator. You can do this by right-clicking the Windows button in the taskbar, then selecting the \"Terminal (Admin)\" or \"PowerShell (Admin)\" menu option. Next, copy the below command, paste it into the window ( Ctrl+V ), and press the Enter/Return key: Mac and Linux: Search for the Terminal in your applications list and open it. Next, copy the below command, paste it into the window ( Ctrl+V or Cmd+V ), and press the Enter/Return key: You can subscribe to the RSS/Atom releases feed to know when there are important changes to the configuration files, documentation, and scripts: This feed can be used with Feedly , Inoreader , The Old Reader , Feedbin , or any other reader tool. You can also subscribe to new releases with your GitHub account by clicking the Watch button on the repository , then selecting Custom > New releases. Start here if you don't have your preferred web browser installed. You can install the configuration files afterwards. macOS (Universal) Windows 64-bit x86 (amd64) Windows 32-bit x86 Windows 64-bit ARM (ARM64) Debian/Ubuntu 64-bit x86 (amd64) Fedora/openSUSE 64-bit x86 (amd64) Not sure which link to use? Try the official download page . macOS (Universal) Windows 64-bit x86 (amd64) Windows 32-bit x86 Windows 64-bit ARM (ARM64) Not sure which link to use? Try the of", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "CVEs affecting the Svelte ecosystem", "url": "https://svelte.dev/blog/cves-affecting-the-svelte-ecosystem", "content": "Time to upgrade Elliott Johnson Jan 15 2026 We‚Äôve released patches for 5 vulnerabilities across devalue , svelte , @sveltejs/kit , and @sveltejs/adapter-node . Here‚Äôs what you need to know: If you‚Äôre using any of these packages, upgrade them to their corresponding non-vulnerable versions: For cross-dependent packages ‚Äî svelte and @sveltejs/kit depend on devalue ‚Äî patched versions already include upgraded dependencies. We‚Äôre extremely thankful to all of the security researchers who responsibly disclosed these vulnerabilities and worked with us to get them fixed, to the security team at Vercel who helped us navigate the disclosure process, and to the maintainers who worked to publish the fixes. Over the last few weeks, we‚Äôve seen a spate of high profile vulnerabilities affecting popular tools across the web development ecosystem. While they are unfortunate, it has been encouraging to see the community pulling together to keep end users safe. Using the lessons learned from these vulnerabilities, we will invest in processes that will help catch future bugs during the writing and review phases, before they go live. If you think you have discovered a vulnerability in a package maintained by the Svelte team, we urge you to privately report it via the Security tab on the repo in question (or the Svelte repo , if unsure). Full reports are available in the published security advisories, but we‚Äôve included a brief summary of each below. (Yes, this is very similar to the previous CVE. No, it is not the same!)", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Martin Luther King was talking about a universal basic income before it was cool", "url": "https://www.businessinsider.com/martin-luther-king-jr-universal-basic-income-ai-economic-equality-2026-1", "content": "Every time Lauren publishes a story, you‚Äôll get an alert straight to your inbox! Enter your email  By clicking ‚ÄúSign up‚Äù, you agree to receive emails from Business Insider. In addition, you accept Insider‚Äôs Terms of Service and Privacy Policy . Billionaire tech bros like Sam Altman and Elon Musk like to think they operate on the futuristic fringe. On at least one subject that is trendy in tech circles, however, they are way late: basic income. Nearly six decades ago, Martin Luther King Jr. advocated for a form of basic income not unlike what AI leaders today suggest could be the salve to mitigate AI's impact on the workforce. King wrote in his 1967 book, \"Where Do We Go From Here?\" that a guaranteed annual income could ultimately create \"widespread economic security.\" \"Personal conflicts between husband, wife, and children will diminish when the unjust measurement of human worth on a scale of dollars is eliminated,\" he wrote. Every time Lauren publishes a story, you‚Äôll get an alert straight to your inbox! Stay connected to Lauren and get more of their work as it publishes.  By clicking ‚ÄúSign up‚Äù, you agree to receive emails from Business Insider. In addition, you accept Insider's Terms of Service and Privacy Policy . A universal basic income is a recurring cash payment provided to all citizens of a population regardless of socioeconomic standing. A guaranteed basic income , on the other hand, refers to recurring cash payments made to specific citizens, such as those belonging to a certain socioeconomic group, for a set period of time. The idea of a basic income has gained traction in recent years. Many US cities and counties have launched pilot programs, and some have made those programs permanent . King's book came three years after former President Lyndon B. Johnson signed the Civil Rights Act of 1964, making it illegal to discriminate based on race, color, sex, religion, or national origin. It was a time of widespread social unrest. In the book, King sought to ad", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: Opal Editor, free Obsidian alternative for markdown and site publishing", "url": "https://github.com/rbbydotdev/opal", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . local-first browser-first markdown workspace wysiwig editor and publisher - built with mdx-editor, code mirror 6, react, shadcn, & typescript There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .  A local-first markdown editor and static publisher‚Äîno-server-required, Git-aware, with complete self-custody and zero backend dependencies.    Visit opaledx.com to start writing. Read the full documentation Opal Editor is completely free to use and own with absolutely no profit motive or incentive. Beyond creating a feature-rich Markdown editor and publisher for the open-source community, it also serves as a way for me to showcase my skills as a developer. If you like what you see and would like to discuss an opening at your company/startup/workshop, feel free to reach out via my website or by email . Enjoy! local-first browser-first markdown workspace wysiwig editor and publisher - built with mdx-editor, code mirror 6, react, shadcn, & typescript There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . There was an error while loading. Please reload this page .", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "What twenty years of DevOps has failed to do", "url": "https://www.honeycomb.io/blog/you-had-one-job-why-twenty-years-of-devops-has-failed-to-do-it", "content": "Futureproof your software for what comes next with the Honeycomb platform. Discover why Honeycomb is the better choice for your engineers, your customers, and your bottom line. Start your journey with the definitive guide to observability. Download our complimentary ebook. Bring observability to every software engineer. Learn about our company, mission and values. Meet the people behind Honeycomb. Come for the impact, stay for the culture. See the latest press releases from Honeycomb. Already a Honeycomb customer? I think the entire DevOps movement was a mighty, twenty year battle to achieve one thing: a single feedback loop connecting devs with prod.\n\nOn those grounds, it failed. By: Charity Majors Let‚Äôs start with a question. What is DevOps all about? I‚Äôll tell you my answer. In retrospect, I think the entire DevOps movement was a mighty, twenty year battle to achieve one thing: a single feedback loop connecting devs with prod. On those grounds, it failed. Not because software engineers weren‚Äôt good at their jobs, or didn‚Äôt care enough. It failed because the technology wasn‚Äôt good enough. The tools we gave them weren‚Äôt designed for this, so using them could easily double, triple, or quadruple the time it took to do their job: writing business logic. This isn‚Äôt true everywhere. Please keep in mind that all data tools are effectively fungible if you can assume an infinite amount of time, money, and engineering skill. You can run production off an Excel spreadsheet if you have to, and some SREs have done so . That doesn‚Äôt make it a great solution, the right use of resources, or accessible to the median engineering org. The good news is that AI has changed this . The technology we have now is good enough to create a feedback loop between developers and production systems for the median engineering team, for the first time ever. The bad news is also that AI has changed this . Our existing feedback loops are unprepared to deal with the current amount of code slop. And I", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Kip: A programming language based on grammatical cases of Turkish", "url": "https://github.com/kip-dili/kip", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . A programming language in Turkish where grammatical case and mood are part of the type system. There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . Kip (meaning \"grammatical mood\" in Turkish) is an experimental programming language that uses Turkish grammatical cases as part of its type system. It demonstrates how natural language morphology‚Äîspecifically Turkish noun cases and vowel harmony‚Äîcan be integrated into programming language design. This is a research/educational project exploring the intersection of linguistics and type theory, not a production programming language. There is also a tutorial in Turkish and a tutorial in English that explains how to write Kip programs. Note Kip is experimental. Expect changes in syntax and behavior over time. For you to get a taste of what Kip looks like, here is an example program that prompts the user to enter a number and then prints that many of the Fibonacci numbers: Kip uses Turkish noun cases (ismin halleri) to determine argument relationships in function calls: Because Turkish cases mark grammatical relationships explicitly, Kip allows flexible argument ordering. These two calls are equivalent: As long as arguments have different case suffixes or different types, Kip can determine which argument is which. Define algebraic data types with Turkish syntax: Type variables are supported for generic data structures: Pattern match using the conditional suffix -sa/-se : Supports nested pattern matching, binders, and wildcard patterns ( deƒüilse ): Define named constants with diyelim : Sequencing with -ip/-ƒ±p/-up/-√ºp suffixes and binding with olarak : Integers ( tam-sayƒ± ): Strings ( dizge ): I/O: Foma - finite-state morphology toolkit Stack - Haskell build tool Tip If you only want to explore the language, you can start with stack exec", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Amazon is ending all inventory commingling as of March 31, 2026", "url": "https://twitter.com/ghhughes/status/2012824754319753456", "content": "Amazon is ending all inventory commingling as of March 31, 2026. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Cows can use sophisticated tools", "url": "https://nautil.us/the-far-side-had-it-all-wrong-cows-really-can-use-sophisticated-tools-1262026/", "content": "Art+Science Biology + Beyond Catalysts of Discovery Cosmos Culture Currents Earth Life Mind Ocean One Question Quanta Abstractions Rewilding Science at the Ballot Box Science Philanthropy Alliance Spark of Science The Animal Issue The Climates Issue The Food Issue The Kinship Issue The Porthole The Reality Issue The Rebel Issue Women in Science & Engineering Upending Gary Larson‚Äôs premise that cows are too daft to use tools Upending Gary Larson‚Äôs premise that cows are too daft to use tools The full Nautilus archive ‚Ä¢ eBooks & Special Editions ‚Ä¢ Ad-free reading I f cows could use tools, imagine the scenes that might unfold: cutting wires to escape from their pastures; extracting themselves from milking machines; or removing the twine on hay bales. Cows haven‚Äôt been seen doing any of these things, of course. But a study published today in Current Biology demonstrates a cow named Veronika effectively using a deck broom as a scratching tool, satisfying the scientific definition of tool use as ‚Äúthe manipulation of an external object to achieve a goal via a mechanical interface.‚Äù Veronika is a pet Brown Swiss cow ( Bos taurus ) kept as a companion by a farmer. In a series of 10 trials, researchers from the University of Veterinary Medicine Vienna presented her with a deck broom tossed on the ground in a random orientation. Each trial, they recorded which end of the brush she selected and how she used it. Veronika manipulated the broom with her mouth, positioning it under her tongue, then wedging it into the gaps between her incisors and molars for a stable grip. Veronika adeptly used the deck brush to scratch her itches, manipulating it to target different areas. Across the randomized trials, she chose the bristled end to scratch her hindquarters but switched to the stick end for softer lower-body areas. Across repeat trials, she made consistent choices about how to wield the broom. ‚ÄúWhen I saw the footage, it was¬†immediately¬†clear that this was not accidental,‚Äù said¬†stud", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "SIMD Programming in Pure Rust", "url": "https://kerkour.com/introduction-rust-simd", "content": "SIMD Programming in Pure Rust. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "A rationalist's guide to manifestation. Or, how to live a magical life", "url": "https://read.isabelunraveled.com/p/manifest-rationally", "content": "I‚Äôve been helping my hyper-rational clients and peers manifest what they want for a number of years now, and I finally feel ready to articulate how this process works in the most logical, straight-forward terms possible. My goal is that this essay makes ‚Äòmanifestation‚Äô make sense to anyone, and to explain it in a way that feels approachable for you, dear reader, to begin doing, today (and what better day to begin than the first day of a new year?). All I ask is that you set aside your priors associated to the word ‚Äòmanifestation‚Äô before we begin, and open your mind to the possibility that you really could get the things that you want much more effortlessly‚Äîand perhaps even magically‚Äîthan you‚Äôve let yourself believe before. What you will see from reading this is that while there is some whimsy to this art, there is also a lot you can influence consciously when you actually understand how your mind works. That‚Äôs right: you‚Äôll get to use your agency as well as your third eye, I promise. Now let‚Äôs begin. The first thing I‚Äôve learned is that despite the controversial reputation of the word ‚Äòmanifestation‚Äô, the process it refers to is actually incredibly logical, and when the rational mind comprehends the effectiveness of simply aligning your mind towards what you want , it becomes much more willing to do so. The second is that once you understand the basic mechanics of manifestation, you become a weapon at rapidly up-levelling your life . I‚Äôll start with some friendly, approachable examples for how I think about manifestation in my life‚Äîwhich is, broadly speaking, that I think of it as cleaning up your inner world, identifying what you truly want and giving yourself full permission to pursue and receive it, effortlessly . Also, to embrace the part of it that really does feel like magic‚Äîwhich often looks like being given, offered, or invited to almost eerily aligned opportunities and moments that you have previously held in your mind‚Äôs eye . If you want more whimsical & m", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Mammals have evolved into ant eaters 12 times since the dinosaur age ‚Äì study (2025)", "url": "https://phys.org/news/2025-07-mammals-evolved-ant-eaters-dinosaur.html", "content": "Sign in with Forget Password? Learn more share this! 502 Tweet Share Email July 16, 2025 by Jesse Jenkins, New Jersey Institute of Technology edited by Stephanie Baum , \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\treviewed by Andrew Zinin   This article has been reviewed according to Science¬†X's editorial process and policies . Editors have highlighted\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tthe following attributes while ensuring the content's credibility: fact-checked peer-reviewed publication trusted source proofread Mammals have developed some unusual eating habits over the past 100 million years, but a new study has uncovered the surprising lengths to which some have gone to satisfy one of the more peculiar‚Äîa taste for ants and termites. Findings published in Evolution reveal that mammals independently evolved specialized adaptations for exclusively feeding on ants and termites at least 12 times since the Cenozoic era began, roughly 66 million years ago. Researchers say the convergent evolution among mammals toward this dietary strategy‚Äîcalled myrmecophagy‚Äîemerged following the K-Pg extinction and fall of non-avian dinosaurs, which reshaped ecosystems and set the stage for ant and termite colonies to rapidly expand worldwide, driving extreme shifts in feeding modes for certain species. \"There's not been an investigation into how this dramatic diet evolved across all known mammal species until now,\" said Phillip Barden, the study's corresponding author and associate professor of biology at New Jersey Institute of Technology (NJIT). \"This work gives us the first real roadmap, and what really stands out is just how powerful a selective force ants and termites have been over the last 50 million years‚Äîshaping environments and literally changing the face of entire species.\" Over 200 mammal species are known to eat ants and termites today, yet only about 20 true myrmecophages‚Äîsuch as giant anteaters, aardvarks and pangolins‚Äîhave evolved traits like long sticky tongues, specialized claws and stomachs, and reduced o", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "There is no comfortable reading position", "url": "https://slate.com/life/2026/01/body-books-reading-position-posture-pain.html", "content": "Enter your email to receive alerts for this author. Sign in or create an account to better manage your email preferences. Are you sure you want to unsubscribe from email alerts for Luke Winkie ? Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily. For the 10 th year in a row, my New Year‚Äôs resolution is to read more books. Ideally, as I tend to tell myself during these protean early weeks of January, 2026 will be remembered for languorous evenings on the couch, tearing through the inventory of novels that crowd the modest capacity of my living-room shelves, perhaps with a tumbler of scotch resting on a coaster. I revel in the fantasy‚ÄîI dream about finally cracking open A Confederacy of Dunces, or knocking out the last two entries of the Broken Earth trilogy, or making time for that Patti Smith memoir that I bought more than a decade ago. If I‚Äôm really feeling myself, I contemplate aiming even higher. Tolstoy? Pynchon? I mean, there‚Äôs also that copy of The Pale King that has been steadily yellowing on my coffee table for quite some time now. And yet, I already know how this saga is going to end. The year will draw to a close with a piddling number of new entries to my Goodreads, hopelessly incongruous with the size of my bibliophilic ambitions. Ask me why I never seem to read as much as I like, and I could gesture toward the well-worn afflictions of modernity‚Äîballooning screen time, addictive algorithms, frayed attention spans. But one of my fundamental issues with literature is far more prosaic. In fact, I think it‚Äôs much more common than anyone would like to admit. Why is it that no matter what I do, I can never get comfortable while reading a book? Don‚Äôt act like you don‚Äôt know what I‚Äôm talking about. This is a species-wide affliction. The first published novel in history is widely considered to be The Tale of Genji, a courtly drama written in the late 11 th century by the Japanese noblewoman", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Clipboard overflows causing system crashes in macOS Tahoe 26.3 beta 2?", "url": "item?id=46693038", "content": "Ask HN: Clipboard overflows causing system crashes in macOS Tahoe 26.3 beta 2?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "EU Parliament freezes US trade deal ratification", "url": "https://www.lemonde.fr/en/international/article/2026/01/20/eu-parliament-freezes-us-trade-deal-after-trump-s-tariff-threats-over-greenland_6749625_4.html", "content": "Date: Loading date... Time: Loading time... Le Monde with AFP 1 min read EU lawmakers have agreed to hold off on ratifying a key trade deal with the United States following President Donald Trump's tariff threats over Greenland, the main political groups said on Tuesday, January 20. The warning shot from the European Parliament comes as the 27-nation bloc weighs how hard to hit back if Trump follows through against Washington's long-standing allies. The Parliament was planning a vote in the coming weeks on removing tariffs on US industrial goods as part of the agreement. A delay does not sink the deal, agreed in July with Trump after months of intense wrangling that saw Washington slap 15% tariffs on EU goods. But by suspending approval, it does send a strong message of discontent to the White House that EU lawmakers argued would unnerve American businesses. \"It is an extremely powerful lever ‚Äì I don't think companies would agree to give up the European market,\" Valerie Hayer, president of the centrist Renew group, told journalists. Trump has threatened to hit six EU countries ‚Äì including powerhouses France and Germany ‚Äì with tariffs for not going along with his demand to get Greenland. EU leaders are set to hold an emergency summit in Brussels on Thursday evening over the US threats against Denmark's autonomous territory, Greenland. The bloc is weighing different responses if Trump does not back down, including putting last year's trade deal on hold and hitting the US with ‚Ç¨93 billion in tariffs. The package of retaliatory tariffs was agreed at the height of the EU-US trade standoff last year, but was ultimately suspended until February 6 to avoid an all-out trade war. Beyond that, French President Emmanuel Macron is pushing to unleash the bloc's potent anti-coercion trade instrument to use in case Trump makes good on his threats. Le Monde with AFP Lecture du Monde en cours sur un autre appareil. Vous pouvez lire Le Monde sur un seul appareil √† la fois Ce message s", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Should you combine your personal website and blog or keep them separate?", "url": "item?id=46695579", "content": "Ask HN: Should you combine your personal website and blog or keep them separate?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Profession by Isaac Asimov (1957)", "url": "https://www.abelard.org/asimov.php", "content": "Profession , \r\n        copyright ¬©1957 by Street and Smith Publications, Inc., from ISAAC \r\n        ASIMOV: THE COMPLETE STORIES OF VOL. 1 by Isaac Asimov. Used by permission of Doubleday, a division of Random House, Inc. For on-line information about other Random \r\n        House, Inc. books and authors, see the Internet Web site at http://www.randomhouse.com . Another \r\n        sci-fi short story at abelard.org: And Then There \r\n        Were None by Eric Frank Russell G eorge Platen could not conceal the longing in his voice. It was \r\n        too much to suppress. He said, ‚ÄúTomorrow‚Äôs 1 May. Olympics!‚Äù He rolled over on his stomach and peered over the foot of his bed at his \r\n        roommate. Didn‚Äôt he feel it, too? Didn‚Äôt this make some impression \r\n        on him? George‚Äôs face was thin and had grown a trifle thinner in the nearly \r\n        year and a half that he had been at the House. His figure was slight but the \r\n        look in his blue eyes was as intense as it had ever been, and right now there \r\n        was a trapped look in the way his fingers curled against the bedspread. George‚Äôs roommate looked up briefly from his book and took the opportunity \r\n        to adjust the light-level of the stretch of wall near his chair. His name \r\n        was Hali Omani and he was a Nigerian by birth. His dark brown skin and massive \r\n        features seemed made for calmness, and mention of the Olympics did not move \r\n        him. ‚ÄúI know, George.‚Äù George owed much to Hali‚Äôs patience and kindness when it was needed, \r\n        but even patience and kindness could be overdone. Was this a time to sit there like a statue built of some dark, warm wood? George wondered if he himself would grow like that after ten years here and \r\n        rejected the thought violently. No! He said defiantly, ‚ÄúI think you‚Äôve forgotten what May means.‚Äù The other said,‚ÄúI remember very well what it means. It means nothing! \r\n        You‚Äôre the one who‚Äôs forgotten that. May means nothing to you,", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "The 600-year-old origins of the word 'hello'", "url": "https://www.bbc.com/culture/article/20260113-hello-hiya-aloha-what-our-greetings-reveal", "content": "It's been 200 years since the word \"hello\" was first used in print ‚Äì though its beginnings date back to the 15th Century. How has the language of greetings evolved around the world - and what does it tell us about ourselves? We use \"hello\" dozens of times a day without thinking ‚Äì during phone calls, emails and face-to-face encounters. We sing it along with Adele and Lionel Richie, and we have watched it spun into moments of screen gold in Jerry Maguire (\"You had me at hello\"), and Scarface (\"Say hello to my little friend!\"). It's been used to sell everything from mobile phones (Motorola's \"Hello, Moto\") to lingerie (Wonderbra's iconic \"Hello boys\"), and it has been borrowed to name computer programs and celebrity magazines. In print, this ubiquitous, friendly greeting has a surprisingly short history. Two centuries ago, on 18 January 1826, \"hello\" made what is thought to be its earliest recorded appearance on the page, in a Connecticut newspaper called The Norwich Courier. Hidden among the column inches, it was a modest in-ink debut for a word that would go on to greet much of the modern world. By the 1850s, it had crossed the Atlantic to Britain ‚Äì appearing in publications such as the London Literary Gazette ‚Äì and became increasingly common in print. Like the go-to greetings in other languages, \"hello\" also says something about the English-speaking world ‚Äì depending on which variation, abbreviation or inflection of the word we choose to use. There are plenty of such forms. Whether due to dialect or accent influences, or the brevity demanded by online communication, which \"hello\" you choose says a lot about you, and can indicate age, nationality, or even mood. According to linguists, elongated variations such as \"heyyy\" could be construed as flirtatious, \"hellaw\" might suggest you're from the southern US, \"howdy\" from western US, and the clipped \"hi\" may indicate a curt disposition. \"It can be pronounced and inflected in many different ways, and these subtle intonat", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Optimizing GPU Programs from Java Using Babylon and Hat", "url": "https://openjdk.org/projects/babylon/articles/hat-matmul/hat-matmul", "content": "The project Babylon is a new OpenJDK project with the goal of enhancing Java reflection, allowing to reflect code from Java methods and Java lambdas, and being able to query their symbolic representation, called code models. These code models can be used at runtime to modify the code, perform optimizations, and/or perform code transformations to other programming models. Furthermore, code reflection allows Java developers to interact with foreign programming models and foreign programming languages without using any 3rd party libraries. One of the foreign programming environments we are exploring in the project Babylon is the GPU environment through the CUDA and OpenCL programming models, called HAT ( Heterogeneous Accelerator Toolkit). The goal for HAT is to be able to offload and run efficient parallel workloads on hardware accelerators. Through this article, we want to tackle these two questions: Each of these questions presents its own set of challenges. The majority of the projects focus on the first challenge with projects such as Sumatra , Aparapi , Marawacc , RootBeer , JaBEE , IBM J9 , and more recently TornadoVM . These projects have focused on abstracting GPU programmability and make it easier for Java developers. While they achieve reasonable high performance ( e.g., TornadoVM√¢¬Ä¬ôs study ) by leveraging specialized accelerators, they often do so at the cost of hindering access to advanced GPU optimizations. However, in the era of AI and high-demand computing, simply being faster than Java on CPUs might not be enough. The second question goes a step further and rethink about how Java programmers could approach native performance on hardware accelerators while still maintaining reasonable high-level constructs. This is a very thin line between what to expose from low-level APIs and from what level of the native software stack. The HAT project tackles GPU programming from a perspective of a performance engineer wanting to efficiently interconnect the Java so", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Predicting OpenAI's ad strategy", "url": "https://ossa-ma.github.io/blog/openads", "content": "Jan 18, 2026 9 min read The World is Ads credit La Haine + Gemini Here we go again, the tech press is having another AI doom cycle. I've primarily written this as a response to an NYT analyst painting a completely unsubstantiated, baseless, speculative, outrageous, EGREGIOUS, preposterous \"grim picture\" on OpenAI going bust . Mate come on. OpenAI is not dying, they're not running out of money. Yes, they're creating possibly the craziest circular economy and defying every economics law since Adam Smith published 'The Wealth of Nations'. $1T in commitments is genuinely insane. But I doubt they're looking to be acquired; honestly by who? you don't raise $40 BILLION at $260 BILLION VALUATION to get acquired. It's all for the $1T IPO. But it seems that the pinnacle of human intelligence: the greatest, smartest, brightest minds have all come together to... build us another ad engine. What happened to superintelligence and AGI? See if OpenAI was not a direct threat to the current ad giants would Google be advertising Gemini every chance they get? Don't forget they're also capitalising on their brand new high-intent ad funnel by launching ads on Gemini and AI overview . Let's crunch the numbers. March: Closed $40B funding round at $260B valuation , the largest raise by a private tech company on record. June: Hit $10B ARR . July: First $1B revenue month , doubled from $500M monthly in January. November: Sam Altman says OpenAI expects $20B ARR for 2025 . Reached 800M WAU , ~190M DAU , 35M paying subscribers , 1M business customers . January 2026: \"Both our Weekly Active User (WAU) and Daily Active User (DAU) figures continue to produce all-time-highs (Jan 14 was the highest, Jan 13 was the second highest, etc.)\" January 16, 2026: Announced ads in ChatGPT free and Go tiers. Yes, OpenAI is burning $8-12B in 2025 .\nCompute infrastructure is obviously not cheap when serving 190M people daily. So let's try to model their expected ARPU (annual revenue per user) by understanding wha", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: How would you design for this scale today?", "url": "item?id=46686023", "content": "Ask HN: How would you design for this scale today?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Stirling Cycle Machine Analysis", "url": "https://ohioopen.library.ohio.edu/opentextbooks/9/", "content": "Home > OPENTEXTBOOKS > 9 Israel Urieli , Ohio University Russ College of Engineering and Technology Download Full Text (61.8¬†MB) Download Stirling Engine Analysis m-files for MATLAB (33¬†KB) Download Biographical Memoir of William Beale (3.0¬†MB) Dedicated to William T. Beale (1928 - 2016), inventor of the Free Piston Stirling Engine, Mentor and Frien. This web resource is intended to be totally self contained learning resource for the analysis and development of computer simulation of single phase, piston/cylinder Stirling cycle machines. It includes thermodynamic, heat transfer and fluid flow friction analysis, and until 2012 it was used as resource material for an advanced course for Mechanical Engineering majors. The course structure was based on the book by I.Urieli & D.M.Berchowitz 'Stirling Cycle Engine Analysis' (Adam Hilger, 1984). The computer simulation program modules (originally written in FORTRAN) have all been updated and rewritten in MATLAB, a convenient interactive language which allows direct graphical output - essential for Stirling cycle analysis. A complete set of all the m-files are developed and provided, and they can be augmented and adapted as needed for specific engine/refrigerator configurations. It is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license and as such is freely available. Comments and constructive criticism are welcomed by the author. Chapter 1: Background and Introduction Chapter 2: Basic Engine Configurations Chapter 3: Ideal Isothermal Analysis We define and analyze the Ideal Isothermal model of a Stirling engine, including the Schmidt Analysis, and discuss its limitations. One obviously incorrect conclusion of this analysis is that all three heat exchangers are redundant, and only contribute dead space, since all required heat transfer processes occur in the isothermal compression and expansion spaces. Nevertheless we can obtain a better understanding of a specific design, partic", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Supply Chain Vuln Compromised Core AWS GitHub Repos & Threatened the AWS Console", "url": "https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild", "content": "Wiz Research discovered a critical supply chain vulnerability that abused a CodeBuild misconfiguration to take over key AWS GitHub repositories - including the JavaScript SDK powering the AWS Console. Wiz Research uncovered CodeBreach , a critical vulnerability that placed the AWS Console supply chain at risk. The issue allowed a complete takeover of key AWS GitHub repositories - most notably the AWS JavaScript SDK, a core library that powers the AWS Console . By exploiting CodeBreach, attackers could have injected malicious code to launch a platform-wide compromise, potentially affecting not just the countless applications depending on the SDK, but the Console itself, threatening every AWS account . The vulnerability stemmed from a subtle flaw in how the repositories‚Äô AWS CodeBuild CI pipelines handled build triggers. Just two missing characters in a Regex filter allowed unauthenticated attackers to infiltrate the build environment and leak privileged credentials. This post breaks down how we leveraged this subtle misconfiguration to achieve a full repository takeover, and provides key recommendations for CodeBuild users to harden their own projects against similar attacks. Wiz responsibly disclosed all findings to AWS, who promptly remediated the issue. AWS also implemented global hardening measures within the CodeBuild service to prevent similar attacks. Most notably, the new Pull Request Comment Approval build gate offers organizations a simple and secure path to prevent untrusted builds. Read the AWS Advisory here . This issue follows a familiar pattern seen in recent supply-chain attacks like the Nx S1ngularity incident, where subtle CI/CD misconfigurations lead to disproportionately impactful attacks. Just last July, a threat actor abused a similar CodeBuild issue to launch a supply chain attack against users of the Amazon Q VS Code extension. This growing trend underscores the urgent need for organizations to harden their CI/CD pipelines. January 16, 2025 up", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Erdos 281 solved with ChatGPT 5.2 Pro", "url": "https://twitter.com/neelsomani/status/2012695714187325745", "content": "Erdos 281 solved with ChatGPT 5.2 Pro. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Briar keeps Iran connected via Bluetooth and Wi-Fi when the internet goes dark", "url": "https://briarproject.org/manual/fa/", "content": "Briar √õ¬å√ö¬© √ò¬®√ò¬±√ô¬Ü√ò¬ß√ô¬Ö√ô¬á √ô¬æ√õ¬å√ò¬ß√ô¬Ö √ò¬±√ò¬≥√ò¬ß√ô¬Ü √ô¬Ö√õ¬å √ò¬®√ò¬ß√ò¬¥√ò¬Ø √ö¬©√ô¬á √ò¬®√ò¬±√ò¬ß√õ¬å √ô¬Å√ò¬π√ò¬ß√ô¬Ñ√ò¬ß√ô¬Ü√ò¬å √ò¬±√ô¬à√ò¬≤√ô¬Ü√ò¬ß√ô¬Ö√ô¬á √ô¬Ü√ö¬Ø√ò¬ß√ò¬±√ò¬ß√ô¬Ü √ô¬à √ô¬á√ò¬± √ö¬©√ò¬≥√õ¬å √ö¬©√ô¬á √ô¬Ü√õ¬å√ò¬ß√ò¬≤√ô¬Ö√ô¬Ü√ò¬Ø √õ¬å√ö¬© √ò¬±√ò¬ß√ô¬á √ò¬ß√ô¬Ö√ô¬Ü√ò¬å √ò¬±√ò¬ß√ò¬≠√ò¬™ √ô¬à √ô¬æ√õ¬å√ò¬¥√ò¬±√ô¬Å√ò¬™√ô¬á √ò¬®√ò¬±√ò¬ß√õ¬å √ò¬ß√ò¬±√ò¬™√ò¬®√ò¬ß√ò¬∑ √ò¬®√ò¬ß √ò¬Ø√õ¬å√ö¬Ø√ò¬±√ò¬ß√ô¬Ü √ò¬ß√ò¬≥√ò¬™ √ô¬Ö√õ¬å √ò¬®√ò¬ß√ò¬¥√ò¬Ø. √ò¬®√ò¬±√ò¬Æ√ô¬Ñ√ò¬ß√ô¬Å √ò¬®√ò¬±√ô¬Ü√ò¬ß√ô¬Ö√ô¬á√¢¬Ä¬å √ô¬á√ò¬ß√õ¬å √ô¬æ√õ¬å√ò¬ß√ô¬Ö√¢¬Ä¬å√ò¬±√ò¬≥√ò¬ß√ô¬Ü√¢¬Ä¬å √ô¬Ö√ò¬±√ò¬≥√ô¬à√ô¬Ö√ò¬å Briar √ò¬®√ô¬á √ò¬≥√ò¬±√ô¬à√ò¬± √ô¬Ö√ò¬™√ô¬Ö√ò¬±√ö¬©√ò¬≤ √ò¬ß√ò¬™√ö¬©√ò¬ß √ô¬Ü√ò¬Ø√ò¬ß√ò¬±√ò¬Ø - √ô¬æ√õ¬å√ò¬ß√ô¬Ö √ô¬á√ò¬ß √ò¬®√ô¬á √ò¬µ√ô¬à√ò¬±√ò¬™ √ô¬Ö√ò¬≥√ò¬™√ô¬Ç√õ¬å√ô¬Ö √ò¬®√õ¬å√ô¬Ü √ò¬Ø√ò¬≥√ò¬™√ö¬Ø√ò¬ß√ô¬á √ö¬©√ò¬ß√ò¬±√ò¬®√ò¬±√ò¬ß√ô¬Ü √ô¬á√ô¬Ö√ö¬Ø√ò¬ß√ô¬Ö √ô¬Ö√õ¬å √ò¬¥√ô¬à√ò¬Ø. √ò¬ß√ö¬Ø√ò¬± √ò¬ß√õ¬å√ô¬Ü√ò¬™√ò¬±√ô¬Ü√ò¬™ √ö¬©√ò¬ß√ò¬± √ô¬Ü√ö¬©√ô¬Ü√ò¬Ø√ò¬å Briar √ô¬Ö√õ¬å√¢¬Ä¬å√ò¬™√ô¬à√ò¬ß√ô¬Ü√ò¬Ø √ò¬ß√ò¬≤ √ò¬∑√ò¬±√õ¬å√ô¬Ç √ò¬®√ô¬Ñ√ô¬à√ò¬™√ô¬à√ò¬´ √õ¬å√ò¬ß √ô¬à√ò¬ß√õ¬å√¢¬Ä¬å-√ô¬Å√ò¬ß√õ¬å √ô¬á√ô¬Ö√ö¬Ø√ò¬ß√ô¬Ö √ò¬≥√ò¬ß√ò¬≤√õ¬å √ö¬©√ò¬±√ò¬Ø√ô¬á√ò¬å √ò¬¨√ò¬±√õ¬å√ò¬ß√ô¬Ü √ò¬ß√ò¬∑√ô¬Ñ√ò¬ß√ò¬π√ò¬ß√ò¬™ √ò¬±√ò¬ß √ò¬Ø√ò¬± √ò¬≤√ô¬Ö√ò¬ß√ô¬Ü √ò¬®√ò¬≠√ò¬±√ò¬ß√ô¬Ü √ô¬Ü√ö¬Ø√ô¬á √ò¬Ø√ò¬ß√ò¬±√ò¬Ø. √ò¬ß√ö¬Ø√ò¬± √ò¬ß√õ¬å√ô¬Ü√ò¬™√ò¬±√ô¬Ü√ò¬™ √ö¬©√ò¬ß√ò¬± √ö¬©√ô¬Ü√ò¬Ø√ò¬å Briar √ô¬Ö√õ¬å√¢¬Ä¬å√ò¬™√ô¬à√ò¬ß√ô¬Ü√ò¬Ø √ò¬®√ò¬±√ò¬ß√õ¬å √ô¬Ö√ò¬≠√ò¬ß√ô¬Å√ò¬∏√ò¬™ √ö¬©√ò¬ß√ò¬±√ò¬®√ò¬±√ò¬ß√ô¬Ü √ô¬à √ô¬à√ò¬ß√ò¬®√ò¬∑ √ò¬¢√ô¬Ü √ô¬á√ò¬ß √ò¬ß√ò¬≤ √ò¬ß√ò¬≤ √ò¬¥√ô¬Ü√ô¬à√ò¬Ø√ò¬å √ò¬ß√ò¬≤ √ò¬∑√ò¬±√õ¬å√ô¬Ç √ò¬¥√ò¬®√ö¬©√ô¬á √ò¬™√ô¬à√ò¬± √ô¬á√ô¬Ö√ö¬Ø√ò¬ß√ô¬Ö √ò¬≥√ò¬ß√ò¬≤√õ¬å √ö¬©√ô¬Ü√ò¬Ø. √ò¬®√ò¬±√ò¬ß√õ¬å√ò¬± √ò¬±√ô¬à√õ¬å Google Play √ò¬®√ò¬±√ò¬ß√õ¬å √ò¬Ø√ò¬≥√ò¬™√ö¬Ø√ò¬ß√ô¬á √ô¬á√ò¬ß√õ¬å √ò¬ß√ô¬Ü√ò¬Ø√ò¬±√ô¬à√õ¬å√ò¬Ø √ô¬Ö√ô¬à√ò¬¨√ô¬à√ò¬Ø √ô¬Ö√õ¬å √ò¬®√ò¬ß√ò¬¥√ò¬Ø. √ô¬Ü√ö¬©√ò¬™√ô¬á: √ò¬ß√ö¬Ø√ò¬± √ô¬Ö√ò¬∑√ô¬Ö√ò¬¶√ô¬Ü √ô¬Ü√õ¬å√ò¬≥√ò¬™√õ¬å√ò¬Ø √ö¬©√ô¬á √ò¬Ø√ò¬≥√ò¬™√ö¬Ø√ò¬ß√ô¬á √ò¬¥√ô¬Ö√ò¬ß √ò¬ß√ô¬Ü√ò¬Ø√ò¬±√ô¬à√õ¬å√ò¬Ø √ô¬Ö√õ¬å √ò¬®√ò¬ß√ò¬¥√ò¬Ø√ò¬å √ô¬à√ò¬¨√ô¬à√ò¬Ø √ò¬®√ò¬±√ô¬Ü√ò¬ß√ô¬Ö√ô¬á √ô¬æ√ô¬Ñ√õ¬å √ò¬ß√ò¬≥√ò¬™√ô¬à√ò¬± √õ¬å√ò¬ß Play Store √ò¬±√ò¬ß √ò¬®√ò¬±√ò¬±√ò¬≥√õ¬å √ö¬©√ô¬Ü√õ¬å√ò¬Ø. √ò¬Ø√ò¬± √ò¬µ√ô¬à√ò¬±√ò¬™ √ô¬à√ò¬¨√ô¬à√ò¬Ø√ò¬å √ò¬Ø√ò¬≥√ò¬™√ö¬Ø√ò¬ß√ô¬á √ò¬¥√ô¬Ö√ò¬ß √ò¬ß√ô¬Ü√ò¬Ø√ò¬±√ô¬à√õ¬å√ò¬Ø √ô¬Ö√õ¬å √ò¬®√ò¬ß√ò¬¥√ò¬Ø. √ò¬ß√ö¬Ø√ò¬± √õ¬å√ö¬© √ò¬Ø√ò¬≥√ò¬™√ö¬Ø√ò¬ß√ô¬á √ò¬ß√ô¬Ü√ò¬Ø√ò¬±√ô¬à√õ¬å√ò¬Ø √ò¬Ø√ò¬ß√ò¬±√õ¬å√ò¬Ø √ò¬ß√ô¬Ö√ò¬ß √ò¬™√ò¬±√ò¬¨√õ¬å√ò¬≠ √ô¬Ö√õ¬å√¢¬Ä¬å√ò¬Ø√ô¬á√õ¬å√ò¬Ø √ö¬©√ô¬á √ò¬ß√ò¬≤ √ö¬Ø√ô¬à√ö¬Ø√ô¬Ñ √ô¬æ√ô¬Ñ√õ¬å √ò¬ß√ò¬≥√ò¬™√ô¬Å√ò¬ß√ò¬Ø√ô¬á √ô¬Ü√ö¬©√ô¬Ü√õ¬å√ò¬Ø√ò¬å √ô¬à√ò¬®√¢¬Ä¬å √ò¬≥√ò¬ß√õ¬å√ò¬™ Briar √ò¬±√ò¬ß√ô¬á√ô¬Ü√ô¬Ö√ò¬ß√õ¬å√õ¬å √ô¬á√ò¬ß√õ¬å √ô¬Ñ√ò¬ß√ò¬≤√ô¬Ö √ò¬®√ò¬±√ò¬ß√õ¬å √ô¬Ü√ò¬µ√ò¬® √ò¬®√ò¬±√ô¬Ü√ò¬ß√ô¬Ö√ô¬á √ò¬ß√ò¬≤ √ò¬∑√ò¬±√õ¬å√ô¬Ç F-Droid √õ¬å√ò¬ß √ò¬Ø√ò¬ß√ô¬Ü√ô¬Ñ√ô¬à√ò¬Ø √ô¬Ö√ò¬≥√ò¬™√ô¬Ç√õ¬å√ô √ò¬±√ò¬ß √ò¬Ø√ò¬ß√ò¬±√ò¬Ø.  √ô¬Ü√ò¬Æ√ò¬≥√ò¬™√õ¬å√ô¬Ü √ò¬®√ò¬ß√ò¬±√õ¬å √ö¬©√ô¬á Briar √ò¬±√ò¬ß √ò¬®√ò¬ß√ò¬≤ √ô¬Ö√õ¬å√¢¬Ä¬å√ö¬©√ô¬Ü√õ¬å√ò¬Ø√ò¬å √ò¬ß√ò¬≤ √ò¬¥√ô¬Ö√ò¬ß √ò¬Æ√ô¬à√ò¬ß√ò¬≥√ò¬™√ô¬á √ô¬Ö√õ¬å√¢¬Ä¬å√ò¬¥√ô¬à√ò¬Ø √õ¬å√ö¬© √ò¬≠√ò¬≥√ò¬ß√ò¬® √ö¬©√ò¬ß√ò¬±√ò¬®√ò¬±√õ¬å √ò¬ß√õ¬å√ò¬¨√ò¬ß√ò¬Ø √ö¬©√ô¬Ü√õ¬å√ò¬Ø. √ô¬Ö√õ¬å√¢¬Ä¬å√ò¬™√ô¬à√ò¬ß√ô¬Ü√õ¬å√ò¬Ø √ô¬á√ò¬± √ô¬Ü√ò¬ß√ô¬Ö √ô¬Ö√ò¬≥√ò¬™√ò¬π√ò¬ß√ò¬± √ô¬à √ö¬Ø√ò¬∞√ò¬±√ô¬à√ò¬ß√ö¬ò√ô¬á√¢¬Ä¬å √ò¬ß√õ¬å √ò¬±√ò¬ß √ò¬ß√ô¬Ü√ò¬™√ò¬Æ√ò¬ß√ò¬® √ö¬©√ô¬Ü√õ¬å√ò¬Ø. √ö¬Ø√ò¬∞√ò¬±√ô¬à√ò¬ß√ö¬ò√ô¬á √ò¬≠√ò¬Ø√ò¬ß√ô¬Ç√ô¬Ñ √ò¬®√ò¬ß√õ¬å√ò¬Ø √ò¬Ø√ò¬ß√ò¬±√ò¬ß√õ¬å 8 √ö¬©√ò¬ß√ò¬±√ò¬ß√ö¬©√ò¬™√ò¬± √ò¬®√ò¬ß√ò¬¥√ò¬Ø √ô¬à √ò¬≠√ò¬Ø√ò¬≥ √ò¬≤√ò¬Ø√ô¬Ü √ò¬¢√ô¬Ü √ò¬Ø√ò¬¥√ô¬à√ò¬ß√ò¬± √ò¬®√ò¬ß√ò¬¥√ò¬Ø. √ô¬á√ò¬¥√ò¬Ø√ò¬ß√ò¬±: √ò¬≠√ò¬≥√ò¬ß√ò¬® √ö¬©√ò¬ß√ò¬±√ò¬®√ò¬±√õ¬å Briar √ò¬¥√ô¬Ö√ò¬ß √ò¬®√ô¬á √ò¬µ√ô¬à√ò¬±√ò¬™ √ò¬ß√ô¬Ö√ô¬Ü √ò¬®√ò¬± √ò¬±√ô¬à√õ¬å √ò¬Ø√ò¬≥√ò¬™√ö¬Ø", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Ask HN: Would you trust a new browser security extension in 2025?", "url": "item?id=46692163", "content": "Ask HN: Would you trust a new browser security extension in 2025?. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: MicroState ‚Äì JavaScript City Builder", "url": "https://microstate.neocities.org", "content": "This is an early tech demo of the engine for MicroState and is not a finished game. Created for fun using HTML 2D Canvas and vanilla JavaScript by mastodon.social/@iaincollins Some features in this preview have better support for mouse and keyboard than for devices with touch\ninput. You can click and drag with the right mouse button to move around the map. You can also move the the map selecting the Move tool and dragging with the left mouse button. Two / three finger dragging and pinch-to-zoom is supported on devices with touch input. The mini map in the top right is interactive , it highights the are of the map you are viewing, you can\nclick on it to view to another part of the map. Zoom using the mouse wheel or the +/- buttons on the mini map. You c n also rotate your view from\nthe minimap . You can open the map using the √∞¬ü¬ó¬∫√Ø¬∏¬è Map button or by using the M key . √¢¬õ¬∞√Ø¬∏¬è Terrain You can place Parkland , Soil , Clay , Scrub , Paved , Sand , and Water tiles for terrain. You can √∞¬ü¬î¬º Raise , √∞¬ü¬î¬Ω Lower , √¢¬è¬¨ Flatten , and √∞¬ü¬í¬´ Smooth terrain by clicking and\ndragging using the relevant tools. Different terrain types support different types of trees and structures. Unlike many isometric games, terrain is not constrained to being fixed heights - but there are limits to how\nsteep it can be before you end up with a cliff! Hold the Control Key while placing terrain tiles to \"flood fill\" in an area between other terrain\ntiles, or between roads. Hold the Control Key when changing a terrain type under a road to change the terrain of connected\nroads. √∞¬ü¬ö¬¶ Roads You can place roads on any type of terrain except deep water - placing roads on shallower water\ncreates a bridge. Roads can't lean too much to the right or left, or have too steep a gradient. You use the √∞¬ü¬í¬´ Smooth tool to fix issues with the terrain. You can click to place a single stretch of road or click and drag to place a longer stretch of\nroad. You can draw bridges over water, but bridges can't have intersection", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Launch HN: Indy (YC S21) ‚Äì A support app designed for ADHD brains", "url": "https://www.shimmer.care/indy-redirect", "content": "Launch HN: Indy (YC S21) ‚Äì A support app designed for ADHD brains. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Netflix tells directors to repeat plot for people using phones, says Matt Damon", "url": "https://www.nme.com/news/film/netflix-tells-directors-to-repeat-plot-for-people-using-phones-while-watching-says-matt-damon-3924120", "content": "Damon and Ben Affleck praised 'Adolescence' for being the \"exception\" Matt Damon has claimed that Netflix pushes directors to reiterate the plot for viewers who are watching while on their phones. The actor has just released new action film The Rip on the streaming platform, which sees him reunite with frequent collaborator Ben Affleck . During an appearance on the Joe Rogan Experience podcast alongside his co-star, Damon spoke about collaborating with Netflix, saying they want bigger action earlier in such films, and push for the plot to be repeated to accommodate attention spans. ‚ÄúThe standard way to make an action movie that we learned was, you usually have three set pieces,‚Äù he said. ‚ÄúOne in the first act, one in the second, one in the third‚Ä¶ You spend most of your money on that one in the third act. That‚Äôs your finale.  ‚ÄúAnd now they‚Äôre like, ‚ÄòCan we get a big one in the first five minutes? We want people to stay tuned in. And it wouldn‚Äôt be terrible if you reiterated the plot three or four times in the dialogue because people are on their phones while they‚Äôre watching.‚Äô‚Äù Affleck went on to praise Netflix series Adolescence , which became a huge success last year, and the fact that it ‚Äúdidn‚Äôt do any of that shit‚Äù. ‚ÄúAnd it‚Äôs fucking great,‚Äù he added. ‚ÄúAnd it‚Äôs dark too. It‚Äôs tragic and intense. [It‚Äôs about] this guy who finds out his kid is accused of murder. There are long shots of the back of their heads. They get in the car, nobody says anything.‚Äù Damon said the series was ‚Äúso masterfully made that it feels like the exception‚Äù, his co-star suggesting it ‚Äúdemonstrates that you don‚Äôt need to do any of that shit‚Äù. Elsewhere in the interview, Damon suggested that some people who have been cancelled would prefer prison to being publicly shunned.  After Rogan argued that one perceived misstep is ‚Äúexaggerated to the fullest extent‚Äù and a person is ‚Äúcast out of civilisation for life‚Äù, Damon responded: ‚ÄúIn perpetuity. Because I bet some of those people would have pref", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "psc: The ps utility, with an eBPF twist and container context", "url": "https://github.com/loresuso/psc", "content": "We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . the ps utility, with an eBPF twist and container context There was an error while loading. Please reload this page . There was an error while loading. Please reload this page . psc (ps container) is a fast process scanner that uses eBPF iterators and Google CEL to query system state with precision and full container context. psc uses eBPF iterators to read process and file descriptor information directly from kernel data structures. This approach is: Traditional Linux tools like ps , lsof , and ss are powerful but inflexible. They output fixed formats that require extensive piping through grep , awk , and sed : psc uses the Common Expression Language (CEL) to filter processes. CEL expressions read almost like natural language, making your scripts self-documenting and maintainable. No more deciphering complex pipelines of grep | awk | sed | xargs . The -o flag lets you output exactly the fields you need, eliminating post-processing entirely: Output presets are also available to quickly print common information: Traditional tools have no concept of containers. Getting container information requires parsing cgroup paths, querying container runtimes, and correlating PIDs manually: psc extracts container context (ID, name, image, runtime, labels) automatically for Docker, containerd, CRI-O, and Podman. Debug any container's processes, files, and network connections directly from the host: On Debian/Ubuntu: On Fedora/RHEL: Or manually: psc requires root privileges to load eBPF programs. Pass a CEL expression as the first argument to filter processes: Understanding why a process exists often requires looking at its open file descriptors and network connections: Process fields ( process.X ): Capability fields ( process.capabilities.X ): Namespace fields ( process.namespaces.X ): Container fields ( container.X ): File/Socket fields ( file.X or socket.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Show HN: HTTP:COLON ‚Äì A quick HTTP header/directive inspector and reference", "url": "https://httpcolon.dev/", "content": "HTTP headers are a fundamental component of the HTTP protocol, which is the backbone of the internet. These headers contain important information about the request and response, such as content type, caching instructions, authentication tokens, and more. By understanding how to read and manipulate HTTP headers, developers can optimize their web applications for performance, security, and functionality. Moreover, HTTP headers play a critical role in API integrations, allowing developers to communicate with external services and systems. In short, HTTP headers are an essential tool in the web developer's arsenal, and any developer serious about building high-quality web applications should invest the time to learn and master them.", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Semiconductor Fabs III: Ion Implantation", "url": "https://nomagicpill.substack.com/p/ion-implantation", "content": "Ion implantation is a common process used in the semiconductor industry to change the properties of a material, namely silicon (the substrate). Physics, equipment used, process considerations, alternatives, and further resources are discussed. While I wrote this in 2020 and some advances have been made, the principles remain the same. First, why are ions shot into silicon (Si)? What does it do from a physics perspective? The reason has to do with the band gap , the energy difference between the valence band and conduction band. Within Si exist both electrons (negatively-charged) and electron holes (positively-charged). The hole is a bit of an oddity: it‚Äôs an unoccupied space where an electron could exist, but doesn‚Äôt at that moment. While not literally a particle, they can be treated and thought of as such. Current can be viewed as the flow of electrons or holes. When a bias is applied, electrons begin to move and occupy holes. When electron A moves to hole B, hole A is formed. This propagates and creates the flow of charge, or current. What does this have to do with Si? Si has four valence electrons in its four states of 3s 2 3p 2 . Those four valence electrons covalently bond with the surrounding Si crystal lattice structure, effectively filling that Si atom‚Äôs valence shell. So, when an ion is introduced into the lattice that does not have four valence electrons, one of two things happen: there are free electrons (if the number of valence electrons is >4, such as in phosphorus‚Äôs case) or free holes (valence electrons <4, such as boron). In the first case, four of phosphorus‚Äôs (P‚Äôs) electrons have bonded to surrounding Si atoms‚Äô valence electrons, leaving the fifth one free and able to contribute to current, making it a donor impurity, because it donates an electron. This creates an n(egative)-type semiconductor. In the second case, three of boron‚Äôs (B‚Äôs) electrons have bonded to surrounding Si atoms, but one Si atom and the B atom both have incomplete valence shel", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Shingles vaccine may help keep older people biologically younger", "url": "https://www.thetimes.com/uk/science/article/shingles-vaccine-news-bz55zstn5", "content": "Shingles vaccine may help keep older people biologically younger. Score: None. Author: None. Date: None", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Why Greenland's natural resources are nearly impossible to mine", "url": "https://theweek.com/world-news/greenland-natural-resources-impossible-mine", "content": "SUBSCRIBE & SAVE Less than $3 per week The country‚Äôs natural landscape makes the task extremely difficult President Donald Trump has renewed his efforts to take over Greenland, and tapping into the Danish territory‚Äôs natural resources is a key part of the strategy. But even if Trump were to somehow make Greenland a U.S. territory (something Denmark vehemently opposes), experts say the island‚Äôs harsh climate and environment make mining Greenland‚Äôs natural resources an unachievable goal. Greenland has significant supplies of rare earth elements. These 17 metals, with ‚Äúexotic-sounding names like terbium and neodymium, are vital for many everyday technologies,‚Äù said the BBC . Household items like televisions and smartphones would ‚Äúnot work without them.‚Äù Trump wants to tap into Greenland‚Äôs supply of rare earth minerals as part of an effort to overtake China, the country that currently ‚Äúcontrols the world‚Äôs supply,‚Äù said Tony Sage, the CEO of Critical Metals, to the BBC. But rare earth minerals are not Greenland‚Äôs only natural resource . Many ‚Äúoccurrences of graphite and graphite schist are reported from many localities on the island,‚Äù said Reuters . Other minerals commonly found in the territory include diamonds, gold, nickel, titanium, tungsten, zinc and more, according to Greenland‚Äôs Mineral Resources Authority. Escape your echo chamber. Get the facts behind the news, plus analysis from multiple perspectives. From our morning news briefing to a weekly Good News Newsletter, get the best of The Week delivered directly to your inbox. From our morning news briefing to a weekly Good News Newsletter, get the best of The Week delivered directly to your inbox. The island‚Äôs frigid, Arctic climate serves as the main culprit for challenging mining. Most of Greenland‚Äôs natural resources are ‚Äúlocated in remote areas above the Arctic Circle, where there is a mile-thick polar ice sheet and darkness reigns much of the year,‚Äù said CNN . While people may understandably think neighborin", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Raising money fucked me up", "url": "https://blog.yakkomajuri.com/blog/raising-money-fucked-me-up", "content": "January 15, 2026 About four months ago I quit my job at Doublepoint and decided to start my own thing. I'd been working on a little project with Pedrique (who would become my co-founder) for a bit over half-a-year and decided I had enough signal to determine he was someone I wanted to start a business with. I was excited about the idea we were working on at the time (we were live with paying customers and truly believed in the thesis), but in hindsight, being truly honest about my motivations, I mostly wanted to run my own thing. In a dream world I'd have had the \"idea of my life\" while working at PostHog or Doublepoint and have gone on to build that with maximum conviction but this wasn't the case, so I got tired of waiting for a spark and decided to go out and make it happen, with the idea we were working on being our best bet at the time. Since I'd just quit my job, I had my finances well in order. Thus, my ideal scenario would have been to keep working on the product we had, try to scale it, and if that didn't work, try something else, then something else, until something did indeed really get off the ground, and only at that point we would consider whether or not to raise VC funding, depending on whether it made sense or not. My ideal scenario wasn't going to work for Pedrique, though. He had told me for a while that the money he had saved up for trying to build his own thing was running out and that soon he'd need to start freelancing or something to make some income in order to sustain the search for a little longer. Prior to us working together, he had a bit of success with his MicroSaaS products but only just enough to increase his personal runway, which was now reasonably short. We had spoken about this before, but with me now being 110% in, we had to do something about it. I had just come in full-time so we weren't about to go back to a dynamic where one person was full-time and the other part-time because they needed to make ends meet. The decision then", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Memdeklaro ‚Äì The humanitarian open source alternative to government ID", "url": "https://memdeklaro.computersforpeace.net", "content": "Memdeklaro is a philosophical project that empowers people to self-declare their own identity - without third parties such as birth parents, birth cultures or birth countries. Memdeklaro positions itself as a humanitarian alternative to the exclusionary state monopoly on identity and supports the three freedoms: freedom of name, freedom of belief and freedom of association. Memdeklaro supports a world where people are judged only on their character, beliefs and actions, not on where they were born, who they were born to, or what their birth culture was. A world where individuals have power over their own lives - the power to leave corrupt governments, hostile cultures and abusers, and thrive in a self-chosen community. \"Self-declaration of identity gives people the power to decide their own fate, and creates a world where actions and beliefs matter more than arbitrary circumstances of birth.\" Millions of people worldwide have no access to government ID. Nation-states routinely refuse to issue birth certificates, national ID cards and passports to people, most often due to the circumstances of their birth, rather than due to their own actions as an adult. This group may include stateless people, refugees, people who weren‚Äôt registered at birth, and people who escaped from child abuse, domestic abuse or cult abuse. As government ID is increasingly required for employment, housing, healthcare, education, travel and daily life necessities, this leaves people at best on the edge of society or at worst criminalized for existing. In this situation, cash in hand jobs and informal apartment rentals are an essential lifeline, but as the state cracks down on the gray market economy, exclusion from the state monopoly on identity could mean life or death. \"You may think economic exclusion ‚Äî banned from employment, housing, healthcare, education, banking, travel, contracts, mail, sim cards and more ‚Äî would be a punishment for only the most severe of crimes. But for stateless peop", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Install.md: A standard for LLM-executable installation", "url": "https://www.mintlify.com/blog/install-md-standard-for-llm-executable-installation", "content": "Resources Explore Startups Built for fast-moving teams Enterprise Scalable for large organizations Switch Seamless migration tools Company Careers Join our growing team Wall of Love Customer testimonials Guides Guide to technical writing Documentation Guides Getting Started Deploy in minutes Components Customizable components library Developers API Reference Build integrations and custom workflows Changelog Learn what's new January 15, 2026 Michael Ryaboy Content Strategist Installing software is the kind of specific and repetitive task that agents are good at. Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras, Firecrawl, and Langchain. Proposal for a standard /install.md file that provides LLM-executable installation instructions. Agents are growing in capability faster than software developers have been able to keep up. Product documentation today is focused on humans instead of AI which creates friction when trying to automate annoying yak-shaving style tasks like installation. The difference is very subtle. Agents need to have a task iterated to them like \"I want you to install Mintlify CLI for me. Execute all the steps below autonomously.\" whereas humans can work from more general prose or even a bash script. Today we are proposing install.md to standardize how developers should write installation instructions for agents. It's currently live on all Mintlify sites including Cerebras , Firecrawl , and Langchain . Add an install.md markdown file to your project with LLM-executable installation instructions. Users paste that file into an LLM or pipe it directly from a URL. The LLM reads the instructions, detects the environment, adapts to the setup, and executes‚Äîoptionally with approval at every step. Because the file is human-readable, users see exactly what will happen before it runs. Instead of piping an executable file into bash with abs", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Canada's Prime Minister Mark Carney's Full Speech at Davos", "url": "https://www.cbc.ca/news/politics/mark-carney-speech-davos-rules-based-order-9.7053350", "content": "Below are Prime Minister Mark Carney's remarks at the World Economic Forum in Davos, Switzerland, on Tuesday. (In French): It's a pleasure ‚Äî and a duty ‚Äî to be with you at this turning point for Canada and for the world. Today, I'll talk about the rupture in the world order, the end of a nice story and the beginning of a brutal reality where geopolitics among the great powers is not subject to any constraints. But I also submit to you that other countries, particularly middle powers like Canada, are not powerless. They have the capacity to build a new order that embodies our values, like respect for human rights, sustainable development, solidarity, sovereignty and territorial integrity of states. The power of the less powerful begins with honesty. It seems that every day we're reminded that we live in an era of great power rivalry. That the rules-based order is fading. That the strong can do what they can, and the weak must suffer what they must. This aphorism of Thucydides is presented as inevitable ‚Äî as the natural logic of international relations reasserting itself. And faced with this logic, there is a strong tendency for countries to go along to get along. To accommodate. To avoid trouble. To hope that compliance will buy safety. It won't. So, what are our options? 'The old order is not coming back': PM says Canada must 'name reality' and build strength at home In 1978, the Czech dissident V√°clav Havel, later president, wrote an essay called The Power of the Powerless. And in it, he asked a simple question: How did the communist system sustain itself? And his answer began with a greengrocer. Every morning, this shopkeeper places a sign in his window: \"Workers of the world, unite!\" He doesn't believe it. No one does. But he places the sign anyway to avoid trouble, to signal compliance, to get along. And because every shopkeeper on every street does the same, the system persists. Not through violence alone, but through the participation of ordinary people in rit", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "OpenBSD-current now runs as guest under Apple Hypervisor", "url": "https://www.undeadly.org/cgi?action=article;sid=20260115203619", "content": "OpenBSD Journal Home Archives About Submit Story Create Account Login Contributed by Peter N. M. Hansteen on 2026-01-15 from the hyper-armed dept. The commits read List:       openbsd-cvs\r\nSubject:    CVS: cvs.openbsd.org: src\r\nFrom:       Helg Bredow <helg () cvs ! openbsd ! org>\r\nDate:       2026-01-12 18:15:33\r\n\r\n\r\nCVSROOT:\t/cvs\r\nModule name:\tsrc\r\nChanges by:\thelg@cvs.openbsd.org\t2026/01/12 11:15:33\r\n\r\nModified files:\r\n\tsys/dev/pv     : viogpu.c \r\n\r\nLog message:\r\nviogpu_wsmmap() returns a kva but instead should return a physical\r\naddress via bus_dmamem_mmap(9) . Without this, QEMU would only show a\r\nblack screen when starting X11. On the Apple Hypervisor, the kernel\r\nwould panic. Also add calls to bus_dmamap_sync(9) before transferring the framebuffer\r\nto host memory. It was working for me without this, but this ensures\r\nthat the host running on another CPU will see updates to the\r\nframebuffer.\r\n\r\nThanks to kettenis@ for reviewing and providing feedback.\r\n\r\nok sf@ and List:       openbsd-cvs\r\nSubject:    CVS: cvs.openbsd.org: src\r\nFrom:       Stefan Fritsch <sf () cvs ! openbsd ! org>\r\nDate:       2026-01-15 9:06:19\r\n\r\nCVSROOT:\t/cvs\r\nModule name:\tsrc\r\nChanges by:\tsf@cvs.openbsd.org\t2026/01/15 02:06:19\r\n\r\nModified files:\r\n\tsys/dev/pv     : if_vio.c \r\n\r\nLog message:\r\nvio: Support MTU feature\r\n\r\nAdd support for the VIRTIO_NET_F_MTU which allows to get the hardmtu\r\nfrom the hypervisor. Also set the current mtu to the same value. The\r\nvirtio standard is not clear if that is recommended, but Linux does\r\nthis, too.\r\n\r\nUse ETHER_MAX_HARDMTU_LEN as upper hardmtu limit instead of MAXMCLBYTES,\r\nas this seems to be more correct.\r\n\r\nIf the hypervisor requests a MTU larger than ETHER_MAX_HARDMTU_LEN,\r\nredo feature negotiation without VIRTIO_NET_F_MTU.\r\n\r\nWith this commit, OpenBSD finally works on Apple Virtualization.\r\n\r\nInput and testing from @helg\r\n\r\nok jan@ This development will be most welcome for those of us who run with newer Apple Silicon Mac models. As always, if you h", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Patching the Wii News Channel to serve local news (2025)", "url": "https://raulnegron.me/2025/wii-news-pr/", "content": "Site written in Markdown , generated by Hugo , hosted on Github\n        Pages and registered using Route 53 . theme: modified hugo-lanyon ¬© 2025. All rights reserved. üéß Now Playing: Menu (News Channel) via Nintendo Music App In keeping with my passion (?) for displaying local news articles in unexpected places , I figured it would be a fun project to try and see what it would take to display current local news on the Nintendo Wii console‚Äôs News Channel . Here‚Äôs a sneak peek at the result: In this post, I‚Äôd like to share my research and process for getting this all to work. Patched the News Channel‚Äôs hardcoded Nintendo URL to point to an S3 storage bucket using Go and wadlib to extract the necessary binary file and edit it in-memory Modified WiiLink‚Äôs open-source news file generator to add ‚ÄúEl Nuevo D√≠a‚Äù as a news source Set up AWS Lambda + EventBridge to regenerate the necessary news binary files hourly Source code: WiiNewsPR and WiiNewsPR-Patcher The News Channel debuted in North America on January 26, 2007, a little over two months after the Wii‚Äôs launch. Since that date, it mostly came pre-installed with Wii consoles and was a novel way to read news from all over the world. Together with other ‚Äúutility‚Äù channels like the Forecast Channel, it tried to position the Wii as more than just a gaming console. Check out a video recording of the service from right before it was discontinued on June 27th, 2013: Before we can consider displaying custom news on it, we have to figure out how the News Channel actually fetches content. We know that it must have fetched news somehow since it displays a ‚ÄúDownloading‚Ä¶‚Äù splash screen on startup. Luckily for us, the Wii natively supports proxying via its internet connection configuration settings! Meaning we can set up something like mitmproxy on a local machine and observe its HTTP behavior. We can start mitmproxy ‚Äôs web interface for a more screenshot-friendly UI: If we run a man-in-the-middle proxy for the News Channel on an unmo", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "It's Sundowning in America", "url": "https://paulkrugman.substack.com/p/its-sundowning-in-america", "content": "A short post. Today doesn‚Äôt seem like a day for charts and number-crunching. I had never heard the term ‚Äú sundowning ‚Äù before it happened to my own father, yet it‚Äôs a fairly common syndrome. In his last few months my father remained lucid and rational ‚Äî remained himself ‚Äî during daylight hours. Once the sun went down he deteriorated, becoming confused, paranoid and aggressive. It‚Äôs terrible to watch sundowning in someone you love. But that‚Äôs a personal tragedy ‚Äì not a national or global one. It‚Äôs an entirely different matter when the president of the United States is sundowning ‚Äî a president surrounded by malign sycophants who tell him whatever he wants to hear and indulge his every whim, no matter how destructive. For good reasons, it‚Äôs normally bad practice to pronounce on someone‚Äôs mental health from afar. Some of us still remember when right-wing pundits liked to call anyone critical of George W. Bush mentally ill . But after reading the letter that Trump just sent to the prime minister of Norway (Jonas Gahr St√∏re has confirmed that it‚Äôs genuine) there should be no doubt that we have a president who is suffering a real detachment from reality: Dear Jonas: Considering your Country decided not to give me the Nobel Peace Prize for having stopped 8 Wars PLUS, I no longer feel an obligation to think purely of Peace, although it will always be predominant, but can now think about what is good and proper for the United States of America. Denmark cannot protect that land from Russia or China, and why do they have a ‚Äòright of ownership‚Äô anyway? There are no written documents, it‚Äôs only that a boat landed there hundreds of years ago, but we had boats landing there, also. I have done more for NATO than any other person since its founding, and now, NATO should do something for the United States. The World is not secure unless we have Complete and Total Control of Greenland. Thank you! President DJT This might not exactly be sundowning, since it‚Äôs not clear that Trump is lu", "source": "HackerNews", "date": null, "author": null, "score": null}
{"title": "Issue #718: pandas 3.0, deque, tprof, and More (Jan. 20, 2026)", "url": "https://pycoders.com/issues/718", "content": "<p> <span>#718 ‚Äì JANUARY 20, 2026</span><br /> <span><a href=\"https://pycoders.com/issues/718/feed\">View in Browser ¬ª</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s Weekly Logo\" src=\"https://cdn.pycoders.com/37bdf31dc645f968ffb90196e5d38ff5\" /></a></p> <hr /> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15879/feed\" target=\"_blank\">What&rsquo;s New in pandas 3.0</a></h3> <p style=\"margin-bottom: 0;\"> Learn what&rsquo;s new in pandas 3.0: <code>pd.col</code> expressions for cleaner code, Copy-on-Write for predictable behavior, and PyArrow-backed strings for 5-10x faster operations.<br /> <span><a href=\"https://pycoders.com/link/15879/feed\" target=\"_blank\">CODECUT.AI</a> ‚Ä¢ Shared by <a href=\"https://pycoders.com/link/15875/feed\" target=\"_blank\">Khuyen Tran</a></span> </p> </div> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15863/feed\" target=\"_blank\">Python&rsquo;s <code>deque</code>: Implement Efficient Queues and Stacks</a></h3> <p style=\"margin-bottom: 0;\"> Use a Python <code>deque</code> to efficiently append and pop elements from both ends of a sequence, build queues and stacks, and set <code>maxlen</code> for history buffers.<br /> <span><a href=\"https://pycoders.com/link/15863/feed\" target=\"_blank\">REAL PYTHON</a></span> </p> </div> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15848/feed\" target=\"_blank\">B2B Authentication for any Situation - Fully Managed or BYO", "source": "RSS", "date": "2026-01-20T19:30:00+00:00", "author": null, "score": null}
{"title": "Issue #717: Unit Testing Performance, Cursor, Recursive match, and More (Jan. 13, 2026)", "url": "https://pycoders.com/issues/717", "content": "<p> <span>#717 ‚Äì JANUARY 13, 2026</span><br /> <span><a href=\"https://pycoders.com/issues/717/feed\">View in Browser ¬ª</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s Weekly Logo\" src=\"https://cdn.pycoders.com/37bdf31dc645f968ffb90196e5d38ff5\" /></a></p> <hr /> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15840/feed\" target=\"_blank\">Unit Testing Your Code&rsquo;s Performance</a></h3> <p style=\"margin-bottom: 0;\"> Testing your code is important, but not just for correctness also for performance. One approach is to check performance degradation as data sizes go up, also known as Big-O scaling.<br /> <span><a href=\"https://pycoders.com/link/15840/feed\" target=\"_blank\">ITAMA TURNER-TRAURING</a></span> </p> </div> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15832/feed\" target=\"_blank\">Tips for Using the AI Coding Editor Cursor</a></h3> <p style=\"margin-bottom: 0;\"> Learn Cursor fast: AI-powered coding with agents, project-aware chat, inline edits, and VS Code workflow &ndash; ship smarter, sooner.<br /> <span><a href=\"https://pycoders.com/link/15832/feed\" target=\"_blank\">REAL PYTHON</a></span> <span style=\"color: #AAAAAA; padding: 1px 4px; border: 1px solid #dddddd; margin-left: 4px; font-size: 0.8em; border-radius: 2px;\">course</span> </p> </div> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15811/feed\" target=\"_blank\">AI Code Review With Comments You&rsquo;ll Actually Imp", "source": "RSS", "date": "2026-01-13T19:30:00+00:00", "author": null, "score": null}
{"title": "Issue #716: Performance Numbers, async Web Apps, uv Speed, and More (Jan. 6, 2026)", "url": "https://pycoders.com/issues/716", "content": "<p> <span>#716 ‚Äì JANUARY 6, 2026</span><br /> <span><a href=\"https://pycoders.com/issues/716/feed\">View in Browser ¬ª</a></span> </p> <p><a href=\"https://pycoders.com\"><img alt=\"The PyCoder&rsquo;s Weekly Logo\" src=\"https://cdn.pycoders.com/37bdf31dc645f968ffb90196e5d38ff5\" /></a></p> <hr /> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15805/feed\" target=\"_blank\">PyCoder&rsquo;s Weekly 2025 Top Articles &amp; Hidden Gems</a></h3> <p style=\"margin-bottom: 0;\"> PyCoder&rsquo;s Weekly included over 1,500 links to articles, blog posts, tutorials, and projects in 2025. Christopher Trudeau is back on the show this week to help wrap up everything by sharing some highlights and uncovering a few hidden gems from the pile.<br /> <span><a href=\"https://pycoders.com/link/15805/feed\" target=\"_blank\">REAL PYTHON</a></span> <span style=\"color: #AAAAAA; padding: 1px 4px; border: 1px solid #dddddd; margin-left: 4px; font-size: 0.8em; border-radius: 2px;\">podcast</span> </p> </div> <div> <h3 style=\"margin-bottom: 0;\"><a href=\"https://pycoders.com/link/15788/feed\" target=\"_blank\">Python Numbers Every Programmer Should Know</a></h3> <p style=\"margin-bottom: 0;\"> Ever wonder how much memory an empty list takes? How about how long it takes to add two integers in Python? This post contains loads of performance data for common Python operations.<br /> <span><a href=\"https://pycoders.com/link/15788/feed\" target=\"_blank\">MICHAEL KENNEDY</a></span> </p> </div> <div> <h3 style=\"", "source": "RSS", "date": "2026-01-06T19:30:00+00:00", "author": null, "score": null}
{"title": "Nvidia: End-to-End Test-Time Training for Long Context aka Being Able To Update A Model's Weights In Real-Time As You Use It | \"TTT changes the paradigm from retrieving info to learning it on the fly...the TTT model treats the context window as a dataset &amp; trains itself on it in real-time.\" [R]", "url": "https://www.reddit.com/r/MachineLearning/comments/1qd696s/nvidia_endtoend_testtime_training_for_long/", "content": "Nvidia: End-to-End Test-Time Training for Long Context aka Being Able To Update A Model's Weights In Real-Time As You Use It | \"TTT changes the paradigm from retrieving info to learning it on the fly...the TTT model treats the context window as a dataset &amp; trains itself on it in real-time.\" [R]. ####TL;DR:\nThe paper describes a mechanism that essentially turns the context window into a training dataset for a \"fast weight\" update loop:\n\n * **Inner Loop:** The model runs a mini-gradient descent on the context during inference. It updates specific MLP layers to \"learn\" the current context.\n * **Outer Loop:** The model's initial weights are meta-learned during training to be \"highly updateable\" or optimized for this test-time adaptation\n\n**From the Paper:** \"Overall, our empirical observations strongly indicate that TTT-E2E should produce the same trend as full attention for scaling with training compute in large-budget production runs.\"\n\n\n\n\n---\n\n\n\n####Abstract:\n\n&gt;We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture a Transformer with sliding-window attention. \n&gt;\n&gt;**However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights.** In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. \n&gt;\n&gt;In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7x faster than full attention for 128K context. **Our code is publicly available.**\n\n\n---\n\n####Layman's Explanation:\n\nThink of this paper as solving the memory bottleneck by fundamentally changing how a model processes information. Imagine you are taking a massive open-book exam. \n\nA standard Transformer (like GPT-4) is the student who frantically re-reads every single page of the textbook before answering every single question. This strategy guarantees they find the specific details (perfect recall), but as the textbook gets thicker, they get exponentially slower until they simply cannot finish the test in time. \n\nOn the other hand, alternatives like RNNs or Mamba try to summarize the entire textbook onto a single index card. They can answer questions instantly because they don't have to look back at the book, but for long, complex subjects, they eventually run out of space on the card and start forgetting crucial information.\n\nThis new method, Test-Time Training (TTT), changes the paradigm from retrieving information to learning it on the fly. Instead of re-reading the book or summarizing it onto a card, the TTT model treats the context window as a dataset and actually trains itself on it in real-time. It performs a mini-gradient descent update on its own neural weights as it reads. **This is equivalent to a student who reads the textbook and physically rewires their brain to master the subject matter before the test.** \n\nBecause the information is now compressed into the model's actual intelligence (its weights) rather than a temporary cache, the model can answer questions instantly (matching the constant speed of the fast index-card models) but with the high accuracy and scaling capability of the slow, page-turning Transformers. \n\n**This effectively decouples intelligence from memory costs, allowing for massive context lengths without the usual slowdown.**\n\n---\n\n\n######Link to the Paper: https:/", "source": "Reddit", "date": "2026-01-15T02:43:26", "author": "44th--Hokage", "score": 249}
{"title": "[P] I Gave Claude Code 9.5 Years of Health Data to Help Manage My Thyroid Disease", "url": "https://www.reddit.com/r/MachineLearning/comments/1qi8twv/p_i_gave_claude_code_95_years_of_health_data_to/", "content": "[P] I Gave Claude Code 9.5 Years of Health Data to Help Manage My Thyroid Disease. I have episodic Graves' disease, which has been difficult b/c its not chronic. Meds are up and down and often lag when the actual onset occurs\n\nI fed Claude 9.5 years of my Apple Watch and Whoop data, and tasked it to build an ML model (ended up with XGBoost after I tasked it to run every ML model, ran for over 1 hr) to detect these phases. It hit \\~98% validation accuracy and now acts as a personal risk assessor, alerting me 3-4 weeks before symptoms even appear. Backtested it on my last episode, and it would've given me a heads-up in early August before labs confirmed it at the end of the month. I was pretty blown away by this, it even made some very novel approach shift decisions.¬†\n\nTurned it into a simple iOS app I can check whenever. I wrote this article given alot of interest I saw in emulating this along with the repo w/ claude code setup open sourced. Hope this helps\n\n[https://medium.com/data-science-collective/i-gave-claude-code-9-5-years-of-health-data-to-help-manage-my-thyroid-disease-85fcd8c0449f](https://medium.com/data-science-collective/i-gave-claude-code-9-5-years-of-health-data-to-help-manage-my-thyroid-disease-85fcd8c0449f)", "source": "Reddit", "date": "2026-01-20T19:17:38", "author": "ThatAi_guy", "score": 179}
{"title": "[D] Why Mamba rewrote its core algorithm and Microsoft abandoned RetNet", "url": "https://www.reddit.com/r/MachineLearning/comments/1qehwlu/d_why_mamba_rewrote_its_core_algorithm_and/", "content": "[D] Why Mamba rewrote its core algorithm and Microsoft abandoned RetNet. Mamba-2 restructured its recurrence from parallel scans (10-20% Tensor Core utilization) to block-diagonal GEMMs (60-70%). The architecture bent to fit the silicon.\n\nRetNet was published by Microsoft Research in July 2023 with promising results at 6.7B. Five months later, the same organization shipped Phi-2, a dense Transformer. Then Phi-3. Then Phi-4. The co-authors didn't bet on their own architecture.\n\nI wrote an analysis of why this pattern keeps repeating. The short version: Transformers and NVIDIA GPUs co-evolved into a stable attractor. Breaking out requires clearing two reinforcing gates at once, hardware compatibility and institutional backing, and the gates make each other harder to pass. At frontier scale, no pure alternative has done it.\n\nEssay has Tensor Core utilization numbers, analysis of alternative chip vendors, and three falsifiable predictions for 2028.", "source": "Reddit", "date": "2026-01-16T15:47:45", "author": "petroslamb", "score": 119}
{"title": "[D] Burnout from the hiring process", "url": "https://www.reddit.com/r/MachineLearning/comments/1qepc05/d_burnout_from_the_hiring_process/", "content": "[D] Burnout from the hiring process. I've been interviewing for research (some engineering) interships for the last 2 months, and I think I'm at a point of mental exhaustion from constant rejections and wasted time.\n\nFor context, I just started my master‚Äôs at Waterloo, but I'm a research associate at one of the top labs in Europe. I have been doing research since my sophomore year. I did not start in ML, but over the last year and a half, I ended up in ML research, first in protein design and now in pretraining optimization.\n\nI started applying for interships a few months ago, and after 10+ first-round interviews and endless OAs, I haven't landed any offers. Most of the companies that I've interviewed with were a mix of (non-FAANG) frontier AI companies, established deep tech startups, research labs of F100 companies, a couple non name startups, and a quant firm. I get past a few rounds, then get cut.\n\nThe feedback in general is that I'm not a good \"fit\" (a few companies told me I'm too researchy for a research engineer, another few were researching some niche stuff). And the next most common reason is that I failed the coding technical (I have no issue passing the research and ML theory technical interviews), but I think too slow for an engineer, and it's never the same type of questions (with one frontier company, I passed the research but failed the code review) and I'm not even counting OAs. Not a single one asked Leetcode or ML modelling; it's always some sort of a custom task that I have no prior experience with, so it's never the same stuff I can prepare.\n\nI'm at a loss, to be honest. Every PhD and a bunch of master's students in our lab have interned at frontier companies, and I feel like a failure that, after so many interviews, I can't get an offer. Because of my CV (no lies), I don't have a problem getting interviews, but I can't seem to get an offer. I've tried applying for non-research and less competitive companies, but I get hit with \"not a good fit.\"\n\nI have 3 technicals next week, and tbh I know for a fact I'm not gonna pass 2 of them (too stupid to be a quant researcher) and the other is a 3rd round technical, but from the way he described it I don't think I'll be passing it (they're gonna throw a scientific simulation coding problem at me). And I still need to schedule one more between those 3, but I'm not sure why they even picked me, I don't do RL or robotics research. After so many days and hours spent preparing for each technical only to get cut, I mentally can't get myself to prepare for them anymore. It's always a new random format.\n\nI'm severely burned out by this whole process, but time is running out. I love research, but I'm starting to hate the hiring process in this industry. Any advice on what to do?", "source": "Reddit", "date": "2026-01-16T20:16:28", "author": "RNRuben", "score": 115}
{"title": "[R] Is Leetcode still relevant for research scientist interviews?", "url": "https://www.reddit.com/r/MachineLearning/comments/1qh9sg5/r_is_leetcode_still_relevant_for_research/", "content": "[R] Is Leetcode still relevant for research scientist interviews?. Hello everybody,\n\nI‚Äôm at my third (and last year) of my phd in computer vision, and I want to start preparing for technical interviews. What I want to do is work as a research scientist, preferably at companies like Meta. In terms of publications and research knowledge I think I have a quite decent profile with 4 papers at A\\* conferences. However I have heard that the coding interviews can be quite thought even for research scientist jobs. So I‚Äôm wondering if practicing with leetcode still relevant or is there other alternatives?\n\nThanks!\n\nEdit: Thanks to anyone who has taken the time to answer you guys rock", "source": "Reddit", "date": "2026-01-19T18:01:23", "author": "Training-Adeptness57", "score": 112}
{"title": "[P] my shot at a DeepSeek style moe on a single rtx 5090", "url": "https://www.reddit.com/r/MachineLearning/comments/1qcxhgw/p_my_shot_at_a_deepseek_style_moe_on_a_single_rtx/", "content": "[P] my shot at a DeepSeek style moe on a single rtx 5090. I know most will wonder why I‚Äôm wasting my time training at only 19k tok a sec. It‚Äôs because I can. I‚Äôm doing this in my living room in my spare time. 0 formal ML experience. The absurd amount I‚Äôve learned in the last few months made me realize I really picked the wrong career.\n\nMy Mixture of Experts is 2.36B parameter with 8 routed experts plus a shared expert using top-2 routing. Attention is Grouped Query Attention with QK-normalization and RoPE positional embeddings. All feed-forward layers use SwiGLU activation with RMSNorm throughout. Load balancing follows DeepSeek V3‚Äôs auxiliary-loss-free approach using bias-based routing. I monitor coefficient of variation and maximum violation per step.\n\nTraining runs on TorchAO FP8 quantization with the Muon optimizer and a multi-stage learning rate schedule (warmup, constant, cosine decay). The backend is optimized for Blackwell architecture with cuBLASLt.\n\nThe data pipeline implements MeCo (Metadata Conditioning then Cooldown) with ledger-based deterministic sampling. I have document-aware attention masking and cross-document loss masking but was disabled for the initial MeCo run. I have since disabled MeCo and curated a clean corpus with no tagging of any kind. MeCo worked but it worked too well and with only 8 experts, it became very problematic.\n\nMy two biggest early mistakes were not using symmetric router initialization (std=0.006) and not having a dense first layer. Cost me a lot of time and sleep. So what did I do? I cheated. I used aux loss of .003 snd ema smoothing at the beginning. I just didn‚Äôt know better. I paid a price later on for that.\n\nDO NOT use router scaling on a small MoE. DeepSeek used 2.5. Kimi K2 used 2.446. I tried 1.2 and it was horribly unstable and violation blew up to over .500.\n\n24 batch 6 Grad LR 3e-4 AdamW+Muon Scaled. Bias .001 Aux .0001. I update every step.\n\nAs of yesterday: 2026-01-13 20:53:06 step¬†41915¬†|¬†lr¬†3.00e-04¬†|¬†loss¬†1.8867¬†|¬†gnorm¬†0.13¬†|¬†19,415¬†tok/s¬†(ema¬†19,553)¬†|¬†75.9s/5¬†steps¬†|¬†cv¬†0.022¬†|¬†bias¬†-0.001708¬±0.179996¬†|¬†rel_max=0.036¬†maxvio=0.027¬†ent=1.203¬†applied=True¬†|¬†seq_aux¬†2.444 2026-01-13 20:54:20 ¬†¬†¬†¬†[moe]¬†token¬†counts:¬†[150018,¬†148422,¬†155402,¬†147966,¬†145236,¬†146724,¬†144358,¬†141522] 2026-01-13 20:54:20 step¬†41920¬†|¬†lr¬†3.00e-04¬†|¬†loss¬†1.9263¬†|¬†gnorm¬†0.13¬†|¬†20,102¬†tok/s¬†(ema¬†19,828)¬†|¬†73.4s/5¬†steps¬†|¬†cv¬†0.026¬†|¬†bias¬†-0.001708¬±0.179920¬†|¬†rel_max=0.054¬†maxvio=0.054¬†ent=1.211¬†applied=True¬†|¬†seq_aux¬†2.515\n\nI got a long ways to go :)\n\nI‚Äôll gladly answer any question. No gate keeping here.", "source": "Reddit", "date": "2026-01-14T20:53:25", "author": "exhorder72", "score": 82}
{"title": "[D] Regret leaving a good remot ML/CV role for mental health and now struggling to get callbacks", "url": "https://www.reddit.com/r/MachineLearning/comments/1qi2jp8/d_regret_leaving_a_good_remot_mlcv_role_for/", "content": "[D] Regret leaving a good remot ML/CV role for mental health and now struggling to get callbacks. I am a Computer Vision and ML engineer with over five years of experience and a research based Masters degree. A few months ago I left a well paying remote role because the work environment and micromanagement were seriously affecting my mental health. At the time I believed stepping away was the right decision for my sanity.\n\nIt has now been around three months and I am barely getting any recruiter screens let alone technical interviews. The lack of callbacks has been extremely demotivating and has made me start regretting leaving a stable job even though I still believe I needed the mental peace.\n\nI am applying to Computer Vision ML and Perception Engineer roles and I am based in Canada but open to North America remote roles. I am tailoring my resume and applying consistently but something is clearly not working. I am trying to understand whether this is just how bad the market is right now or if I am missing something obvious.\n\nIf you have been through this recently I would really appreciate honest advice on what helped you start getting first interviews and what hiring managers are actually looking for right now in ML/CV positions\n\nI am just trying to get unstuck and move forward.", "source": "Reddit", "date": "2026-01-20T15:29:02", "author": "PinPitiful", "score": 76}
{"title": "[R] China just released first SOTA multimodal model trained entirely on domestic chips", "url": "https://www.reddit.com/r/MachineLearning/comments/1qeakhz/r_china_just_released_first_sota_multimodal_model/", "content": "[R] China just released first SOTA multimodal model trained entirely on domestic chips. Zhipu AI and Huawei just dropped GLM-Image, and the technical details are interesting.\n\nFirst multimodal model trained completely on Chinese chips (Huawei Ascend 910) from data preprocessing to full scale training. They're using a hybrid architecture combining autoregressive + diffusion decoder.\n\nWhat stands out is the Chinese text rendering. It consistently ranks first among open source models for complex text generation, especially handling Chinese characters which most models struggle with.\n\nNative support for 1024 to 2048 resolution at any aspect ratio without additional training. API pricing is 0.1 yuan per image (roughly $0.014).\n\nThe model handles both text to image and image to image generation in a single model. GitHub and Hugging Face repos are already up.\n\nThis is significant because it proves you can train frontier models without relying on Nvidia hardware. The compute efficiency numbers they're claiming are 60% better than H200 for tokens per joule.\n\nWhether those benchmarks hold up in practice remains to be seen but the fact they pulled this off on domestic hardware is noteworthy.\n\nEdit: For anyone testing this, X-Design also handles multilingual text rendering well. Been comparing outputs and both handle complex layouts better than DALL-E 3.", "source": "Reddit", "date": "2026-01-16T09:27:32", "author": "Different_Case_6484", "score": 67}
{"title": "[Project] Kuat: A Rust-based, Zero-Copy Dataloader for PyTorch (4.6x training speedup on T4/H100)", "url": "https://www.reddit.com/r/MachineLearning/comments/1qig3ae/project_kuat_a_rustbased_zerocopy_dataloader_for/", "content": "[Project] Kuat: A Rust-based, Zero-Copy Dataloader for PyTorch (4.6x training speedup on T4/H100). Hi everyone,\n\nWe built a drop-in replacement for `torch.utils.data.DataLoader` entirely in Rust.\n\n**The Problem:** Python's `multiprocessing` isolates workers, meaning every batch incurs IPC and pickling overhead. Even on a T4, the CPU often bottlenecks while the GPU sits idle waiting for data.\n\n**The Solution:** We bypass Python's data plane entirely.\n\n* **Rust Backend:** Uses native threads (no GIL, no heavy process forking).\n* **Zero-Copy:** We use a memory-mapped custom format (`.kt`) that creates views into tensors without deserialization overhead.\n\n**Benchmarks (ResNet-18 / ImageWoof, Tesla T4, batch=64):**\n\n|Loader|Throughput|Speedup|\n|:-|:-|:-|\n|PyTorch ImageFolder|116 img/s|1.0x|\n|MosaicML Streaming|179 img/s|1.5x|\n|NVIDIA DALI|246 img/s|2.1x|\n|**Kuattree (Ours)**|**512 img/s**|**4.4x**|\n\n**Summary:** We are roughly **2.08x faster than DALI** and **4.4x faster than standard PyTorch**.\n\nThe trade-off is that you have to pre-convert your dataset to our `.kt` format. It‚Äôs similar conceptually to writing a TFRecord or WebDataset, but designed for random access, and we found the ingestion to be about `60x` faster than MosaicML sharding.\n\nWe aren't open source just yet, but we are running a private beta if anyone wants to verify these numbers on their own hardware.\n\n[www.kuatlabs.com](https://www.kuatlabs.com)\n\nHappy to answer any questions about the Rust implementation or the memory mapping approach!", "source": "Reddit", "date": "2026-01-20T23:41:42", "author": "YanSoki", "score": 56}
{"title": "[D] ICML26 new review policies", "url": "https://www.reddit.com/r/MachineLearning/comments/1qg5pa9/d_icml26_new_review_policies/", "content": "[D] ICML26 new review policies. ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:\n\n* **Policy A (Conservative):**¬†Use of LLMs for reviewing is¬†strictly prohibited. ¬†\n* **Policy B (Permissive):**¬†\n   * ***Allowed***: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant\\* LLMs.¬†\n   * ***Not allowed***: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review¬†*\\*By ‚Äúprivacy-compliant‚Äù, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*\n\nI'm struggling to decide which one to select, any suggestions?", "source": "Reddit", "date": "2026-01-18T11:54:51", "author": "reutococco", "score": 52}
{"title": "[R] Is it possible for a high school student to publish multiple papers at top conferences within a year?", "url": "https://www.reddit.com/r/MachineLearning/comments/1qe1z90/r_is_it_possible_for_a_high_school_student_to/", "content": "[R] Is it possible for a high school student to publish multiple papers at top conferences within a year?. I recently came across the [Google Scholar profile](https://scholar.google.com/citations?hl=en&amp;user=pCrKkUQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate) of a high school student and was quite astonished by the strength of his publication record. Even more strikingly, he is also serving as a reviewer for ICLR and AISTATS.", "source": "Reddit", "date": "2026-01-16T02:12:56", "author": "ApprehensiveEgg5201", "score": 45}
{"title": "[P] Progressive coding exercises for transformer internals", "url": "https://www.reddit.com/r/MachineLearning/comments/1qf80mh/p_progressive_coding_exercises_for_transformer/", "content": "[P] Progressive coding exercises for transformer internals. For a while I've been looking for a good format to practice implementing ML algorithms. LeetCode feels too disconnected from real work, but in actual projects you just use existing libraries. What worked for me was breaking real algorithms into progressive steps and implementing them piece by piece.\n\nI've been using this approach for myself, and recently decided to clean up some of it with tests and hints in case others find it useful. Currently covers: attention, BPE tokenization, beam search variants, and RoPE.\n\nCurious if others have found similar formats helpful, or what primitives would be worth adding.", "source": "Reddit", "date": "2026-01-17T09:33:24", "author": "randmusr66", "score": 39}
{"title": "[D] ICASSP 2026 Results", "url": "https://www.reddit.com/r/MachineLearning/comments/1qeips6/d_icassp_2026_results/", "content": "[D] ICASSP 2026 Results. It looks like ICASSP 2026 decisions may already be accessible.\n\nIf you can log in to the following link and successfully send an invitation email, that seems to indicate your paper has been accepted:\n\n[ https://cmsworkshops.com/ICASSP2026/author\\_invitation\\_request.php ](https://cmsworkshops.com/ICASSP2026/author_invitation_request.php)\n\nThe email says: ‚ÄúOn behalf of IEEE ICASSP 2026, I invite you to join us for the upcoming conference.\n\nWe are pleased to inform you that your submission has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) in Barcelona, Spain, during 3‚Äì8 May 2026. ICASSP is the world‚Äôs largest and most comprehensive technical conference focused on signal processing and its applications. It offers a comprehensive technical program presenting all the latest development in research and technology in the industry that attracts thousands of professionals annually.‚Äù\n\nHopefully this helps others who are anxiously waiting. Good luck everyone\n\n\\--------\n\nUpdate: It was a bug that got fixed within a few hours. It looks like no one can access it right now.\n\n‚ÄúError: No match for paper number and password. 0x4C‚Äù.\n\n\\--------\n\nUpdate: Just got the official email! ü•∞ ID 9000-10000\n\nSome folks haven‚Äôt gotten the email yet, but they can already find their papers on the accepted list here:\n\n[ https://cmsworkshops.com/ICASSP2026/papers/accepted\\_papers.php ](https://cmsworkshops.com/ICASSP2026/papers/accepted_papers.php)\n\nyou can also check a community-maintained spreadsheet compiled by users on another platform:\n\n[ https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2 ](https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2)\n\nThe list is still updating, so no worries if yours isn‚Äôt there yet just give it a bit more time.\n\nYou can check your paper status here:\n\n[https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp](https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp)", "source": "Reddit", "date": "2026-01-16T16:18:35", "author": "Financial-Panda6581", "score": 35}
{"title": "[D] Scale AI ML Research Engineer Interviews", "url": "https://www.reddit.com/r/MachineLearning/comments/1qe1u5f/d_scale_ai_ml_research_engineer_interviews/", "content": "[D] Scale AI ML Research Engineer Interviews. Hi, I'm looking for help into preparing for the upcoming coding interviews for an ML research engineer position I applied to at Scale. These are for the onsite.\n\nThe first coding question relates parsing data, data transformations, getting statistics about the data. The second (ML) coding involves ML concepts, LLMs, and debugging.\n\nI found the description of the ML part to be a bit vague. For those that have done this type of interview, what did you do to prepare? So far on my list, I have reviewing hyperparameters of LLMs, PyTorch debugging, transformer debugging, and data pipeline pre-processing, ingestion, etc. Will I need to implement NLP or CV algorithms from scratch?\n\nAny insight to this would be really helpful.", "source": "Reddit", "date": "2026-01-16T02:06:36", "author": "sailor-goon-is-here", "score": 39}
{"title": "[P] SmallPebble: A minimalist deep learning library written from scratch in NumPy", "url": "https://www.reddit.com/r/MachineLearning/comments/1qgac9b/p_smallpebble_a_minimalist_deep_learning_library/", "content": "[P] SmallPebble: A minimalist deep learning library written from scratch in NumPy.", "source": "Reddit", "date": "2026-01-18T15:44:00", "author": "montebicyclelo", "score": 38}
{"title": "[D] LLMs as a semantic regularizer for feature synthesis (small decision-tree experiment)", "url": "https://www.reddit.com/r/MachineLearning/comments/1qffcgi/d_llms_as_a_semantic_regularizer_for_feature/", "content": "[D] LLMs as a semantic regularizer for feature synthesis (small decision-tree experiment). I‚Äôve been experimenting with using LLMs not to generate features, but instead to filter them during enumerative feature synthesis.\n\nThe approach was inspired by this paper: https://arxiv.org/pdf/2403.03997v1\n\nI had already been playing with enumerative bottom up synthesis but noticed it usually gave me unintelligible features (even with regularization).\n\nI looked into how other symbolic approaches deal with this problem and saw that they tried to model the semantics of the domain somehow - including dimensions, refinement types etc. But those approaches weren't appealing to me because I was trying to come up with something that worked in general.\n\nSo I tried using an LLM to score candidate expressions by how meaningful they are. The idea was that the semantic meaning of the column names, the dimensions, and the salience of the operations could be embedded in the LLM.\n\nMy approach was:\n* Enumerate simple arithmetic features (treat feature eng as program synthesis)\n* Use an LLM as a semantic filter (‚Äúdoes this look like a meaningful quantity?‚Äù)\n* Train a decision tree (with oblique splits) considering only the filtered candidates as potential splits.\n\nThe result was that the tree was noticeably more readable, accuracy was similar / slightly better in my small test.\n\n\nI wrote it up here: https://mchav.github.io/learning-better-decision-tree-splits/\nRunnable code is [here](https://github.com/mchav/dataframe/blob/main/app%2FREADME.md)\n\nIf you‚Äôve tried constraining feature synthesis before: what filters worked best in practice? Are the any measures of semantic viability out there?", "source": "Reddit", "date": "2026-01-17T15:59:55", "author": "ChavXO", "score": 38}
{"title": "Spine surgery has massive decision variability. Retrospective ML won‚Äôt fix it. Curious if a workflow-native, outcome-driven approach could. [D]", "url": "https://www.reddit.com/r/MachineLearning/comments/1qcyd7z/spine_surgery_has_massive_decision_variability/", "content": "Spine surgery has massive decision variability. Retrospective ML won‚Äôt fix it. Curious if a workflow-native, outcome-driven approach could. [D]. Hi everyone I‚Äôm a fellowship-trained neurosurgeon / spine surgeon. I‚Äôve been discussing a persistent problem in our field with other surgeons for a while, and I wanted to run it by people who think about ML systems, not just model performance.\n\nI‚Äôm trying to pressure-test whether a particular approach is even technically sound, where it would break, and what I‚Äôm likely underestimating. Id love to find an interested person to have a discussion with to get a 10000 feet level understanding of the scope of what I am trying to accomplish.\n\n**The clinical problem:**  \nFor the same spine pathology and very similar patient presentations, you can see multiple reputable surgeons and get very different surgical recommendations. anything from continued conservative management to decompression, short fusion, or long multilevel constructs. Costs and outcomes vary widely.\n\nThis isn‚Äôt because surgeons are careless. It‚Äôs because spine surgery operates with:\n\n* Limited prospective evidence\n* Inconsistent documentation\n* Weak outcome feedback loops\n* Retrospective datasets that are biased, incomplete, and poorly labeled\n\nEMRs are essentially digital paper charts. PACS is built for viewing images, not capturing¬†*decision intent*. Surgical reasoning is visual, spatial, and 3D, yet we reduce it to free-text notes after the fact. From a data perspective, the learning signal is pretty broken.\n\n**Why I‚Äôm skeptical that training on existing data works:**\n\n* ‚ÄúLabels‚Äù are often inferred indirectly (billing codes, op notes)\n* Surgeon decision policies are non-stationary\n* Available datasets are institution-specific and access-restricted\n* Selection bias is extreme (who gets surgery vs who doesn‚Äôt is itself a learned policy)\n* Outcomes are delayed, noisy, and confounded\n\nEven with access, I‚Äôm not convinced retrospective supervision converges to something clinically useful.\n\n**The idea I‚Äôm exploring:**  \nInstead of trying to clean bad data later, what if the workflow itself generated structured, high-fidelity labels as a byproduct of doing the work, or at least the majority of it?\n\nConcretely, I‚Äôm imagining an EMR-adjacent, spine-specific surgical planning and case monitoring environment that surgeons would actually want to use. Not another PACS viewer, but a system that allows:\n\n* 3D reconstruction from pre-op imaging\n* Automated calculation of alignment parameters\n* Explicit marking of anatomic features tied to symptoms\n* Surgical plan modeling (levels, implants, trajectories, correction goals)\n* Structured logging of surgical cases (to derive patterns and analyze for trends)\n* Enable productivity (generate note, auto populate plans ect.)\n* Enable standardized automated patient outcomes data collection.\n\nThe key point isn‚Äôt the UI, but UI is also an area that currently suffers. It‚Äôs that surgeons would be forced (in a useful way) to externalize decision intent in a structured format because it directly helps them plan cases and generate documentation. Labeling wouldn‚Äôt feel like labeling it would almost just be how you work. The data used for learning would explicitly include post-operative outcomes. PROMs collected at standardized intervals, complications (SSI, reoperation), operative time, etc, with automated follow-up built into the system.\n\nThe goal would not be to replicate surgeon decisions, but to learn decision patterns that are associated with better outcomes. Surgeons could specify what they want to optimize for a given patient (eg pain relief vs complication risk vs durability), and the system would generate predictions conditioned on those objectives.\n\nOver time, this would generate:\n\n* Surgeon-specific decision + outcome datasets\n* Aggregate cross-surgeon data\n* Explicit representations of surgical choices, not just endpoints\n\nLearning systems could then train on:\n\n* Individual surgeon decision‚Äìoutco", "source": "Reddit", "date": "2026-01-14T21:25:39", "author": "LaniakeaResident", "score": 31}
{"title": "[D] ICLR Results coming on 22nd or 26th?", "url": "https://www.reddit.com/r/MachineLearning/comments/1qiddw6/d_iclr_results_coming_on_22nd_or_26th/", "content": "[D] ICLR Results coming on 22nd or 26th?. Website still shows 22nd but we know during the leak they pushed the timeline back. I‚Äôm aware I can submit abstracts to ICML either ways but just curious", "source": "Reddit", "date": "2026-01-20T22:01:03", "author": "Recent_Confection944", "score": 28}
{"title": "[D] tested file based memory vs embedding search for my chatbot. the difference in retrieval accuracy was bigger than i expected", "url": "https://www.reddit.com/r/MachineLearning/comments/1qgwtas/d_tested_file_based_memory_vs_embedding_search/", "content": "[D] tested file based memory vs embedding search for my chatbot. the difference in retrieval accuracy was bigger than i expected. been working on a personal assistant that needs to remember user preferences, past conversations, and reference documents. tested two approaches for memory retrieval and wanted to share what i found.   \n  \nsetup: about 5k memory items accumulated over 2 months of usage. mix of conversation history, user preferences, and document excerpts.\n\napproach 1: standard rag with embedding search. used openai embeddings with pgvector. retrieval was fast, maybe 200ms per query. but accuracy was inconsistent. worked great for direct factual queries like \"whats my favorite restaurant\" but struggled with temporal queries like \"what did we discuss about the project last tuesday\" or logical queries like \"which of my preferences conflict with each other\"\n\napproach 2: file based memory using memU framework. it organizes memory items into thematic files that the model reads directly. retrieval is slower because the model has to process more tokens but the accuracy on complex queries was noticeably better.\n\nrough numbers from my testing (not rigorous, just my observation):\n\n\\- simple factual queries: both approaches similar, maybe 85-90% accuracy\n\n\\- temporal queries: embedding search around 40%, file based around 75%\n\n\\- multi-hop reasoning: embedding search struggled hard, file based was usable\n\nthe tradeoff is inference cost. file based approach uses more tokens because the model reads entire memory files. for my use case thats fine because i care more about accuracy than cost. but if youre running at scale the token usage would add up. also worth noting that memU does support embedding search as a fallback so you can combine both approaches. i mostly used the file reading mode.\n\nmain takeaway: embedding search is not always the right answer for memory retrieval. depends a lot on what kinds of queries you need to support.", "source": "Reddit", "date": "2026-01-19T07:36:31", "author": "Winter_Ant_4196", "score": 25}
{"title": "[D] CVPR 2026 Paper Reviews", "url": "https://www.reddit.com/r/MachineLearning/comments/1qis2rj/d_cvpr_2026_paper_reviews/", "content": "[D] CVPR 2026 Paper Reviews. CVPR 2026 Reviews are supposed to be released within next 24 hours. Creating a discussion thread to discuss among ourselves, thanks!", "source": "Reddit", "date": "2026-01-21T09:03:38", "author": "akshitsharma1", "score": 24}
{"title": "Cursor Implied Success Without Evidence | Not one of 100 selected commits even built", "url": "https://www.reddit.com/r/programming/comments/1qeotkj/cursor_implied_success_without_evidence_not_one/", "content": "Cursor Implied Success Without Evidence | Not one of 100 selected commits even built.", "source": "Reddit", "date": "2026-01-16T19:57:57", "author": "xX_Negative_Won_Xx", "score": 959}
{"title": "Here is the 15 sec coding test to instantly filter out 50% of unqualified applicants by JOSE ZARAZUA", "url": "https://www.reddit.com/r/programming/comments/1qeqfmo/here_is_the_15_sec_coding_test_to_instantly/", "content": "Here is the 15 sec coding test to instantly filter out 50% of unqualified applicants by JOSE ZARAZUA.", "source": "Reddit", "date": "2026-01-16T20:58:22", "author": "RevillWeb", "score": 933}
{"title": "AI is Not Ready to Replace Junior Devs Says Ruby on Rails Creator", "url": "https://www.reddit.com/r/programming/comments/1qh23o0/ai_is_not_ready_to_replace_junior_devs_says_ruby/", "content": "AI is Not Ready to Replace Junior Devs Says Ruby on Rails Creator.", "source": "Reddit", "date": "2026-01-19T12:49:12", "author": "ImpressiveContest283", "score": 919}
{"title": "MySQL‚Äôs popularity as ranked by DB-Engines started to tank hard, a trend that will likely accelerate in 2026.", "url": "https://www.reddit.com/r/programming/comments/1qg0p6p/mysqls_popularity_as_ranked_by_dbengines_started/", "content": "MySQL‚Äôs popularity as ranked by DB-Engines started to tank hard, a trend that will likely accelerate in 2026..", "source": "Reddit", "date": "2026-01-18T07:04:01", "author": "thehashimwarren", "score": 773}
{"title": "Cursor CEO Built a Browser using AI, but Does It Really Work?", "url": "https://www.reddit.com/r/programming/comments/1qdo9r3/cursor_ceo_built_a_browser_using_ai_but_does_it/", "content": "Cursor CEO Built a Browser using AI, but Does It Really Work?.", "source": "Reddit", "date": "2026-01-15T17:32:27", "author": "ImpressiveContest283", "score": 671}
{"title": "A hacker is making a list of vibecoded apps, 198 scanned 196 with vulnerabilities", "url": "https://www.reddit.com/r/programming/comments/1qhw9zg/a_hacker_is_making_a_list_of_vibecoded_apps_198/", "content": "A hacker is making a list of vibecoded apps, 198 scanned 196 with vulnerabilities.", "source": "Reddit", "date": "2026-01-20T10:09:56", "author": "bored_wombat_v1", "score": 602}
{"title": "Ken Thompson rewrote his code in real-time. A federal court said he co-created MP3. So why has no one heard of James D. Johnston?", "url": "https://www.reddit.com/r/programming/comments/1qd3mko/ken_thompson_rewrote_his_code_in_realtime_a/", "content": "Ken Thompson rewrote his code in real-time. A federal court said he co-created MP3. So why has no one heard of James D. Johnston?. In 1988, James D. Johnston at Bell Labs and Karlheinz Brandenburg in Germany independently invented perceptual audio coding - the science behind MP3. Brandenburg became famous. Johnston got erased from history. The evidence is wild: Brandenburg worked *at Bell Labs* with Johnston from 1989-1990 building what became MP3. A federal appeals court explicitly states they \"together\" created the standard. Ken Thompson - yes, *that* Ken Thompson - personally rewrote Johnston's PAC codec from Fortran to C in a week after Johnston explained the functions to him in real time, then declared it \"vastly superior to MP3.\" AT&amp;T even had a working iPod competitor in 1998, killed it because \"nobody will ever sell music over the internet,\" and the prototype now sits in the Computer History Museum. I interviewed Johnston and dug through court records, patents, and Brandenburg's own interviews to piece together what actually happened. The IEEE calls Johnston \"the father of perceptual audio coding\" but almost no one knows his name.", "source": "Reddit", "date": "2026-01-15T00:50:27", "author": "Traditional_Rise_609", "score": 584}
{"title": "jQuery 4.0 released", "url": "https://www.reddit.com/r/programming/comments/1qfxo89/jquery_40_released/", "content": "jQuery 4.0 released.", "source": "Reddit", "date": "2026-01-18T04:31:22", "author": "curiousdannii", "score": 472}
{"title": "Newer AI Coding Assistants Are Failing in Insidious Ways", "url": "https://www.reddit.com/r/programming/comments/1qdv6h0/newer_ai_coding_assistants_are_failing_in/", "content": "Newer AI Coding Assistants Are Failing in Insidious Ways.", "source": "Reddit", "date": "2026-01-15T21:42:25", "author": "CackleRooster", "score": 465}
{"title": "The 7 deadly sins of software engineers productivity", "url": "https://www.reddit.com/r/programming/comments/1qg69su/the_7_deadly_sins_of_software_engineers/", "content": "The 7 deadly sins of software engineers productivity.", "source": "Reddit", "date": "2026-01-18T12:27:52", "author": "strategizeyourcareer", "score": 374}
{"title": "I decided to make a worse UUID for the pettiest of reasons.", "url": "https://www.reddit.com/r/programming/comments/1qhq372/i_decided_to_make_a_worse_uuid_for_the_pettiest/", "content": "I decided to make a worse UUID for the pettiest of reasons..", "source": "Reddit", "date": "2026-01-20T04:33:32", "author": "theghostofm", "score": 338}
{"title": "ASCII characters are not pixels: a deep dive into ASCII rendering", "url": "https://www.reddit.com/r/programming/comments/1qg3rbf/ascii_characters_are_not_pixels_a_deep_dive_into/", "content": "ASCII characters are not pixels: a deep dive into ASCII rendering.", "source": "Reddit", "date": "2026-01-18T09:59:46", "author": "XLEX97", "score": 259}
{"title": "LLVM adopts \"human in the loop\" policy for AI/tool-assisted contributions", "url": "https://www.reddit.com/r/programming/comments/1qi8vz4/llvm_adopts_human_in_the_loop_policy_for/", "content": "LLVM adopts \"human in the loop\" policy for AI/tool-assisted contributions.", "source": "Reddit", "date": "2026-01-20T19:19:39", "author": "Fcking_Chuck", "score": 237}
{"title": "Why Senior Engineers Let Bad Projects Fail", "url": "https://www.reddit.com/r/programming/comments/1qijolr/why_senior_engineers_let_bad_projects_fail/", "content": "Why Senior Engineers Let Bad Projects Fail.", "source": "Reddit", "date": "2026-01-21T02:07:44", "author": "Ordinary_Leader_2971", "score": 234}
{"title": "Responsible disclosure of a Claude Cowork vulnerability that lets hidden prompt injections exfiltrate local files by uploading them to an attacker‚Äôs Anthropic account", "url": "https://www.reddit.com/r/programming/comments/1qdg7i4/responsible_disclosure_of_a_claude_cowork/", "content": "Responsible disclosure of a Claude Cowork vulnerability that lets hidden prompt injections exfiltrate local files by uploading them to an attacker‚Äôs Anthropic account. From the article:\n\n&gt; Two days ago, Anthropic released the Claude Cowork research preview (a general-purpose AI agent to help anyone with their day-to-day work). In this article, we demonstrate how attackers can exfiltrate user files from Cowork by exploiting an unremediated vulnerability in Claude‚Äôs coding environment, which now extends to Cowork. The vulnerability was first identified in Claude.ai chat before Cowork existed by Johann Rehberger, who disclosed the vulnerability ‚Äî it was acknowledged but not remediated by Anthropic.", "source": "Reddit", "date": "2026-01-15T11:37:06", "author": "sean-adapt", "score": 205}
{"title": "A good test of engineering team maturity is how well you can absorb junior talent", "url": "https://www.reddit.com/r/programming/comments/1qcw37d/a_good_test_of_engineering_team_maturity_is_how/", "content": "A good test of engineering team maturity is how well you can absorb junior talent. Christine Miao nails it here:\n\n\\&gt; Teams that can easily absorb junior talent have systems of resilience to minimize the impact of their mistakes. An intern can‚Äôt take down production because¬†\\*\\*no individual engineer\\*\\*¬†could take down production!\n\nThe whole post is a good sequel to Charity Majors' \"In Praise of Normal Engineers\" from last year.", "source": "Reddit", "date": "2026-01-14T20:02:19", "author": "sean-adapt", "score": 198}
{"title": "The Astro Technology Company joins Cloudflare | Astro", "url": "https://www.reddit.com/r/programming/comments/1qeilrk/the_astro_technology_company_joins_cloudflare/", "content": "The Astro Technology Company joins Cloudflare | Astro.", "source": "Reddit", "date": "2026-01-16T16:14:19", "author": "ReallySuperName", "score": 178}
{"title": "Windows? Linux? Browser? Same Executable", "url": "https://www.reddit.com/r/programming/comments/1qdnx4a/windows_linux_browser_same_executable/", "content": "Windows? Linux? Browser? Same Executable.", "source": "Reddit", "date": "2026-01-15T17:19:36", "author": "double-happiness", "score": 145}
{"title": "Docker Releases Hardened Images For Free - What Does It Do Differently?", "url": "https://www.reddit.com/r/programming/comments/1qeoyb8/docker_releases_hardened_images_for_free_what/", "content": "Docker Releases Hardened Images For Free - What Does It Do Differently?.", "source": "Reddit", "date": "2026-01-16T20:02:34", "author": "Active-Fuel-49", "score": 138}
{"title": "The Influentists: AI hype without proof", "url": "https://www.reddit.com/r/programming/comments/1qdqtk0/the_influentists_ai_hype_without_proof/", "content": "The Influentists: AI hype without proof.", "source": "Reddit", "date": "2026-01-15T19:03:09", "author": "iamapizza", "score": 137}
{"title": "When did destructive criticism become normalized on this sub?", "url": "https://www.reddit.com/r/Python/comments/1qhdssm/when_did_destructive_criticism_become_normalized/", "content": "When did destructive criticism become normalized on this sub?. It‚Äôs been a while since  this sub popped up on my feed. It‚Äôs coming up more recently. I‚Äôm noticing a shocking amount of toxicity on people‚Äôs project shares that I didn‚Äôt notice in the past. Any attempt to call out this toxicity is met with a wave of downvotes.\n\nFor those of you who have been in the Reddit echo chamber a little too long, let me remind you that it is not normal to mock/tease/tear down the work that someone did on their own free time for others to see or benefit from. It \\*is\\* normal to offer advice, open issues, offer reference work to learn from and ask questions to guide the author in the right direction.\n\nThis is an anonymous platform. The person sharing their work could be a 16 year old who has never seen a production system and is excited about programming, or a 30 yoe developer who got bored and just wanted to prove a concept, also in their free time. It does not make you a better to default to tearing someone down or mocking their work.\n\nYou poison the community as a whole when you do so. I am not seeing behavior like this as commonly on other language subs, otherwise I would not make this post. The people willing to build in public and share their sometimes unpolished work is what made tech and the Python ecosystem what it is today, in case any of you have forgotten.\n\n**‚Äîupdate‚Äî**\n\nThe majority of you are saying it‚Äôs because of LLM generated projects. This makes sense (to a limit); but, this toxicity is bleeding into some posts for projects that are clearly are not vibe-coded (existed before the LLM boom). I will not call anyone by name, but I occasionally see moderators taking part or enabling the behavior as well.\n\nAs someone commented, having an explanation for the behavior does not excuse the behavior. Hopefully this at least serves as a reminder of that for some of you.  The LLM spam is a problem that needs to be solved. I disagree that this is the way to do it.", "source": "Reddit", "date": "2026-01-19T20:20:11", "author": "behusbwj", "score": 217}
{"title": "I built a Python UI framework inspired by Streamlit, but with O(1) state updates", "url": "https://www.reddit.com/r/Python/comments/1qh6733/i_built_a_python_ui_framework_inspired_by/", "content": "I built a Python UI framework inspired by Streamlit, but with O(1) state updates. Hey r/Python,\n\nI love Streamlit's simplicity, but the \"full script rerun\" on every interaction drove me crazy. It gets super slow once your app grows, and using `st.cache` everywhere felt like a band-aid.\n\nSo I spent the last few weeks building **Violit**. I wanted something that feels like writing a simple Python script but performs like a modern React app.\n\n**What My Project Does**\n\nViolit is a high-performance Python web framework. It allows you to build interactive web apps using pure Python without the performance penalty of full-page reloads.\n\nIt uses a **\"Zero Rerun\"** architecture based on FastAPI, htmx, and WebSockets. When you interact with a widget (like a button or slider), Violit updates *only* that specific component in **O(1)** time, ensuring no screen flickering and instant feedback. It also supports running your web app into a desktop app (like electron) with a single flag (`--native`).\n\n**Target Audience**\n\n* **Data Scientists &amp; Python Devs:** Who need to build dashboards or internal tools quickly but are frustrated by Streamlit's lag.\n* **Production Use:** It's currently in early Alpha (v0.0.2), so it's best for internal tools, side projects, and early adopters who want to contribute to a faster Python UI ecosystem.\n\n**Comparison**\n\nHere is how Violit differs from existing alternatives:\n\n* **vs. Streamlit:** Violit keeps the intuitive API (90% compatible) but removes the \"Full Script Rerun.\" State updates are O(1) instead of O(N).\n* **vs. Dash:** Violit offers reactive state management without the \"callback hell\" complexity of Dash.\n* **vs. Reflex:** Violit requires **Zero Configuration**. No Node.js dependency, no build steps. Just `pip install` and run. Plus, it has built-in native desktop support.\n* **vs. NiceGUI:** The theme system for the beautiful app. Unlike Streamlit's rigid look or NiceGUI's engineer-first aesthetic, Violit comes with **30+  Themes** out of the box. You can switch from \"cyberpunk\" to \"retro\" styles with a single line of code‚Äîno CSS mastery required. **Plus, it's fully extensible‚Äîyou can easily add your own custom themes via CSS.**\n\n**Code Example**\n\n    import violit as vl\n    ‚Äã\n    app = vl.App()\n    count = app.state(0) ¬†# Reactive State\n    ‚Äã\n    # No rerun! Only the label updates instantly.\n    app.button(\"Increment\", on_click=lambda: count.set(count.value + 1))\n    app.write(\"Count:\", count)\n    ‚Äã\n    app.run()\n\n**Link to Source Code**\n\nIt is open source (MIT License).\n\n* **Repo:** [https://github.com/violit-dev/violit](https://github.com/violit-dev/violit)\n* **PyPI:** `pip install violit`\n* **Example:**\n   * [demo showcase source code](https://github.com/violit-dev/violit/blob/main/examples/1_demo_showcase/demo_showcase.py)\n   * [(Tutorial) Build Your Own Blog in 10 Minutes with Violit!](https://github.com/violit-dev/violit/tree/main/examples/2_violit_blog)\n\nI'd love to hear your feedback!", "source": "Reddit", "date": "2026-01-19T15:52:16", "author": "Puzzleheaded_Clerk68", "score": 133}
{"title": "Tracking 13,000 satellites in under 3 seconds from Python", "url": "https://www.reddit.com/r/Python/comments/1qif5o1/tracking_13000_satellites_in_under_3_seconds_from/", "content": "Tracking 13,000 satellites in under 3 seconds from Python.  I've been working on [https://github.com/ATTron/astroz](https://github.com/ATTron/astroz), an orbital mechanics toolkit with Python bindings. The core is written in Zig with SIMD vectorization.\n\n# What My Project Does\n\nastroz is an astrodynamics toolkit, including propagating satellite orbits using the SGP4 algorithm. It writes directly to numpy arrays, so there's very little overhead going between Python and Zig. You can propagate 13,000+ satellites in under 3 seconds.\n\npip install astroz is all you need to get started!\n\n# Target Audience\n\nAnyone doing orbital mechanics, satellite tracking, or space situational awareness work in Python. It's production-ready. I'm using it myself and the API is stable, though I'm still adding more functionality to the Python bindings.\n\n# Comparison\n\nIt's about 2-3x faster than python-sgp4, far and away the most popular sgp4 implementation being used:\n\n|Library|Throughput|\n|:-|:-|\n|astroz|\\~8M props/sec|\n|python-sgp4|\\~3M props/sec|\n\n# Demo &amp; Links\n\nIf you want to see it in action, I put together a live demo that visualizes all 13,000+ active satellites generated from Python in under 3 seconds: [https://attron.github.io/astroz-demo/](https://attron.github.io/astroz-demo/)\n\nAlso wrote a blog post about how the SIMD stuff works under the hood if you're into that, but it's more Zig heavy than Python: [https://atempleton.bearblog.dev/i-made-zig-compute-33-million-satellite-positions-in-3-seconds-no-gpu-required/](https://atempleton.bearblog.dev/i-made-zig-compute-33-million-satellite-positions-in-3-seconds-no-gpu-required/)\n\nRepo: [https://github.com/ATTron/astroz](https://github.com/ATTron/astroz)", "source": "Reddit", "date": "2026-01-20T23:06:02", "author": "Frozen_Poseidon", "score": 117}
{"title": "Robyn (finally) supports Python 3.14 üéâ", "url": "https://www.reddit.com/r/Python/comments/1qgai08/robyn_finally_supports_python_314/", "content": "Robyn (finally) supports Python 3.14 üéâ. For the unaware -¬†[Robyn](https://github.com/sparckles/Robyn)¬†is a fast, async Python web framework built on a Rust runtime.\n\nPython 3.14 support has been pending for a while.\n\nWanted to share it with folks outside the Robyn community.\n\nYou can check out the release at -¬†[https://github.com/sparckles/Robyn/releases/tag/v0.74.0](https://github.com/sparckles/Robyn/releases/tag/v0.74.0)", "source": "Reddit", "date": "2026-01-18T15:50:34", "author": "stealthanthrax", "score": 99}
{"title": "I built bytes.replace() for CUDA - process multi-GB files without leaving the GPU", "url": "https://www.reddit.com/r/Python/comments/1qh1ekg/i_built_bytesreplace_for_cuda_process_multigb/", "content": "I built bytes.replace() for CUDA - process multi-GB files without leaving the GPU. Built a CUDA kernel that does Python's `bytes.replace()` on the GPU without CPU transfers.\n\n**Performance (RTX 3090):**\n\n    Benchmark                      | Size       | CPU (ms)     | GPU (ms)   | Speedup\n    -----------------------------------------------------------------------------------\n    Dense/Small (1MB)              | 1.0 MB     |   3.03       |   2.79     |  1.09x\n    Expansion (5MB, 2x growth)     | 5.0 MB     |  22.08       |  12.28     |  1.80x\n    Large/Dense (50MB)             | 50.0 MB    | 192.64       |  56.16     |  3.43x\n    Huge/Sparse (100MB)            | 100.0 MB   | 492.07       | 112.70     |  4.37x\n    \n    Average: 3.45x faster | 0.79 GB/s throughput\n\n**Features:**\n\n* Exact Python semantics (leftmost, non-overlapping)\n* Streaming mode for files larger than GPU memory\n* Session API for chained replacements\n* Thread-safe\n\n**Example:**\n\npython\n\n    from cuda_replace_wrapper import CudaReplaceLib\n    \n    lib = CudaReplaceLib('./cuda_replace.dll')\n    result = lib.unified(data, b\"pattern\", b\"replacement\")\n    \n    # Or streaming for huge files\n    cleaned = gpu_replace_streaming(lib, huge_data, pairs, chunk_bytes=256*1024*1024)\n\nBuilt this for a custom compression algorithm. Includes Python wrapper, benchmark suite, and pre-built binaries.\n\nGitHub: [https://github.com/RAZZULLIX/cuda\\_replace](https://github.com/RAZZULLIX/cuda_replace)", "source": "Reddit", "date": "2026-01-19T12:10:04", "author": "andreabarbato", "score": 61}
{"title": "What Python Tools Do You Use for Data Visualization and Why?", "url": "https://www.reddit.com/r/Python/comments/1qeq7c7/what_python_tools_do_you_use_for_data/", "content": "What Python Tools Do You Use for Data Visualization and Why?. Data visualization is crucial for interpreting complex datasets, and Python offers a variety of tools to accomplish this. I'm curious to know which libraries or frameworks you prefer for data visualization and what features make them stand out for you. For instance, do you lean towards Matplotlib for its flexibility, Seaborn for its ease of use, or perhaps Plotly for interactive plots? Additionally, how do you handle specific challenges, such as customizing visualizations or integrating them into web applications? Sharing your experiences and use cases could be beneficial for those looking to enhance their data storytelling skills. Let's discuss the strengths and weaknesses of different tools and any tips you may have for getting the most out of them.", "source": "Reddit", "date": "2026-01-16T20:49:39", "author": "Confident_Compote_39", "score": 49}
{"title": "An open-source tool to add \"Word Wise\" style definitions to any EPUB using Python", "url": "https://www.reddit.com/r/Python/comments/1qff835/an_opensource_tool_to_add_word_wise_style/", "content": "An open-source tool to add \"Word Wise\" style definitions to any EPUB using Python. I've been trying to read more English books, but constantly stopping to look up difficult words breaks my flow. I really liked Kindle's \"Word Wise\" feature, but it doesn't work on sideloaded books.\n\nSo, I built Sura. It's a Python tool that injects ruby text definitions directly into EPUB files.\n\nRepo: https://github.com/watsuyo/Sura\n\n## What My Project Does\n\nSura processes EPUB files to help language learners read more smoothly. Specifically, it:\n\n1. Extracts text from an EPUB file.\n2. Filters words based on difficulty using wordfreq (Zipf scores), so it only targets words you likely don't know.\n3. Generates definitions using an LLM (OpenAI/compatible API) to provide short, context-aware meanings.\n4. Injects ruby text (HTML/CSS) back into the EPUB structure.\n5. Rebuilds the EPUB, making it compatible with almost any e-reader (Kobo, Kindle, etc.).\n\nIt uses asyncio for concurrent processing to keep performance reasonably fast.\n\n## Target Audience\n\nThis tool is meant for language learners who want to read native content without constant dictionary interruptions, and e-reader users (Kindle) who sideload their books.\n\nIt is currently a hobby/open-source project intended for personal use and for developers interested in EPUB manipulation or LLM integration.\n\n## Comparison\n\nThe main alternative is Kindle's native \"Word Wise\" feature.\n\nKindle Word Wise: Only works on books purchased directly from Amazon. It does not support sideloaded documents or other devices like Kobo.\n\nSura: Works on any DRM-free EPUB file, allowing you to use the feature on sideloaded books and non-Kindle devices. It also allows for customizable difficulty thresholds, unlike the fixed settings on Kindle.", "source": "Reddit", "date": "2026-01-17T15:54:53", "author": "Classic_Method_5547", "score": 39}
{"title": "Teaching services online for kids/teenagers?", "url": "https://www.reddit.com/r/Python/comments/1qcos9u/teaching_services_online_for_kidsteenagers/", "content": "Teaching services online for kids/teenagers?. My son (13) is interested in programming. I would like to sign him up for some introductory (and fun for teenagers) online program. Are there any that you‚Äôve seen that you‚Äôd be able to recommend. Paid or unpaid are fine.", "source": "Reddit", "date": "2026-01-14T15:33:04", "author": "CodeVirus", "score": 31}
{"title": "Opticol: memory optimized python collections", "url": "https://www.reddit.com/r/Python/comments/1qhl2o2/opticol_memory_optimized_python_collections/", "content": "Opticol: memory optimized python collections. Hi everyone,\n\nI just created a new library called [opticol](https://github.com/lessico/opticol/) (which stands for optimized collections), which I wanted to share with the community. The idea of the library is to create space optimized versions of Sequence, Set, and Mapping for small collections leveraging the collections.ABC vocabulary.\n\n## What My Project Does\nCreates optimized versions of the main python collection types (Sequence, Set, Mapping) along with vocabulary types and convenience methods for transforming builtins to the optimized type.\n\nFor collections of size 3 or less, it is pretty trivial (using slots) to create an object that can act as a collection, but uses notably less memory than the builtins. Consider the fact that an empty set requires 216 bytes, or a dictionary with one element requires 224 bytes. Applications that create many (on the order of 100k to a million) of these objects can substantially reduce their memory usage with this library.\n\n## Target Audience\n\nThis will benefit users who use Python for various forms of data analysis. These problems often have many collection instances, which can often be just a few items. I myself have run into issues with memory pressure like this with some NLP datasets. Additionally, this is helpful for those doing this primarily in Python or for situations where dropping to a lower level language is not advantageous yet.\n\n## Comparison\n\nI could not find a similar library to this, nor even discussion of implementing such an idea. I would be happy to update this section if something comes up, but as far as I know, there are no direct comparisons.\n\nAnyway, it's currently a beta release as I'm working on finishing up the last unit tests, but the main use case generally works. I'm also very interested in any feedback on the project itself or other optimizations that may be good to add!", "source": "Reddit", "date": "2026-01-20T00:53:38", "author": "matgrioni", "score": 26}
{"title": "Network monitoring dashboard built with Flask, scapy, and nmap", "url": "https://www.reddit.com/r/Python/comments/1qi4o7p/network_monitoring_dashboard_built_with_flask/", "content": "Network monitoring dashboard built with Flask, scapy, and nmap. built a home network monitor as a learning project useful to anyone.\n\n\\- what it does: monitors local network in real time, tracks devices, bandwidth usage per device, and detects anomalies like new unknown devices or suspicious traffic patterns.\n\n\\- target audience: educational/homelab project, not production ready. built for learning networking fundamentals and packet analysis. runs on any linux machine, good for raspberry pi setups.\n\n\\- comparison: most alternatives are either commercial closed source like fing or heavyweight enterprise tools like ntopng. this is intentionally simple and focused on learning. everything runs locally, no cloud, full control. anomaly detection is basic rule based so you can actually understand what triggers alerts, not black box ml.\n\ntech stack used:\n\n* flask for web backend + api\n* scapy for packet sniffing / bandwidth monitoring\n* python-nmap for device discovery\n* sqlite for data persistence\n* chart.js for visualization\n\nit was a good way to learn about networking protocols, concurrent packet processing, and building a full stack monitoring application from scratch.\n\ncode + screenshots: [https://github.com/torchiachristian/HomeNetMonitor](https://github.com/torchiachristian/HomeNetMonitor)\n\nfeedback welcome, especially on the packet sniffing implementation and anomaly detection logic", "source": "Reddit", "date": "2026-01-20T16:49:52", "author": "christiantorchia", "score": 27}
{"title": "Please recommend a front-end framework/package", "url": "https://www.reddit.com/r/Python/comments/1qdz1qu/please_recommend_a_frontend_frameworkpackage/", "content": "Please recommend a front-end framework/package. I'm building an app with streamlit.\n&gt; Why streamlit?\n\nBecause I have no frontend experience and streamlit helped me get off the ground pretty quickly. Also, I'm simultaneously deploying to web and desktop,  and streamlit lets me do this with just the one codebase (I intend to use something like PyInstaller for distribution)\n\n\nI have different \"[expanders](https://docs.streamlit.io/develop/api-reference/layout/st.expander)\" in my streamlit application. Each expander has some data/input elements in it (in the case of my most recent problem, it's a `data_editor`). Sometimes, I need one element to update in response to the user clicking on \"Save Changes\" in a different part of the application. If they were both in the same fragment, I could just do `st.rerun(scope='fragment')`. But since they're not, I have no other choice but to do `st.rerun()`. But if there's incorrect input, I write an error message, which gets subsequently erased due to the rerun. Now I know that I can store this stuff in `st.session_state` and add additional logic to \"recreate\" the (prior) error-message state of the app, but that adds a lot of complexity.\n\nSince there is no way to `st.rerun()` a different fragment than the one I'm in, it looks like I have to give up streamlit - about time, I've been writing workarounds/hacks for a lot of streamlit stumbling blocks.\n\nSo, would anyone be able to recommend an alternative to streamlit? These are the criteria to determine viability of an alternative:\n\n1. ability to control the layout of my elements and programmatically refresh specific elements on demand\n1. web and desktop deployments from the same codebase\n  1. bonus points for being able to handle mobile deployments as well\n1. Python API - I can learn another language if the learning curve is fast. That takes Node/React out of the realm of possibility\n1. somewhat mature - I started using streamlit back in v0.35 or so. But now I'm using v1.52. While streamlit hasn't been around for as long as React, v1.52 is sufficiently mature. I doubt a flashy new frontend framework (eg: with current version 0.43) would have had enough time to iron out the bugs if it's only been around for a very short period of time (eg: 6 months).\n1. ideally something you have experience with and can therefore speak confidently to its stability/reliability\n\nI'm currently considering:\n\n1. [flet](https://flet.dev/): hasn't been around for very long - anyone know if it's any good?\n1. [NiceGUI](https://nicegui.io)\n1. [Reflex](https://github.com/reflex-dev/reflex)\n\nIf anyone has any thoughts or suggestions, I'd love them\n\nThank you", "source": "Reddit", "date": "2026-01-16T00:10:21", "author": "inspectorG4dget", "score": 20}
{"title": "unwrappy: Rust-inspired Result and Option types with lazy async chaining for Python", "url": "https://www.reddit.com/r/Python/comments/1qh1ros/unwrappy_rustinspired_result_and_option_types/", "content": "unwrappy: Rust-inspired Result and Option types with lazy async chaining for Python. I built a library that brings Rust's `Result` and `Option` types to Python, with lazy evaluation for clean async operation chaining (inspired by Polars' deferred execution).\n\n### What My Project Does\n\n**unwrappy** provides:\n\n- **Result[T, E]** - Success (`Ok`) or failure (`Err`) - errors as values, not exceptions\n- **Option[T]** - Presence (`Some`) or absence (`Nothing`) - explicit optionality\n- **LazyResult / LazyOption** - Build async pipelines without nested awaits\n\n```python\nfrom unwrappy import Ok, Err, Some, NOTHING, LazyResult\n\n# Pattern matching (Python 3.10+)\nmatch divide(10, 0):\n    case Ok(value):\n        print(f\"Result: {value}\")\n    case Err(error):\n        print(f\"Error: {error}\")\n\n# Option for nullable values\nemail = from_nullable(get_user_email(42))  # Some(\"...\") or NOTHING\ndisplay = email.map(lambda e: e.split(\"@\")[0]).unwrap_or(\"Anonymous\")\n\n# Lazy async chaining - no nested awaits\nresult = await (\n    LazyResult.from_awaitable(fetch_user(42))\n    .and_then(fetch_profile)\n    .map(lambda p: p[\"name\"].upper())\n    .collect()\n)\n```\n\nFull combinator API: `map`, `and_then`, `or_else`, `filter`, `zip`, `flatten`, `tee`, and more.\n\n### Target Audience\n\n**Production-ready** - 99% test coverage, fully typed, zero dependencies. Best for API boundaries and data pipelines where you want explicit error handling.\n\n### Why This Exists\n\nThe `rustedpy` ecosystem (`result`, `maybe`) is no longer actively maintained. I needed a maintained alternative with proper async support, so I built unwrappy with `LazyResult`/`LazyOption` for clean async pipeline composition.\n\n**Links:**\n- GitHub: https://github.com/leodiegues/unwrappy\n- PyPI: `pip install unwrappy`\n- Docs: https://leodiegues.github.io/unwrappy\n\nFeedbacks and contributions are welcome!", "source": "Reddit", "date": "2026-01-19T12:30:36", "author": "leonardodiegues", "score": 21}
{"title": "Python Script Ranking All 262,143 Possible Pokemon Type Combinations", "url": "https://www.reddit.com/r/Python/comments/1qf56jo/python_script_ranking_all_262143_possible_pokemon/", "content": "Python Script Ranking All 262,143 Possible Pokemon Type Combinations. **What My Project Does:**¬†Finds all possible combinations of Pokemon types from 1 type to 18 types, making 262,143 combinations in total, and scores their offensive and defensive capabilities.\n\n**Target Audience:**¬†Anyone who plays Pokemon! This is just for fun.\n\n**Comparison:**¬†Existing rankings only rank combinations possible in the game (1 type or 2 types) but this analyzes the capabilities of type combinations that couldn't normally exist in-game (3 types to 18 types). \n\n\\-----------------------------------------------------------------------------------------------------  \n  \nI wrote a Python script with Pandas and Multiprocessing that analyzes all possible Pokemon type combinations and ranks them according to their offensive and defensive capabilities. It doesn't just do 1-2 types, but instead all combinations up to 18 types. This makes for 262,143 possible combinations in total!\n\n  \n**Some highlights:**\n\nThe best possible defensive combination is:\n\n    ['Normal', 'Fire', 'Water', 'Electric', 'Poison', 'Ground', 'Flying', 'Ghost', 'Dragon', 'Dark', 'Steel', 'Fairy']\n\nThis has no weaknesses.   \nResists Fire, Grass, Flying, Bug (0.03125x damage lol), Dark, Steel, and Fairy.   \nImmune to Normal,\tElectric, Fighting, Poison, Ground, Psychic, and Ghost.   \nThis ranked 28th overall.\n\nThat's only 12 types though. If a Pokemon had all 18 types, a.k.a:\n\n    ['Normal', 'Fire', 'Water', 'Electric', 'Grass', 'Ice', 'Fighting', 'Poison', 'Ground', 'Flying', 'Psychic', 'Bug', 'Rock', 'Ghost', 'Dragon', 'Dark', 'Steel', 'Fairy']\n\n  \nIt would be weak to only Rock, but it would only resist Grass, Bug, Dark, and Steel.  \nThis ranked 1,992nd place in defense and 536th overall.\n\nThe smallest number of types to hit all Pokemon for super effective STAB is 7. There were 10 7-type combinations that could hit all types for super effective damage. In total, 16,446 combinations could do this.\n\nThe single worst defensive type combination is:\n\n    ['Grass', 'Ice', 'Psychic', 'Bug', 'Dragon']\n\nIts weaknesses are\n\n    Fire: 4.0x\n    Ice: 2.0x\n    Poison: 2.0x\n    Flying: 4.0x\n    Bug: 4.0x\n    Rock: 4.0x\n    Ghost: 2.0x\n    Dragon: 2.0x\n    Dark: 2.0x\n    Steel: 2.0x\n    Fairy: 2.0x\n\nOuch. This combination placed 262,083rd overall.\n\nAnd the single lowest-scored type combination out of all 262,143 is... *Grass*. That's it. Pure Grass.\n\n**Looking at only 1-type and 2-type combinations:**\n\nTop 5 by Offense:\n\n    Rank 1: ¬† ['Ice', 'Ground'] ¬† ¬† ¬† ¬†75.0% ¬†Highest for 2 types.\n    Rank 2: ¬† ['Ice', 'Fighting'] ¬† ¬† ¬†75.0% ¬†Highest for 2 types.\n    Rank 3: ¬† ['Ground', 'Flying'] ¬† ¬† 72.22% \n    Rank 4: ¬† ['Fire', 'Ground'] ¬† ¬† ¬† 72.22% \n    Rank 5: ¬† ['Ground', 'Fairy'] ¬† ¬† ¬†72.22%\n\nTop 5 by Defense:\n\n    Rank 1: ¬† ['Flying', 'Steel'] ¬† ¬† ¬†69.44% Highest for 2 types.\n    Rank 2: ¬† ['Steel', 'Fairy'] ¬† ¬† ¬† 69.44% Highest for 2 types.\n    Rank 3: ¬† ['Normal', 'Ghost'] ¬† ¬† ¬†68.06% \n    Rank 4: ¬† ['Bug', 'Steel'] ¬† ¬† ¬† ¬† 67.36% \n    Rank 5: ¬† ['Ghost', 'Steel'] ¬† ¬† ¬† 67.36% \n\nTop 5 Overall:\n\n    Rank 1:\n    ['Ground', 'Flying']\n    # of Types: 2\n    Offense Score: 72.22%\n    Defense Score: 63.19%\n    Overall:       67.71% Highest average for 2 types.\n    \n    Rank 2:\n    ['Fire', 'Ground']\n    # of Types: 2\n    Offense Score: 72.22%\n    Defense Score: 62.5%\n    Overall:       67.36%\n    \n    Rank 3:\n    ['Ground', 'Steel']\n    # of Types: 2\n    Offense Score: 69.44%\n    Defense Score: 64.58%\n    Overall:       67.01%\n    \n    Rank 4:\n    ['Ground', 'Fairy']\n    # of Types: 2\n    Offense Score: 72.22%\n    Defense Score: 61.11%\n    Overall:       66.67%\n    \n    Rank 5:\n    ['Flying', 'Steel']\n    # of Types: 2\n    Offense Score: 63.89%\n    Defense Score: 69.44% Highest defense for 2 types.\n    Overall:       66.67%\n\nThe full code and output files up to 6-type combinations can be found on my Github, [here.](https://github.com/superwatts/pokemon-type-ranking/) \n\nThe full output file for all 262,143", "source": "Reddit", "date": "2026-01-17T06:52:01", "author": "sxprwtts", "score": 20}
{"title": "Convert your bear images into bear images: Bear Right Back", "url": "https://www.reddit.com/r/Python/comments/1qiulsc/convert_your_bear_images_into_bear_images_bear/", "content": "Convert your bear images into bear images: Bear Right Back. # What My Project Does\n\n**bearrb** is a Python CLI tool that takes **two images of bears** (a source and a target) and transforms the source into a close approximation of the target **by only rearranging pixel coordinates**.\n\nNo pixel values are modified, generated, blended, or recolored, every original pixel is preserved exactly as it was. The algorithm computes a permutation of pixel positions that minimizes the visual difference from the target image.\n\nrepo: [https://github.com/JoshuaKasa/bearrb](https://github.com/JoshuaKasa/bearrb)\n\n# Target Audience\n\nThis is obviously a **toy / experimental project**, not meant for production image editing.\n\nIt's mainly for:\n\n* people interested in algorithmic image processing\n* optimization under hard constraints\n* weird/fun CLI tools\n* math-y or computational art experiments\n\n# Comparison\n\nMost image tools try to be useful and correct... bearrb does not.\n\nInstead of editing, filtering, generating, or enhancing images, bearrb just takes the pixels it already has and **throws them around until the image vaguely resembles the other bear**", "source": "Reddit", "date": "2026-01-21T11:39:59", "author": "JizosKasa", "score": 18}
{"title": "I built a local-first file metadata extraction library with a CLI (Python + Pydantic + Typer)", "url": "https://www.reddit.com/r/Python/comments/1qi3zwa/i_built_a_localfirst_file_metadata_extraction/", "content": "I built a local-first file metadata extraction library with a CLI (Python + Pydantic + Typer). Hi all,\n\nI've been working on a project called Dorsal for the last 18 months. It's a way to make unstructured data more queryable and organized, without having to upload files to a cloud bucket or pay for remote compute (my CPU/GPU can almost always handle my workloads).\n\n# What my Project Does\n\nDorsal is a Python library and CLI for generating, validating and managing structured file metadata. It scans files locally to generate validated JSON-serializable records. I personally use it for deduplicating files, adding annotations (structured metadata records) and organizing files by tags.\n\n* Core Extraction: Out of the box, it extracts \"universal\" metadata (Name, Hashes, Media Type; things any file has), as well and format-specific values (e.g., document page counts, video resolution, ebook titles/authors).\n* The Toolkit: It provides the scaffolding to build and plug in your own complex extraction models (like OCR, classification, or entity extraction, where the input is a file). It handles the pipeline execution, dependency management, and file I/O for you.\n* Strict Validation: It enforces Pydantic/JSON Schema on all outputs. If your custom extractor returns a float where a string is expected, Dorsal catches it before it pollutes your index.\n\nExample: a simple custom model for checking PDF files for sensitive words:\n\n    from dorsal import AnnotationModel\n    from dorsal.file.helpers import build_classification_record\n    from dorsal.file.preprocessing import extract_pdf_text\n    \n    SENSITIVE_LABELS = {\n        \"Confidential\": [\"confidential\", \"do not distribute\", \"private\"],\n        \"Internal\": [\"internal use only\", \"proprietary\"],\n    }\n    \n    class SensitiveDocumentScanner(AnnotationModel):\n        id: str = \"github:dorsalhub/annotation-model-examples\"\n        version: str = \"1.0.0\"\n    \n        def main(self) -&gt; dict | None:\n            try:\n                pages = extract_pdf_text(self.file_path)\n            except Exception as err:\n                self.set_error(f\"Failed to parse PDF: {err}\")\n                return None\n    \n            matches = set()\n            for text in pages:\n                text = text.lower()\n                for label, keywords in SENSITIVE_LABELS.items():\n                    if any(k in text for k in keywords):\n                        matches.add(label)\n    \n            return build_classification_record(\n                labels=list(matches),\n                vocabulary=list(SENSITIVE_LABELS.keys())\n            )\n\n\\^ This can be easily integrated into a locally-run linear pipeline, and executed via either the command line (by pointing at a file or directory) or in a python script.\n\n# Target Audience\n\n* ML Engineers / Data Scientists: Dorsal lets you make sure all of your output steps are validated, using a set of robust schemas for many common data engineering tasks (regression, entity extraction, classification etc.).\n* Data Hoarders / Archivists: People with massive local datasets (TB+) who like customizable tools for deduplication, tagging and even cloud querying\n* RAG Pipeline Builders: Turn folders of PDFs and docs into structured JSON chunks for vector embeddings\n\n# Links\n\n* Github: [https://github.com/dorsalhub/dorsal](https://github.com/dorsalhub/dorsal)\n* PyPI: pip install dorsalhub\n* Docs: [https://docs.dorsalhub.com](https://docs.dorsalhub.com)\n\n# Comparison\n\n|Feature|Dorsal|Cloud ETL (AWS/GCP)|\n|:-|:-|:-|\n|**Integrity**|Hash-based|Upload required|\n|**Validation**|JSON Schema / Pydantic|API Dependent|\n|**Cost**|Free (Local Compute)|$$$ (Per Page)|\n|**Workflow**|Standardized Pipeline|Vendor Lock-in|\n\nAny and all feedback is extremely welcome!", "source": "Reddit", "date": "2026-01-20T16:25:00", "author": "AverageMechUser", "score": 19}
{"title": "I built a Python DSL for creating C4 models and diagrams", "url": "https://www.reddit.com/r/Python/comments/1qhxsad/i_built_a_python_dsl_for_creating_c4_models_and/", "content": "I built a Python DSL for creating C4 models and diagrams. Hello!\n\nLast year, I started writing a Python C4 model authoring tool, and it has come to a point where I feel good enough to share it with you guys so you can start playing around with it locally and render the C4 model views with PlantUML.\n\nGitHub repo:¬†[https://github.com/amirulmenjeni/buildzr](https://github.com/amirulmenjeni/buildzr)\n\nDocumentation here:¬†[https://buildzr.dev](https://buildzr.dev/)\n\n# What My Project Does\n\nbuildzr is a¬†[Structurizr](https://structurizr.com/)¬†authoring tool for Python programmers. It allows you to declaratively or procedurally author Structurizr models and diagrams.\n\nIf you're not familiar with Structurizr, it is both an open standard (see¬†[Structurizr JSON schema](https://github.com/structurizr/json)) and a¬†[set of tools](https://docs.structurizr.com/usage)¬†for building software architecture diagrams as code. Structurizr derives its architecture modeling paradigm based on the¬†[C4 model](https://c4model.com/), the modeling language for describing software architectures and their relationships.\n\nIn Structurizr, you define architecture models (System Context, Container, Component, and Code) and their relationships first. And then, you can re-use the models to present multiple perspectives, views, and stories about your architecture.\n\nbuildzr supercharges this workflow with Pythonic syntax sugar and intuitive APIs that make modeling as code more fun and productive.\n\n# Target Audience\n\nUse buildzr if you want to have an intuitive and powerful tool for writing C4 architecture models:\n\n* **Intuitive Pythonic Syntax**: Use Python's context managers (`with`¬†statements) to create nested structures that naturally mirror your architecture's hierarchy. See the¬†[example](https://github.com/amirulmenjeni/buildzr#quick-example).\n* **Programmatic Creation**: Use¬†buildzr's DSL APIs to programmatically create C4 model architecture diagrams. Great for automation!\n* **Advanced Styling**: Style elements beyond just tags --- target by direct reference, type, group membership, or custom predicates for fine-grained visual control. Just take a look at¬†[Styles](https://buildzr.dev/user-guide/styles/)!\n* **Cloud Provider Themes**: Add AWS, Azure, Google Cloud, Kubernetes, and Oracle Cloud icons to your diagrams with IDE-discoverable constants. No more memorizing tag strings! See¬†[Themes](https://buildzr.dev/user-guide/themes/).\n* **Standards Compliant**: Stays true to the¬†[Structurizr JSON schema](https://github.com/structurizr/json)¬†standards.¬†buildzr¬†uses¬†[datamodel-code-generator](https://github.com/koxudaxi/datamodel-code-generator)¬†to automatically generate the low-level representation of the Workspace model.\n* **Rich Toolchain**: Uses the familiar Python programming language and its rich toolchains to write software architecture models and diagrams!\n\nQuick example, so you can get the idea (more examples and explanations at [https://buildzr.dev](https://buildzr.dev)):\n\n    from buildzr.dsl import (\n        Workspace,\n        SoftwareSystem,\n        Person,\n        Container,\n        SystemContextView,\n        ContainerView,\n        desc,\n        Group,\n        StyleElements,\n    )\n    from buildzr.themes import AWS\n    \n    with Workspace('w') as w:\n    \n        # Define your models (architecture elements and their relationships).\n    \n        with Group(\"My Company\") as my_company:\n            u = Person('Web Application User')\n            webapp = SoftwareSystem('Corporate Web App')\n            with webapp:\n                database = Container('database')\n                api = Container('api')\n                api &gt;&gt; (\"Reads and writes data from/to\", \"http/api\") &gt;&gt; database\n        with Group(\"Microsoft\") as microsoft:\n            email_system = SoftwareSystem('Microsoft 365')\n    \n        u &gt;&gt; [\n            desc(\"Reads and writes email using\") &gt;&gt; email_system,\n            desc(\"Create work order using\") &gt;&gt; webapp,\n        ]", "source": "Reddit", "date": "2026-01-20T11:39:20", "author": "scribe-kiddie", "score": 17}
{"title": "Python Version in Production ?", "url": "https://www.reddit.com/r/Python/comments/1qgt083/python_version_in_production/", "content": "Python Version in Production ?. 3.12 / 3.13 / 3.14 (Stable) \n\nSo in production, which version of Python are you using? Apparently I'm using 3.12, but I'm thinking off upgrading to 3.13 What's the main difference? What version are you using for your production in these cases?", "source": "Reddit", "date": "2026-01-19T04:23:58", "author": "TopicBig1308", "score": 17}
{"title": "Follow up: Clientele - an API integration framework for Python", "url": "https://www.reddit.com/r/Python/comments/1qdo37p/follow_up_clientele_an_api_integration_framework/", "content": "Follow up: Clientele - an API integration framework for Python. Hello pythonistas, two weeks ago I shared a [blog post](https://www.reddit.com/r/Python/comments/1q1udpj/blog_post_a_different_way_to_think_about_python/) about an alternative way of building API integrations, heavily inspired by the developer experience of python API  frameworks.\n\n**What My Project Does**\n\nClientele lets you focus on the behaviour you want from an API, and let it handle the rest - networking, hydration, caching, and data validation. It uses strong types and decorators to build a reliable and loveable API integration experience.\n\nI have been working on the project day and night - testing, honing, extending, and even getting contributions from other helpful developers. I now have the project in a stable state where I need more feedback on real-life usage and testing.\n\nHere are some examples of it in action:\n\n## Simple API\n\n```python\nfrom clientele import api\n\nclient = api.APIClient(base_url=\"https://pokeapi.co/api/v2\")\n\n@client.get(\"/pokemon/{pokemon_name}\")\ndef get_pokemon_info(pokemon_name: str, result: dict) -&gt; dict:\n    return result\n```\n\n## Simple POST request\n\n```python\nfrom clientele import api\n\nclient = api.APIClient(base_url=\"https://httpbin.org\")\n\n\n@client.post(\"/post\")\ndef post_input_data(data: dict, result: dict) -&gt; dict:\n    return result\n```\n\n## Streaming responses\n\n```python\nfrom typing import AsyncIterator\nfrom pydantic import BaseModel\nfrom clientele import api\n\nclient = api.APIClient(base_url=\"http://localhost:8000\")\n\nclass Event(BaseModel):\n    text: str\n\n@client.get(\"/events\", streaming_response=True)\nasync def stream_events(*, result: AsyncIterator[Event]) -&gt; AsyncIterator[Event]:\n    return result\n```\n\nNew features include:\n\n- Handle streaming responses for Server Sent Events\n- Handle custom response parsing with callbacks\n- Sensible HTTP caching decorator with extendable backends\n- A Mypy plugin to handle the way the library injects parameters\n- Many many tweaks and updates to handle edge-case OpenAPI schemas\n\nPlease star ‚≠ê the project, give it a download and let me know what you think: https://github.com/phalt/clientele", "source": "Reddit", "date": "2026-01-15T17:25:53", "author": "phalt_", "score": 15}
{"title": "pyauto_desktop: Benchmarks, window controls, OCR", "url": "https://www.reddit.com/r/Python/comments/1qgjcsk/pyauto_desktop_benchmarks_window_controls_ocr/", "content": "pyauto_desktop: Benchmarks, window controls, OCR. I have just released a major update to my pyauto\\_desktop module. Below is the list of new features introduced:\n\n# Optical character recognition\n\nI have added OCR support to my pyauto\\_desktop module, you can now detect text on your screen and automate it.\n\nExample of the inspector at work: [https://i.imgur.com/TqiXLWA.gif](https://i.imgur.com/TqiXLWA.gif)\n\n# Window Control:\n\nYou can now control program windows like minimize, maximize, move, focus and much more!\n\n# Benchmarks:\n\n**1. Standard UI Match**\n\n*Settings: 56x56 Template | Pyramid=True | Grayscale=False | Conf=0.95*\n\n|**Function**|**Library**|**FPS**|**Time (ms)**|**Speedup**|\n|:-|:-|:-|:-|:-|\n|`locateOnScreen`|PyAutoGUI|5.55|180ms|‚Äî|\n|`locateOnScreen`|**pyauto\\_desktop**|**23.35**|**42ms**|**4.2x**|\n|`locateAllOnScreen`|PyAutoGUI|5.56|180ms|‚Äî|\n|`locateAllOnScreen`|**pyauto\\_desktop**|**24.14**|**41ms**|**4.3x**|\n\n**2. Max Performance (Grayscale)**\n\n*Settings: 56x56 Template | Pyramid=True | Grayscale=True | Conf=0.95*\n\n|**Function**|**Library**|**FPS**|**Time (ms)**|**Speedup**|\n|:-|:-|:-|:-|:-|\n|`locateOnScreen`|PyAutoGUI|10.27|97ms|‚Äî|\n|`locateOnScreen`|**pyauto\\_desktop**|**27.13**|**36ms**|**2.6x**|\n|`locateAllOnScreen`|PyAutoGUI|10.20|98ms|‚Äî|\n|`locateAllOnScreen`|**pyauto\\_desktop**|**27.01**|**37ms**|**2.6x**|\n\n**3. Small Image / Raw Search (No Scaling)**\n\n*Settings: 24x24 Template | Pyramid=False | Grayscale=False | Conf=0.95*\n\n|**Function**|**Library**|**FPS**|**Time (ms)**|**Speedup**|\n|:-|:-|:-|:-|:-|\n|`locateOnScreen`|PyAutoGUI|6.08|164ms|‚Äî|\n|`locateOnScreen`|**pyauto\\_desktop**|**6.74**|**148ms**|**1.1x**|\n|`locateAllOnScreen`|PyAutoGUI|6.14|162ms|‚Äî|\n|`locateAllOnScreen`|**pyauto\\_desktop**|**7.12**|**140ms**|**1.2x**|\n\n# What My Project Does\n\nIt allows you to create shareable image or coordinate based automation regardless of resolution or dpr.\n\nIt features:  \n\\-¬†**Built-in GUI Inspector**¬†to snip, edit, test, and generate code.  \n\\-¬†Uses¬†`Session`¬†logic to scale coordinates &amp; images automatically.  \n\\-¬†**Up to 5x Faster.**¬†Uses¬†`mss`¬†&amp; Pyramid Template Matching &amp; Image caching.  \n\\-¬†`locateAny`¬†/¬†`locateAll`¬†built-in. Finds the first or all matches from a list of images.  \n\\- OCR &amp; Window control\n\n# Target Audience\n\nProgramer who need to automate programs they don't have backend access to and aren't browser-based.\n\nYou can install it here: [pyauto-desktop ¬∑ PyPI](https://pypi.org/project/pyauto-desktop/)  \nCode and Documentation: [pyauto-desktop: github](https://github.com/Omar-F-Rashed/pyauto-desktop)", "source": "Reddit", "date": "2026-01-18T21:26:37", "author": "MrYaml", "score": 13}
{"title": "I built event2vector, a scikit‚Äëstyle library for event sequence embeddings in Python)", "url": "https://www.reddit.com/r/Python/comments/1qgaac2/i_built_event2vector_a_scikitstyle_library_for/", "content": "I built event2vector, a scikit‚Äëstyle library for event sequence embeddings in Python). # What event2vec Project Does\n\nI‚Äôve been working on my Python library, Event2Vector (event2vec), for embedding event sequences (logs, clickstreams, POS tags, life‚Äëevent sequences, etc.) into vectors in a way that is easy to inspect and reason about.\n\nInstead of a complex RNN/transformer, the model uses a simple additive recurrent update: the hidden state for a sequence is constrained to behave like the sum of its event embeddings (the ‚Äúlinear additive hypothesis‚Äù). This makes sequence trajectories geometrically interpretable and supports vector arithmetic on histories (e.g., A ‚àí B + C style analogies on event trajectories).\n\nFrom the Python side, you primarily interact with a scikit‚Äëlearn‚Äëstyle estimator:\n\n    python\n    from event2vector import Event2Vec\n    \n    model = Event2Vec(\n        num_event_types=len(vocab),\n        geometry=\"euclidean\",   # or \"hyperbolic\"\n        embedding_dim=128,\n        pad_sequences=True,\n        num_epochs=50,\n    )\n    model.fit(train_sequences, verbose=True)\n    embeddings = model.transform(train_sequences)\n\nThere are both Euclidean and hyperbolic (Poincar√© ball) variants, so you can choose flat vs hierarchical geometry for your event space.\n\n# Target Audience\n\nPython users working with discrete event sequences: logs, clickstreams, POS tags, user journeys, synthetic processes, etc.\n\nE.g. posts about shopping patterns [https://substack.com/home/post/p-181632020?source=queue](https://substack.com/home/post/p-181632020?source=queue) or geometry of languages [https://sulcantonin.substack.com/p/the-geometry-of-language-families](https://sulcantonin.substack.com/p/the-geometry-of-language-families)\n\nPeople who want interpretable, geometric representations of sequences rather than just ‚Äúit works but I can‚Äôt see what it‚Äôs doing.‚Äù\n\nIt is currently more of a research/analysis tool and prototyping library than a fully battle‚Äëhardened production system, but:\n\nIt is MIT‚Äëlicensed and on PyPI (`pip install event2vector`).\n\nIt has a scikit‚Äëstyle API (`fit`, `fit_transform`, `transform`, `most_similar`) and optional padded batching + GPU support, so it should drop into many Python ML workflows.\n\n# Comparison\n\n**Versus Word2Vec and similar context‚Äëwindow models:**\n\nWord2Vec is excellent for capturing local co‚Äëoccurrence and semantic similarity, but it does not model the ordered trajectory of a sequence; contexts are effectively treated as bags of neighbors.\n\nEvent2Vector, in contrast, explicitly treats the hidden state as an ordered sum of event embeddings, and its training objective enforces that likely future events lie along the trajectory of that sum. This lets it capture sequential structure and trajectory geometry that Word2Vec is not designed to represent.\n\nIn the paper, an unsupervised experiment on the Brown Corpus shows that Event2Vector‚Äôs additive sequence embeddings produce clearer clusters of POS‚Äëtag patterns than a Word2Vec baseline when you compose tag sequences and visualize them.\n\n**Versus generic RNNs / LSTMs / transformers:**\n\nThose models are more expressive and often better for pure prediction, but their hidden states are usually hard to interpret geometrically.\n\nEvent2Vector intentionally trades some expressivity for a simple, reversible additive structure: sequences are trajectories in a space where addition/subtraction have a clear meaning, and you can inspect them with PCA/t‚ÄëSNE or do analogical reasoning.\n\n# Python‚Äëcentric details\n\n* Install: `pip install event2vector` \n* Github Repo: [https://github.com/sulcantonin/event2vec\\_public/tree/main](https://github.com/sulcantonin/event2vec_public/tree/main)\n\nAccepts integer‚Äëencoded sequences (Python lists / tensors), with optional padding for minibatching.\n\nProvides a tiny synthetic quickstart (START‚ÜíA/B‚ÜíC‚ÜíEND) that trains in seconds on CPU and plots embeddings with matplotlib, plus a Brown Corpus POS example that mirrors the paper.\n\nI‚Äôd love feedback f", "source": "Reddit", "date": "2026-01-18T15:41:43", "author": "sulcantonin", "score": 12}
{"title": "Wikipedia turns 25, still boasting zero ads and over 7 billion visitors per month despite the rise of AI and threats of government repression", "url": "https://www.reddit.com/r/technology/comments/1qgk4it/wikipedia_turns_25_still_boasting_zero_ads_and/", "content": "Wikipedia turns 25, still boasting zero ads and over 7 billion visitors per month despite the rise of AI and threats of government repression.", "source": "Reddit", "date": "2026-01-18T21:58:29", "author": "Turbostrider27", "score": 60910}
{"title": "X has stopped working", "url": "https://www.reddit.com/r/technology/comments/1qejnjo/x_has_stopped_working/", "content": "X has stopped working.", "source": "Reddit", "date": "2026-01-16T16:53:34", "author": "Well_Socialized", "score": 41862}
{"title": "US President Is Obsessed With Oil. But Chinese Batteries Will Soon Run the World.", "url": "https://www.reddit.com/r/technology/comments/1qh5kdg/us_president_is_obsessed_with_oil_but_chinese/", "content": "US President Is Obsessed With Oil. But Chinese Batteries Will Soon Run the World..", "source": "Reddit", "date": "2026-01-19T15:27:22", "author": "rezwenn", "score": 32692}
{"title": "Supreme Court Hacked, Proving Its Cybersecurity Is As Robust As Its Ethical Code", "url": "https://www.reddit.com/r/technology/comments/1qd46jv/supreme_court_hacked_proving_its_cybersecurity_is/", "content": "Supreme Court Hacked, Proving Its Cybersecurity Is As Robust As Its Ethical Code.", "source": "Reddit", "date": "2026-01-15T01:13:25", "author": "Ok_Heron_5442", "score": 28813}
{"title": "Jeff Bezos said the quiet part out loud ‚Äî hopes that you'll give up your PC to rent one from the cloud", "url": "https://www.reddit.com/r/technology/comments/1qcqc5i/jeff_bezos_said_the_quiet_part_out_loud_hopes/", "content": "Jeff Bezos said the quiet part out loud ‚Äî hopes that you'll give up your PC to rent one from the cloud.", "source": "Reddit", "date": "2026-01-14T16:33:46", "author": "ControlCAD", "score": 26759}
{"title": "‚ÄòELITE‚Äô: The Palantir App ICE Uses to Find Neighborhoods to Raid | Internal ICE material and testimony from an official obtained by 404 Media provides the clearest link yet between the technological infrastructure Palantir is building for ICE and the agency‚Äôs activities on the ground", "url": "https://www.reddit.com/r/technology/comments/1qdo076/elite_the_palantir_app_ice_uses_to_find/", "content": "‚ÄòELITE‚Äô: The Palantir App ICE Uses to Find Neighborhoods to Raid | Internal ICE material and testimony from an official obtained by 404 Media provides the clearest link yet between the technological infrastructure Palantir is building for ICE and the agency‚Äôs activities on the ground.", "source": "Reddit", "date": "2026-01-15T17:22:46", "author": "Hrmbee", "score": 26366}
{"title": "AI hype meets reality as majority of CEOs report no financial returns", "url": "https://www.reddit.com/r/technology/comments/1qi1t48/ai_hype_meets_reality_as_majority_of_ceos_report/", "content": "AI hype meets reality as majority of CEOs report no financial returns.", "source": "Reddit", "date": "2026-01-20T14:59:18", "author": "AdSpecialist6598", "score": 26276}
{"title": "DOGE employees may have improperly accessed social security data, DOJ says", "url": "https://www.reddit.com/r/technology/comments/1qifeym/doge_employees_may_have_improperly_accessed/", "content": "DOGE employees may have improperly accessed social security data, DOJ says.", "source": "Reddit", "date": "2026-01-20T23:15:45", "author": "esporx", "score": 23990}
{"title": "Website that leaked info about ICE agents is down after cyberattack.", "url": "https://www.reddit.com/r/technology/comments/1qd1tsz/website_that_leaked_info_about_ice_agents_is_down/", "content": "Website that leaked info about ICE agents is down after cyberattack..", "source": "Reddit", "date": "2026-01-14T23:38:17", "author": "MiamiPower", "score": 21813}
{"title": "President Bought at Least $1 Million in Netflix, Warner Bros. Discovery Bonds Following Their Deal Announcement", "url": "https://www.reddit.com/r/technology/comments/1qfzfmm/president_bought_at_least_1_million_in_netflix/", "content": "President Bought at Least $1 Million in Netflix, Warner Bros. Discovery Bonds Following Their Deal Announcement.", "source": "Reddit", "date": "2026-01-18T05:58:05", "author": "ControlCAD", "score": 20302}
{"title": "Russia threatens to ban GTA 6 if Rockstar doesn't remove male strippers and other \"immoral content\"", "url": "https://www.reddit.com/r/technology/comments/1qhfd2q/russia_threatens_to_ban_gta_6_if_rockstar_doesnt/", "content": "Russia threatens to ban GTA 6 if Rockstar doesn't remove male strippers and other \"immoral content\".", "source": "Reddit", "date": "2026-01-19T21:15:55", "author": "IndicaOatmeal", "score": 17687}
{"title": "East coast could soon get rolling blackouts during summer because data centers have pushed electric grid to the limit", "url": "https://www.reddit.com/r/technology/comments/1qflq0x/east_coast_could_soon_get_rolling_blackouts/", "content": "East coast could soon get rolling blackouts during summer because data centers have pushed electric grid to the limit.", "source": "Reddit", "date": "2026-01-17T20:01:52", "author": "MetaKnowing", "score": 14179}
{"title": "Majority of CEOs report zero payoff from AI splurge", "url": "https://www.reddit.com/r/technology/comments/1qi422a/majority_of_ceos_report_zero_payoff_from_ai/", "content": "Majority of CEOs report zero payoff from AI splurge.", "source": "Reddit", "date": "2026-01-20T16:27:10", "author": "kim82352", "score": 13728}
{"title": "Financial Expert Says OpenAI Is on the Verge of Running Out of Money", "url": "https://www.reddit.com/r/technology/comments/1qe7vop/financial_expert_says_openai_is_on_the_verge_of/", "content": "Financial Expert Says OpenAI Is on the Verge of Running Out of Money.", "source": "Reddit", "date": "2026-01-16T06:52:47", "author": "Infinityy100b", "score": 13488}
{"title": "Six months later, President Mobile still hasn‚Äôt delivered preordered phones | Lawmakers seek FTC investigation, but President has taken control of the agency.", "url": "https://www.reddit.com/r/technology/comments/1qdsy8g/six_months_later_president_mobile_still_hasnt/", "content": "Six months later, President Mobile still hasn‚Äôt delivered preordered phones | Lawmakers seek FTC investigation, but President has taken control of the agency..", "source": "Reddit", "date": "2026-01-15T20:19:25", "author": "ControlCAD", "score": 11904}
{"title": "DOGE Cuts ‚ÄúUnexpectedly and Significantly Impacted‚Äù Critical Pentagon Unit | Staffing problems caused by DOGE resulted in the Defense Information Systems Agency warning of ‚Äúextreme risk for loss of service‚Äù across the military", "url": "https://www.reddit.com/r/technology/comments/1qh7v3o/doge_cuts_unexpectedly_and_significantly_impacted/", "content": "DOGE Cuts ‚ÄúUnexpectedly and Significantly Impacted‚Äù Critical Pentagon Unit | Staffing problems caused by DOGE resulted in the Defense Information Systems Agency warning of ‚Äúextreme risk for loss of service‚Äù across the military.", "source": "Reddit", "date": "2026-01-19T16:53:22", "author": "Hrmbee", "score": 11375}
{"title": "Bandcamp becomes the first major music platform to ban AI content", "url": "https://www.reddit.com/r/technology/comments/1qcuxli/bandcamp_becomes_the_first_major_music_platform/", "content": "Bandcamp becomes the first major music platform to ban AI content.", "source": "Reddit", "date": "2026-01-14T19:20:54", "author": "ornithobiography", "score": 10563}
{"title": "FBI fights leaks by seizing Washington Post reporter‚Äôs phone, laptops, and watch | FBI searches home and devices of reporter who has over 1,100 government contacts.", "url": "https://www.reddit.com/r/technology/comments/1qd57lv/fbi_fights_leaks_by_seizing_washington_post/", "content": "FBI fights leaks by seizing Washington Post reporter‚Äôs phone, laptops, and watch | FBI searches home and devices of reporter who has over 1,100 government contacts..", "source": "Reddit", "date": "2026-01-15T01:57:43", "author": "ControlCAD", "score": 9449}
{"title": "AI boom could falter without wider adoption, Microsoft chief Satya Nadella warns", "url": "https://www.reddit.com/r/technology/comments/1qi5si0/ai_boom_could_falter_without_wider_adoption/", "content": "AI boom could falter without wider adoption, Microsoft chief Satya Nadella warns.", "source": "Reddit", "date": "2026-01-20T17:30:26", "author": "PaiDuck", "score": 8692}
{"title": "Data Centers Will Consume 70 Percent Of Memory Chips made in 2026, RAM Shortage Will Last Until Until Atleast 2029 As Manafacturing Capacity For RAM In 2028 That Hasnt Even Been Made Yet Is Already being Sold", "url": "https://www.reddit.com/r/technology/comments/1qgolhs/data_centers_will_consume_70_percent_of_memory/", "content": "Data Centers Will Consume 70 Percent Of Memory Chips made in 2026, RAM Shortage Will Last Until Until Atleast 2029 As Manafacturing Capacity For RAM In 2028 That Hasnt Even Been Made Yet Is Already being Sold.", "source": "Reddit", "date": "2026-01-19T01:03:04", "author": "Shogouki", "score": 8226}
{"title": "Natural language processing", "url": "https://en.wikipedia.org/wiki/Natural_language_processing", "content": "Natural language processing (NLP) is the processing of natural language information by a computer. NLP is a subfield of computer science and is closely associated with artificial intelligence. NLP is also related to information retrieval, knowledge representation, computational linguistics, and linguistics more broadly.\nMajor processing tasks in an NLP system include: speech recognition, text classification, natural language understanding, and natural language generation.\n\nHistory\nNatural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n\nSymbolic NLP (1950s ‚Äì early 1990s)\nThe premise of symbolic NLP is often illustrated using John Searle's Chinese room thought experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n\n1950s: The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten years of research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted in America (though some research continued elsewhere, such as Japan and Europe) until the late 1980s when the first statistical machine translation systems were developed.\n1960s: Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapy, written by Joseph Weizenbaum between 1964 and 1966. Despite using minimal information about human thought or emotion, ELIZA was able to produce interactions that appeared human-like. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because that was all that would fit in a computer  memory at the time.\n1970s: During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, the first chatterbots were written (e.g., PARRY).\n1980s: The 1980s and early 1990s mark the heyday of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar), morphology (e.g., two-level morphology), semantics (e.g., Lesk algorithm), reference (e.g., within Centering Theory) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory). Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky. An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.\n\nStatistical NLP (1990s‚Äìpresent)\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This shift was influenced by increasing computational power (see Moore's law) and a decline in the dominance of Chomskyan linguistic theories... (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. \n\n1990s: Many of the notable early successes in statistical methods in NLP occurred in the field of machine translation, due especially to work at IBM Research, such as IBM alignment models. These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems o", "source": "Wikipedia", "date": null, "author": null, "score": null}
{"title": "Deep learning", "url": "https://en.wikipedia.org/wiki/Deep_learning", "content": "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n\nOverview\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\nImportantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.\nThe term deep learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons. Although the history of its appearance is apparently more complicated.\n\nInterpretations\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.\nThe classic u", "source": "Wikipedia", "date": null, "author": null, "score": null}
{"title": "Machine learning", "url": "https://en.wikipedia.org/wiki/Machine_learning", "content": "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.\nFrom a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimisation under this framework.\n\nHistory\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used during this time period.\nThe earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.\nBy the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nils Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question, \"Can machines think?\", is replaced with the question, \"Can machines do what we (as thinking entities) can do?\".\nModern-day Machine Learning algorithms are broken into 3 algorithm types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.\n\nCurrent Supervised Learning Algorithms have objectives of classification and regression.\nCurrent Unsupervised Learning Algorithms have objectives of clustering, dimensionality reduction, and association rule.\nCurrent Reinforcement Learning Algorithms focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods.\nIn 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis. By 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.\n\nRelationships to other fields\nArtificial intelligence\nAs a scientific endeavour, machine learning grew out of the quest for artifi", "source": "Wikipedia", "date": null, "author": null, "score": null}
{"title": "Artificial intelligence", "url": "https://en.wikipedia.org/wiki/Artificial_intelligence", "content": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI) ‚Äì AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms. Ethical concerns have been raised about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\nKnowledge representation\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the", "source": "Wikipedia", "date": null, "author": null, "score": null}
